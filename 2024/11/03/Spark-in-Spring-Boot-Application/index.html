<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.whereq.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Introduction Prerequisites Project Folder Structure Setting Up the Spring Boot Application Step 1: Create a Spring Boot Project Step 2: Configure Application Properties   Integrating Spark with Sprin">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark in Spring Boot Application">
<meta property="og:url" content="https://www.whereq.com/2024/11/03/Spark-in-Spring-Boot-Application/index.html">
<meta property="og:site_name" content="WhereQ">
<meta property="og:description" content="Introduction Prerequisites Project Folder Structure Setting Up the Spring Boot Application Step 1: Create a Spring Boot Project Step 2: Configure Application Properties   Integrating Spark with Sprin">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-11-03T21:24:53.000Z">
<meta property="article:modified_time" content="2024-11-04T03:20:38.671Z">
<meta property="article:author" content="Dazhi Zhang">
<meta property="article:tag" content="Spring Boot">
<meta property="article:tag" content="Elasticsearch">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="Spark">
<meta property="article:tag" content="Big Data">
<meta property="article:tag" content="Minio">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.whereq.com/2024/11/03/Spark-in-Spring-Boot-Application/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://www.whereq.com/2024/11/03/Spark-in-Spring-Boot-Application/","path":"2024/11/03/Spark-in-Spring-Boot-Application/","title":"Spark in Spring Boot Application"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Spark in Spring Boot Application | WhereQ</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">WhereQ</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-articles"><a href="/articles/" rel="section"><i class="fa fa-file fa-fw"></i>Articles</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Prerequisites"><span class="nav-number">2.</span> <span class="nav-text">Prerequisites</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Project-Folder-Structure"><span class="nav-number">3.</span> <span class="nav-text">Project Folder Structure</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Setting-Up-the-Spring-Boot-Application"><span class="nav-number">4.</span> <span class="nav-text">Setting Up the Spring Boot Application</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-1-Create-a-Spring-Boot-Project"><span class="nav-number">4.1.</span> <span class="nav-text">Step 1: Create a Spring Boot Project</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-2-Configure-Application-Properties"><span class="nav-number">4.2.</span> <span class="nav-text">Step 2: Configure Application Properties</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Integrating-Spark-with-Spring-Boot"><span class="nav-number">5.</span> <span class="nav-text">Integrating Spark with Spring Boot</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-1-Add-Spark-Dependencies"><span class="nav-number">5.1.</span> <span class="nav-text">Step 1: Add Spark Dependencies</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Step-2-Configure-Spark"><span class="nav-number">5.2.</span> <span class="nav-text">Step 2: Configure Spark</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Communicating-with-Kafka"><span class="nav-number">6.</span> <span class="nav-text">Communicating with Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reading-Avro-Records-from-Kafka"><span class="nav-number">6.1.</span> <span class="nav-text">Reading Avro Records from Kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reading-Avro-Records-from-Kafka-with-Schema-Registry"><span class="nav-number">6.2.</span> <span class="nav-text">Reading Avro Records from Kafka with Schema Registry</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Writing-Data-to-Kafka"><span class="nav-number">6.3.</span> <span class="nav-text">Writing Data to Kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Writing-Avro-Records-to-Kafka-with-Schema-Registry"><span class="nav-number">6.4.</span> <span class="nav-text">Writing Avro Records to Kafka with Schema Registry</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Communicating-with-Elasticsearch"><span class="nav-number">7.</span> <span class="nav-text">Communicating with Elasticsearch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reading-JSON-Data-from-Elasticsearch"><span class="nav-number">7.1.</span> <span class="nav-text">Reading JSON Data from Elasticsearch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Writing-Data-to-Elasticsearch"><span class="nav-number">7.2.</span> <span class="nav-text">Writing Data to Elasticsearch</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Handling-Parquet-Files-in-MinIO"><span class="nav-number">8.</span> <span class="nav-text">Handling Parquet Files in MinIO</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reading-Parquet-Files-from-MinIO"><span class="nav-number">8.1.</span> <span class="nav-text">Reading Parquet Files from MinIO</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Writing-Parquet-Files-to-MinIO"><span class="nav-number">8.2.</span> <span class="nav-text">Writing Parquet Files to MinIO</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Using-Spark-DataFrame-and-Spark-SQL"><span class="nav-number">9.</span> <span class="nav-text">Using Spark DataFrame and Spark SQL</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Creating-DataFrames"><span class="nav-number">9.1.</span> <span class="nav-text">Creating DataFrames</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Querying-DataFrames-with-Spark-SQL"><span class="nav-number">9.2.</span> <span class="nav-text">Querying DataFrames with Spark SQL</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Unit-Test-Cases"><span class="nav-number">10.</span> <span class="nav-text">Unit Test Cases</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#KafkaServiceTest-java"><span class="nav-number">10.1.</span> <span class="nav-text">KafkaServiceTest.java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ElasticsearchServiceTest-java"><span class="nav-number">10.2.</span> <span class="nav-text">ElasticsearchServiceTest.java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MinIOServiceTest-java"><span class="nav-number">10.3.</span> <span class="nav-text">MinIOServiceTest.java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DataFrameServiceTest-java"><span class="nav-number">10.4.</span> <span class="nav-text">DataFrameServiceTest.java</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Design-Diagrams"><span class="nav-number">11.</span> <span class="nav-text">Design Diagrams</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Component-Diagram"><span class="nav-number">11.1.</span> <span class="nav-text">Component Diagram</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sequence-Diagram"><span class="nav-number">11.2.</span> <span class="nav-text">Sequence Diagram</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Advanced-Scenarios"><span class="nav-number">12.</span> <span class="nav-text">Advanced Scenarios</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Complex-Scenario-1-Flow-Control-and-Backpressure-Handling"><span class="nav-number">12.1.</span> <span class="nav-text">Complex Scenario 1: Flow Control and Backpressure Handling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Complex-Scenario-2-Handling-Large-Scale-Data-Processing"><span class="nav-number">12.2.</span> <span class="nav-text">Complex Scenario 2: Handling Large-Scale Data Processing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Conclusion"><span class="nav-number">13.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">14.</span> <span class="nav-text">References</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Dazhi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">115</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">107</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">68</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/11/03/Spark-in-Spring-Boot-Application/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Spark in Spring Boot Application | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark in Spring Boot Application
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-11-03 16:24:53 / Modified: 22:20:38" itemprop="dateCreated datePublished" datetime="2024-11-03T16:24:53-05:00">2024-11-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spring-Boot/" itemprop="url" rel="index"><span itemprop="name">Spring Boot</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spring-Boot/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spring-Boot/Spark/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big Data</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spring-Boot/Spark/Big-Data/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spring-Boot/Spark/Big-Data/Kafka/Elasticsearch/" itemprop="url" rel="index"><span itemprop="name">Elasticsearch</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spring-Boot/Spark/Big-Data/Kafka/Elasticsearch/Minio/" itemprop="url" rel="index"><span itemprop="name">Minio</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#project-folder-structure">Project Folder Structure</a></li>
<li><a href="#setting-up-the-spring-boot-application">Setting Up the Spring Boot Application</a><ul>
<li><a href="#step-1-create-a-spring-boot-project">Step 1: Create a Spring Boot Project</a></li>
<li><a href="#step-2-configure-application-properties">Step 2: Configure Application Properties</a></li>
</ul>
</li>
<li><a href="#integrating-spark-with-spring-boot">Integrating Spark with Spring Boot</a><ul>
<li><a href="#step-1-add-spark-dependencies">Step 1: Add Spark Dependencies</a></li>
<li><a href="#step-2-configure-spark">Step 2: Configure Spark</a></li>
</ul>
</li>
<li><a href="#communicating-with-kafka">Communicating with Kafka</a><ul>
<li><a href="#reading-avro-records-from-kafka">Reading Avro Records from Kafka</a></li>
<li><a href="#reading-avro-records-from-kafka-with-schema-registry">Reading Avro Records from Kafka with Schema Registry</a></li>
<li><a href="#writing-data-to-kafka">Writing Data to Kafka</a></li>
<li><a href="#writing-avro-records-to-kafka-with-schema-registry">Writing Avro Records to Kafka with Schema Registry</a></li>
</ul>
</li>
<li><a href="#communicating-with-elasticsearch">Communicating with Elasticsearch</a><ul>
<li><a href="#reading-json-data-from-elasticsearch">Reading JSON Data from Elasticsearch</a></li>
<li><a href="#writing-data-to-elasticsearch">Writing Data to Elasticsearch</a></li>
</ul>
</li>
<li><a href="#handling-parquet-files-in-minio">Handling Parquet Files in MinIO</a><ul>
<li><a href="#reading-parquet-files-from-minio">Reading Parquet Files from MinIO</a></li>
<li><a href="#writing-parquet-files-to-minio">Writing Parquet Files to MinIO</a></li>
</ul>
</li>
<li><a href="#using-spark-dataframe-and-spark-sql">Using Spark DataFrame and Spark SQL</a><ul>
<li><a href="#creating-dataframes">Creating DataFrames</a></li>
<li><a href="#querying-dataframes-with-spark-sql">Querying DataFrames with Spark SQL</a></li>
</ul>
</li>
<li><a href="#unit-test-cases">Unit Test Cases</a><ul>
<li><a href="#kafkaservicetestjava">KafkaServiceTest.java</a></li>
<li><a href="#elasticsearchservicetestjava">ElasticsearchServiceTest.java</a></li>
<li><a href="#minioservicetestjava">MinIOServiceTest.java</a></li>
<li><a href="#dataframeservicetestjava">DataFrameServiceTest.java</a></li>
</ul>
</li>
<li><a href="#design-diagrams">Design Diagrams</a><ul>
<li><a href="#component-diagram">Component Diagram</a></li>
<li><a href="#sequence-diagram">Sequence Diagram</a></li>
</ul>
</li>
<li><a href="#advanced-scenarios">Advanced Scenarios</a><ul>
<li><a href="#complex-scenario-1-flow-control-and-backpressure-handling">Complex Scenario 1: Flow Control and Backpressure Handling</a></li>
<li><a href="#complex-scenario-2-handling-large-scale-data-processing">Complex Scenario 2: Handling Large-Scale Data Processing</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This article provides a comprehensive guide to developing a Spark application with Spring Boot 3.3.5 to communicate with Kafka and Elasticsearch. The application will handle Avro records in Kafka, JSON data in Elasticsearch, and Parquet files in MinIO using Spark DataFrame and Spark SQL. The article covers the setup, integration, and advanced scenarios for handling large-scale data processing, including the use of Avro Schema Registry when communicating with Kafka.</p>
<hr>
<p><a name="prerequisites"></a></p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><ul>
<li>Java 17 or later</li>
<li>Apache Spark 3.5.4</li>
<li>Spring Boot 3.3.5</li>
<li>Kafka 3.x</li>
<li>Elasticsearch 8.x</li>
<li>MinIO</li>
<li>Maven or Gradle</li>
<li>Confluent Schema Registry</li>
</ul>
<hr>
<p><a name="project-folder-structure"></a></p>
<h2 id="Project-Folder-Structure"><a href="#Project-Folder-Structure" class="headerlink" title="Project Folder Structure"></a>Project Folder Structure</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">spark-spring-boot-app/</span><br><span class="line">├── src/</span><br><span class="line">│   ├── main/</span><br><span class="line">│   │   ├── java/</span><br><span class="line">│   │   │   ├── com/</span><br><span class="line">│   │   │   │   ├── example/</span><br><span class="line">│   │   │   │   │   ├── config/</span><br><span class="line">│   │   │   │   │   │   ├── SparkConfig.java</span><br><span class="line">│   │   │   │   │   ├── service/</span><br><span class="line">│   │   │   │   │   │   ├── KafkaService.java</span><br><span class="line">│   │   │   │   │   │   ├── ElasticsearchService.java</span><br><span class="line">│   │   │   │   │   │   ├── MinIOService.java</span><br><span class="line">│   │   │   │   │   │   ├── DataFrameService.java</span><br><span class="line">│   │   │   │   │   ├── SparkSpringBootConsoleApplication.java</span><br><span class="line">│   │   ├── resources/</span><br><span class="line">│   │   │   ├── application.properties</span><br><span class="line">│   ├── test/</span><br><span class="line">│   │   ├── java/</span><br><span class="line">│   │   │   ├── com/</span><br><span class="line">│   │   │   │   ├── example/</span><br><span class="line">│   │   │   │   │   ├── service/</span><br><span class="line">│   │   │   │   │   │   ├── KafkaServiceTest.java</span><br><span class="line">│   │   │   │   │   │   ├── ElasticsearchServiceTest.java</span><br><span class="line">│   │   │   │   │   │   ├── MinIOServiceTest.java</span><br><span class="line">│   │   │   │   │   │   ├── DataFrameServiceTest.java</span><br><span class="line">├── pom.xml (or build.gradle)</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="setting-up-the-spring-boot-application"></a></p>
<h2 id="Setting-Up-the-Spring-Boot-Application"><a href="#Setting-Up-the-Spring-Boot-Application" class="headerlink" title="Setting Up the Spring Boot Application"></a>Setting Up the Spring Boot Application</h2><h3 id="Step-1-Create-a-Spring-Boot-Project"><a href="#Step-1-Create-a-Spring-Boot-Project" class="headerlink" title="Step 1: Create a Spring Boot Project"></a>Step 1: Create a Spring Boot Project</h3><p>Create a new Spring Boot project using Spring Initializr or your preferred IDE. Include the following dependencies:</p>
<ul>
<li>Spring for Apache Kafka</li>
<li>Spring Data Elasticsearch</li>
<li>Spring for Apache Spark</li>
</ul>
<h3 id="Step-2-Configure-Application-Properties"><a href="#Step-2-Configure-Application-Properties" class="headerlink" title="Step 2: Configure Application Properties"></a>Step 2: Configure Application Properties</h3><p>Configure the application properties for Kafka, Elasticsearch, and MinIO:</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Kafka Configuration</span></span><br><span class="line"><span class="attr">spring.kafka.bootstrap-servers</span>=<span class="string">localhost:9092</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.group-id</span>=<span class="string">my-group</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.key-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line"><span class="attr">spring.kafka.consumer.value-deserializer</span>=<span class="string">org.apache.kafka.common.serialization.ByteArrayDeserializer</span></span><br><span class="line"><span class="attr">spring.kafka.producer.key-serializer</span>=<span class="string">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class="line"><span class="attr">spring.kafka.producer.value-serializer</span>=<span class="string">org.apache.kafka.common.serialization.ByteArraySerializer</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Schema Registry Configuration</span></span><br><span class="line"><span class="attr">schema.registry.url</span>=<span class="string">http://localhost:8081</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Elasticsearch Configuration</span></span><br><span class="line"><span class="attr">spring.elasticsearch.rest.uris</span>=<span class="string">http://localhost:9200</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># MinIO Configuration</span></span><br><span class="line"><span class="attr">minio.endpoint</span>=<span class="string">http://localhost:9000</span></span><br><span class="line"><span class="attr">minio.accessKey</span>=<span class="string">your-access-key</span></span><br><span class="line"><span class="attr">minio.secretKey</span>=<span class="string">your-secret-key</span></span><br><span class="line"><span class="attr">minio.bucket</span>=<span class="string">your-bucket</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="integrating-spark-with-spring-boot"></a></p>
<h2 id="Integrating-Spark-with-Spring-Boot"><a href="#Integrating-Spark-with-Spring-Boot" class="headerlink" title="Integrating Spark with Spring Boot"></a>Integrating Spark with Spring Boot</h2><h3 id="Step-1-Add-Spark-Dependencies"><a href="#Step-1-Add-Spark-Dependencies" class="headerlink" title="Step 1: Add Spark Dependencies"></a>Step 1: Add Spark Dependencies</h3><p>Add the following dependencies to your <code>pom.xml</code> or <code>build.gradle</code> file:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-core_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-avro_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql-kafka-0-10_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.confluent<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-avro-serializer<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Step-2-Configure-Spark"><a href="#Step-2-Configure-Spark" class="headerlink" title="Step 2: Configure Spark"></a>Step 2: Configure Spark</h3><p>Configure Spark in your Spring Boot application using annotation-style configuration:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> SparkSession <span class="title function_">sparkSession</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> SparkSession.builder()</span><br><span class="line">                .appName(<span class="string">&quot;SparkSpringBootApp&quot;</span>)</span><br><span class="line">                .master(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line">                .config(<span class="string">&quot;spark.sql.shuffle.partitions&quot;</span>, <span class="string">&quot;10&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="communicating-with-kafka"></a></p>
<h2 id="Communicating-with-Kafka"><a href="#Communicating-with-Kafka" class="headerlink" title="Communicating with Kafka"></a>Communicating with Kafka</h2><p><a name="reading-avro-records-from-kafka"></a></p>
<h3 id="Reading-Avro-Records-from-Kafka"><a href="#Reading-Avro-Records-from-Kafka" class="headerlink" title="Reading Avro Records from Kafka"></a>Reading Avro Records from Kafka</h3><p>To read Avro records from Kafka, use the <code>spark-avro</code> and <code>spark-sql-kafka-0-10</code> libraries:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Dataset&lt;Row&gt; <span class="title function_">readAvroFromKafka</span><span class="params">(String topic)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sparkSession.read()</span><br><span class="line">                .format(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;kafka.bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;subscribe&quot;</span>, topic)</span><br><span class="line">                .load()</span><br><span class="line">                .selectExpr(<span class="string">&quot;CAST(value AS BINARY)&quot;</span>)</span><br><span class="line">                .select(org.apache.spark.sql.avro.functions.from_avro(col(<span class="string">&quot;value&quot;</span>), <span class="string">&quot;your_avro_schema&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p><a name="reading-avro-records-from-kafka-with-schema-registry"></a></p>
<h3 id="Reading-Avro-Records-from-Kafka-with-Schema-Registry"><a href="#Reading-Avro-Records-from-Kafka-with-Schema-Registry" class="headerlink" title="Reading Avro Records from Kafka with Schema Registry"></a>Reading Avro Records from Kafka with Schema Registry</h3><p>To read Avro records from Kafka using the Schema Registry, use the <code>spark-avro</code> and <code>spark-sql-kafka-0-10</code> libraries:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;schema.registry.url&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String schemaRegistryUrl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Dataset&lt;Row&gt; <span class="title function_">readAvroFromKafka</span><span class="params">(String topic)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sparkSession.read()</span><br><span class="line">                .format(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;kafka.bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;subscribe&quot;</span>, topic)</span><br><span class="line">                .load()</span><br><span class="line">                .selectExpr(<span class="string">&quot;CAST(value AS BINARY)&quot;</span>)</span><br><span class="line">                .select(org.apache.spark.sql.avro.functions.from_avro(col(<span class="string">&quot;value&quot;</span>), schemaRegistryUrl + <span class="string">&quot;/subjects/&quot;</span> + topic + <span class="string">&quot;-value/versions/latest&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="writing-data-to-kafka"></a></p>
<h3 id="Writing-Data-to-Kafka"><a href="#Writing-Data-to-Kafka" class="headerlink" title="Writing Data to Kafka"></a>Writing Data to Kafka</h3><p>To write data to Kafka, use the <code>spark-sql-kafka-0-10</code> library:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeToKafka</span><span class="params">(Dataset&lt;Row&gt; dataset, String topic)</span> &#123;</span><br><span class="line">        dataset.selectExpr(<span class="string">&quot;to_json(struct(*)) AS value&quot;</span>)</span><br><span class="line">                .write()</span><br><span class="line">                .format(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;kafka.bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;topic&quot;</span>, topic)</span><br><span class="line">                .save();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="writing-avro-records-to-kafka-with-schema-registry"></a></p>
<h3 id="Writing-Avro-Records-to-Kafka-with-Schema-Registry"><a href="#Writing-Avro-Records-to-Kafka-with-Schema-Registry" class="headerlink" title="Writing Avro Records to Kafka with Schema Registry"></a>Writing Avro Records to Kafka with Schema Registry</h3><p>To write Avro records to Kafka using the Schema Registry, use the <code>spark-avro</code> and <code>spark-sql-kafka-0-10</code> libraries:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Value;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;schema.registry.url&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String schemaRegistryUrl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeAvroToKafka</span><span class="params">(Dataset&lt;Row&gt; dataset, String topic)</span> &#123;</span><br><span class="line">        dataset.select(org.apache.spark.sql.avro.functions.to_avro(struct(<span class="string">&quot;*&quot;</span>)).as(<span class="string">&quot;value&quot;</span>))</span><br><span class="line">                .write()</span><br><span class="line">                .format(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;kafka.bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;topic&quot;</span>, topic)</span><br><span class="line">                .option(<span class="string">&quot;schema.registry.url&quot;</span>, schemaRegistryUrl)</span><br><span class="line">                .save();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="communicating-with-elasticsearch"></a></p>
<h2 id="Communicating-with-Elasticsearch"><a href="#Communicating-with-Elasticsearch" class="headerlink" title="Communicating with Elasticsearch"></a>Communicating with Elasticsearch</h2><p><a name="reading-json-data-from-elasticsearch"></a></p>
<h3 id="Reading-JSON-Data-from-Elasticsearch"><a href="#Reading-JSON-Data-from-Elasticsearch" class="headerlink" title="Reading JSON Data from Elasticsearch"></a>Reading JSON Data from Elasticsearch</h3><p>To read JSON data from Elasticsearch, use the <code>elasticsearch-hadoop</code> library:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ElasticsearchService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Dataset&lt;Row&gt; <span class="title function_">readFromElasticsearch</span><span class="params">(String index)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sparkSession.read()</span><br><span class="line">                .format(<span class="string">&quot;org.elasticsearch.spark.sql&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;es.nodes&quot;</span>, <span class="string">&quot;localhost&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;es.port&quot;</span>, <span class="string">&quot;9200&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;es.resource&quot;</span>, index)</span><br><span class="line">                .load();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="writing-data-to-elasticsearch"></a></p>
<h3 id="Writing-Data-to-Elasticsearch"><a href="#Writing-Data-to-Elasticsearch" class="headerlink" title="Writing Data to Elasticsearch"></a>Writing Data to Elasticsearch</h3><p>To write data to Elasticsearch, use the <code>elasticsearch-hadoop</code> library:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ElasticsearchService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeToElasticsearch</span><span class="params">(Dataset&lt;Row&gt; dataset, String index)</span> &#123;</span><br><span class="line">        dataset.write()</span><br><span class="line">                .format(<span class="string">&quot;org.elasticsearch.spark.sql&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;es.nodes&quot;</span>, <span class="string">&quot;localhost&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;es.port&quot;</span>, <span class="string">&quot;9200&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;es.resource&quot;</span>, index)</span><br><span class="line">                .save();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="handling-parquet-files-in-minio"></a></p>
<h2 id="Handling-Parquet-Files-in-MinIO"><a href="#Handling-Parquet-Files-in-MinIO" class="headerlink" title="Handling Parquet Files in MinIO"></a>Handling Parquet Files in MinIO</h2><p><a name="reading-parquet-files-from-minio"></a></p>
<h3 id="Reading-Parquet-Files-from-MinIO"><a href="#Reading-Parquet-Files-from-MinIO" class="headerlink" title="Reading Parquet Files from MinIO"></a>Reading Parquet Files from MinIO</h3><p>To read Parquet files from MinIO, use the <code>spark-hadoop-cloud</code> library:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MinIOService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Dataset&lt;Row&gt; <span class="title function_">readParquetFromMinIO</span><span class="params">(String bucket, String path)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sparkSession.read()</span><br><span class="line">                .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.endpoint&quot;</span>, <span class="string">&quot;http://localhost:9000&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.access.key&quot;</span>, <span class="string">&quot;your-access-key&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.secret.key&quot;</span>, <span class="string">&quot;your-secret-key&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.path.style.access&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .load(<span class="string">&quot;s3a://&quot;</span> + bucket + <span class="string">&quot;/&quot;</span> + path);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="writing-parquet-files-to-minio"></a> </p>
<h3 id="Writing-Parquet-Files-to-MinIO"><a href="#Writing-Parquet-Files-to-MinIO" class="headerlink" title="Writing Parquet Files to MinIO"></a>Writing Parquet Files to MinIO</h3><p>To write Parquet files to MinIO, use the <code>spark-hadoop-cloud</code> library:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MinIOService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeParquetToMinIO</span><span class="params">(Dataset&lt;Row&gt; dataset, String bucket, String path)</span> &#123;</span><br><span class="line">        dataset.write()</span><br><span class="line">                .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.endpoint&quot;</span>, <span class="string">&quot;http://localhost:9000&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.access.key&quot;</span>, <span class="string">&quot;your-access-key&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.secret.key&quot;</span>, <span class="string">&quot;your-secret-key&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;spark.hadoop.fs.s3a.path.style.access&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .save(<span class="string">&quot;s3a://&quot;</span> + bucket + <span class="string">&quot;/&quot;</span> + path);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="using-spark-dataframe-and-spark-sql"></a></p>
<h2 id="Using-Spark-DataFrame-and-Spark-SQL"><a href="#Using-Spark-DataFrame-and-Spark-SQL" class="headerlink" title="Using Spark DataFrame and Spark SQL"></a>Using Spark DataFrame and Spark SQL</h2><p><a name="creating-dataframes"></a></p>
<h3 id="Creating-DataFrames"><a href="#Creating-DataFrames" class="headerlink" title="Creating DataFrames"></a>Creating DataFrames</h3><p>To create DataFrames, use the <code>SparkSession</code> object:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataFrameService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Dataset&lt;Row&gt; <span class="title function_">createDataFrame</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sparkSession.read()</span><br><span class="line">                .format(<span class="string">&quot;csv&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;header&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">                .load(<span class="string">&quot;path/to/csv/file&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="querying-dataframes-with-spark-sql"></a></p>
<h3 id="Querying-DataFrames-with-Spark-SQL"><a href="#Querying-DataFrames-with-Spark-SQL" class="headerlink" title="Querying DataFrames with Spark SQL"></a>Querying DataFrames with Spark SQL</h3><p>To query DataFrames using Spark SQL, register the DataFrame as a temporary view:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataFrameService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Dataset&lt;Row&gt; <span class="title function_">queryDataFrame</span><span class="params">(Dataset&lt;Row&gt; df)</span> &#123;</span><br><span class="line">        df.createOrReplaceTempView(<span class="string">&quot;my_table&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> sparkSession.sql(<span class="string">&quot;SELECT * FROM my_table WHERE column = &#x27;value&#x27;&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="unit-test-cases"></a></p>
<h2 id="Unit-Test-Cases"><a href="#Unit-Test-Cases" class="headerlink" title="Unit Test Cases"></a>Unit Test Cases</h2><h3 id="KafkaServiceTest-java"><a href="#KafkaServiceTest-java" class="headerlink" title="KafkaServiceTest.java"></a>KafkaServiceTest.java</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.jupiter.api.Assertions.assertNotNull;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaServiceTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaService kafkaService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testReadAvroFromKafka</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = kafkaService.readAvroFromKafka(<span class="string">&quot;test-topic&quot;</span>);</span><br><span class="line">        assertNotNull(dataset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testWriteAvroToKafka</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = sparkSession.read().json(<span class="string">&quot;path/to/json/file&quot;</span>);</span><br><span class="line">        kafkaService.writeAvroToKafka(dataset, <span class="string">&quot;test-topic&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="ElasticsearchServiceTest-java"><a href="#ElasticsearchServiceTest-java" class="headerlink" title="ElasticsearchServiceTest.java"></a>ElasticsearchServiceTest.java</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.jupiter.api.Assertions.assertNotNull;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ElasticsearchServiceTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ElasticsearchService elasticsearchService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testReadFromElasticsearch</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = elasticsearchService.readFromElasticsearch(<span class="string">&quot;test-index&quot;</span>);</span><br><span class="line">        assertNotNull(dataset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testWriteToElasticsearch</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = sparkSession.read().json(<span class="string">&quot;path/to/json/file&quot;</span>);</span><br><span class="line">        elasticsearchService.writeToElasticsearch(dataset, <span class="string">&quot;test-index&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="MinIOServiceTest-java"><a href="#MinIOServiceTest-java" class="headerlink" title="MinIOServiceTest.java"></a>MinIOServiceTest.java</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.jupiter.api.Assertions.assertNotNull;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MinIOServiceTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> MinIOService minIOService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testReadParquetFromMinIO</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = minIOService.readParquetFromMinIO(<span class="string">&quot;test-bucket&quot;</span>, <span class="string">&quot;test-path&quot;</span>);</span><br><span class="line">        assertNotNull(dataset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testWriteParquetToMinIO</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = sparkSession.read().json(<span class="string">&quot;path/to/json/file&quot;</span>);</span><br><span class="line">        minIOService.writeParquetToMinIO(dataset, <span class="string">&quot;test-bucket&quot;</span>, <span class="string">&quot;test-path&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="DataFrameServiceTest-java"><a href="#DataFrameServiceTest-java" class="headerlink" title="DataFrameServiceTest.java"></a>DataFrameServiceTest.java</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.jupiter.api.Assertions.assertNotNull;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataFrameServiceTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> DataFrameService dataFrameService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCreateDataFrame</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = dataFrameService.createDataFrame();</span><br><span class="line">        assertNotNull(dataset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testQueryDataFrame</span><span class="params">()</span> &#123;</span><br><span class="line">        Dataset&lt;Row&gt; dataset = sparkSession.read().json(<span class="string">&quot;path/to/json/file&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; result = dataFrameService.queryDataFrame(dataset);</span><br><span class="line">        assertNotNull(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="design-diagrams"></a></p>
<h2 id="Design-Diagrams"><a href="#Design-Diagrams" class="headerlink" title="Design Diagrams"></a>Design Diagrams</h2><p><a name="component-diagram"></a></p>
<h3 id="Component-Diagram"><a href="#Component-Diagram" class="headerlink" title="Component Diagram"></a>Component Diagram</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+-------------------+       +-------------------+       +-------------------+</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">|   Spring Boot     |       |   Apache Spark    |       |   Kafka           |</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">+--------+----------+       +--------+----------+       +--------+----------+</span><br><span class="line">         |                           |                           |</span><br><span class="line">         |                           |                           |</span><br><span class="line">         v                           v                           v</span><br><span class="line">+-------------------+       +-------------------+       +-------------------+</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">|   KafkaService    |       |   Elasticsearch   |       |   MinIOService    |</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">+--------+----------+       +--------+----------+       +--------+----------+</span><br><span class="line">         |                           |                           |</span><br><span class="line">         |                           |                           |</span><br><span class="line">         v                           v                           v</span><br><span class="line">+--------------------+       +-------------------+       +---------------------------------------+</span><br><span class="line">|                    |       |                   |       |                                       |</span><br><span class="line">|   DataFrameService |       |   SparkConfig     |       |   SparkSpringBootConsoleApplication   |</span><br><span class="line">|                    |       |                   |       |                                       |</span><br><span class="line">+--------------------+       +-------------------+       +---------------------------------------+</span><br></pre></td></tr></table></figure>

<p><a name="sequence-diagram"></a></p>
<h3 id="Sequence-Diagram"><a href="#Sequence-Diagram" class="headerlink" title="Sequence Diagram"></a>Sequence Diagram</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">+---------+       +---------+       +---------+       +---------+</span><br><span class="line">|         |       |         |       |         |       |         |</span><br><span class="line">| Client  |       | Spring  |       | Spark   |       | Kafka   |</span><br><span class="line">|         |       | Boot    |       |         |       |         |</span><br><span class="line">+---------+       +---------+       +---------+       +---------+</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |  Request         |               |               |</span><br><span class="line">    |-----------------&gt;|               |               |</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |                  |  Read Avro    |               |</span><br><span class="line">    |                  |  from Kafka   |               |</span><br><span class="line">    |                  |--------------&gt;|               |</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |                  |               |  Send Avro    |</span><br><span class="line">    |                  |               |&lt;-------------&gt;|</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |                  |  Process      |               |</span><br><span class="line">    |                  |  Data         |               |</span><br><span class="line">    |                  |--------------&gt;|               |</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |                  |  Write to     |               |</span><br><span class="line">    |                  |  Elasticsearch|               |</span><br><span class="line">    |                  |--------------&gt;|               |</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |                  |  Write to     |               |</span><br><span class="line">    |                  |  MinIO        |               |</span><br><span class="line">    |                  |--------------&gt;|               |</span><br><span class="line">    |                  |               |               |</span><br><span class="line">    |  Response        |               |               |</span><br><span class="line">    |&lt;-----------------|               |               |</span><br><span class="line">    |                  |               |               |</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="advanced-scenarios"></a></p>
<h2 id="Advanced-Scenarios"><a href="#Advanced-Scenarios" class="headerlink" title="Advanced Scenarios"></a>Advanced Scenarios</h2><p><a name="complex-scenario-1-flow-control-and-backpressure-handling"></a></p>
<h3 id="Complex-Scenario-1-Flow-Control-and-Backpressure-Handling"><a href="#Complex-Scenario-1-Flow-Control-and-Backpressure-Handling" class="headerlink" title="Complex Scenario 1: Flow Control and Backpressure Handling"></a>Complex Scenario 1: Flow Control and Backpressure Handling</h3><p>In scenarios where your application needs to handle flow control and backpressure, you can use Spark’s built-in mechanisms for handling large-scale data processing.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowControlService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">handleFlowControl</span><span class="params">(Dataset&lt;Row&gt; dataset)</span> &#123;</span><br><span class="line">        dataset.writeStream()</span><br><span class="line">                .format(<span class="string">&quot;console&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;checkpointLocation&quot;</span>, <span class="string">&quot;path/to/checkpoint&quot;</span>)</span><br><span class="line">                .start()</span><br><span class="line">                .awaitTermination();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="complex-scenario-2-handling-large-scale-data-processing"></a></p>
<h3 id="Complex-Scenario-2-Handling-Large-Scale-Data-Processing"><a href="#Complex-Scenario-2-Handling-Large-Scale-Data-Processing" class="headerlink" title="Complex Scenario 2: Handling Large-Scale Data Processing"></a>Complex Scenario 2: Handling Large-Scale Data Processing</h3><p>For large-scale data processing, use Spark’s distributed processing capabilities and optimize resource usage.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LargeScaleProcessingService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> SparkSession sparkSession;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processLargeScaleData</span><span class="params">(Dataset&lt;Row&gt; dataset)</span> &#123;</span><br><span class="line">        dataset.repartition(<span class="number">100</span>)</span><br><span class="line">                .write()</span><br><span class="line">                .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">                .save(<span class="string">&quot;path/to/output&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Developing a Spark application with Spring Boot 3.3.5 to communicate with Kafka and Elasticsearch involves setting up the Spring Boot application, integrating Spark, and handling data using Spark DataFrame and Spark SQL. By following the best practices outlined in this article, you can create efficient and scalable data processing applications.</p>
<hr>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/">Spring Boot Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/">Apache Spark Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/">Apache Kafka Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Elasticsearch Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.min.io/">MinIO Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.confluent.io/platform/current/schema-registry/index.html">Confluent Schema Registry Documentation</a></li>
</ol>
<p>By following these best practices, you can leverage Spark and Spring Boot to build powerful and scalable data processing applications.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Spring-Boot/" rel="tag"><i class="fa fa-tag"></i> Spring Boot</a>
              <a href="/tags/Elasticsearch/" rel="tag"><i class="fa fa-tag"></i> Elasticsearch</a>
              <a href="/tags/Kafka/" rel="tag"><i class="fa fa-tag"></i> Kafka</a>
              <a href="/tags/Spark/" rel="tag"><i class="fa fa-tag"></i> Spark</a>
              <a href="/tags/Big-Data/" rel="tag"><i class="fa fa-tag"></i> Big Data</a>
              <a href="/tags/Minio/" rel="tag"><i class="fa fa-tag"></i> Minio</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/11/03/Best-Practices-of-Using-Docker-in-Application-Development/" rel="prev" title="Best Practices of Using Docker in Application Development">
                  <i class="fa fa-angle-left"></i> Best Practices of Using Docker in Application Development
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/11/04/Best-Practices-for-Java-8-Lambda-Expressions/" rel="next" title="Best Practices for Java 8 Lambda Expressions">
                  Best Practices for Java 8 Lambda Expressions <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Dazhi Zhang</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.1/mermaid.min.js","integrity":"sha256-YbM1pG3wWnzhyYN49g5fPnen+2CKEFaZfopkkwSpNtY="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
