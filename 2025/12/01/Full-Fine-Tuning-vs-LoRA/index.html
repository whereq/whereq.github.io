<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.whereq.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Table of Contents Introduction What is Fine-Tuning? Full Fine-Tuning Explained LoRA (Low-Rank Adaptation) Explained Technical Comparison Real-World Use Cases When to Use Which Method Hands-On Practice">
<meta property="og:type" content="article">
<meta property="og:title" content="Full Fine-Tuning vs LoRA">
<meta property="og:url" content="https://www.whereq.com/2025/12/01/Full-Fine-Tuning-vs-LoRA/index.html">
<meta property="og:site_name" content="WhereQ">
<meta property="og:description" content="Table of Contents Introduction What is Fine-Tuning? Full Fine-Tuning Explained LoRA (Low-Rank Adaptation) Explained Technical Comparison Real-World Use Cases When to Use Which Method Hands-On Practice">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-12-01T19:37:04.000Z">
<meta property="article:modified_time" content="2025-12-01T19:43:37.472Z">
<meta property="article:author" content="Dazhi Zhang">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LoRA">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.whereq.com/2025/12/01/Full-Fine-Tuning-vs-LoRA/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://www.whereq.com/2025/12/01/Full-Fine-Tuning-vs-LoRA/","path":"2025/12/01/Full-Fine-Tuning-vs-LoRA/","title":"Full Fine-Tuning vs LoRA"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Full Fine-Tuning vs LoRA | WhereQ</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">WhereQ</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-articles"><a href="/articles/" rel="section"><i class="fa fa-file fa-fw"></i>Articles</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Table-of-Contents"><span class="nav-number">1.</span> <span class="nav-text">Table of Contents</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#What-is-Fine-Tuning"><span class="nav-number">3.</span> <span class="nav-text">What is Fine-Tuning?</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Simple-Analogy"><span class="nav-number">3.1.</span> <span class="nav-text">Simple Analogy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Technical-Definition"><span class="nav-number">3.2.</span> <span class="nav-text">Technical Definition</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Full-Fine-Tuning-Explained"><span class="nav-number">4.</span> <span class="nav-text">Full Fine-Tuning Explained</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-Full-Fine-Tuning"><span class="nav-number">4.1.</span> <span class="nav-text">What is Full Fine-Tuning?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-It-Works"><span class="nav-number">4.2.</span> <span class="nav-text">How It Works</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Advantages-%E2%9C%85"><span class="nav-number">4.3.</span> <span class="nav-text">Advantages âœ…</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Disadvantages-%E2%9D%8C"><span class="nav-number">4.4.</span> <span class="nav-text">Disadvantages âŒ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Real-World-Example"><span class="nav-number">4.5.</span> <span class="nav-text">Real-World Example</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LoRA-Low-Rank-Adaptation-Explained"><span class="nav-number">5.</span> <span class="nav-text">LoRA (Low-Rank Adaptation) Explained</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-LoRA"><span class="nav-number">5.1.</span> <span class="nav-text">What is LoRA?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visual-Explanation"><span class="nav-number">5.2.</span> <span class="nav-text">Visual Explanation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mathematical-Foundation"><span class="nav-number">5.3.</span> <span class="nav-text">Mathematical Foundation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-LoRA-Works-Step-by-Step"><span class="nav-number">5.4.</span> <span class="nav-text">How LoRA Works (Step-by-Step)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Advantages-%E2%9C%85-1"><span class="nav-number">5.5.</span> <span class="nav-text">Advantages âœ…</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Disadvantages-%E2%9D%8C-1"><span class="nav-number">5.6.</span> <span class="nav-text">Disadvantages âŒ</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Real-World-Examples"><span class="nav-number">5.7.</span> <span class="nav-text">Real-World Examples</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Technical-Comparison"><span class="nav-number">6.</span> <span class="nav-text">Technical Comparison</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Architecture-Comparison"><span class="nav-number">6.1.</span> <span class="nav-text">Architecture Comparison</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Detailed-Comparison-Table"><span class="nav-number">6.2.</span> <span class="nav-text">Detailed Comparison Table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Memory-Comparison-7B-Model-Example"><span class="nav-number">6.3.</span> <span class="nav-text">Memory Comparison (7B Model Example)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Real-World-Use-Cases"><span class="nav-number">7.</span> <span class="nav-text">Real-World Use Cases</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Case-1-Healthcare-Clinical-Note-Generation"><span class="nav-number">7.1.</span> <span class="nav-text">Use Case 1: Healthcare - Clinical Note Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Case-2-Legal-Contract-Analysis"><span class="nav-number">7.2.</span> <span class="nav-text">Use Case 2: Legal - Contract Analysis</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Case-3-E-Commerce-Multi-Category-Product-Descriptions"><span class="nav-number">7.3.</span> <span class="nav-text">Use Case 3: E-Commerce - Multi-Category Product Descriptions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Use-Case-4-Multilingual-Customer-Support"><span class="nav-number">7.4.</span> <span class="nav-text">Use Case 4: Multilingual Customer Support</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#When-to-Use-Which-Method"><span class="nav-number">8.</span> <span class="nav-text">When to Use Which Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Choose-Full-Fine-Tuning-When"><span class="nav-number">8.1.</span> <span class="nav-text">Choose Full Fine-Tuning When:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Choose-LoRA-When"><span class="nav-number">8.2.</span> <span class="nav-text">Choose LoRA When:</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hands-On-Practice-Guide"><span class="nav-number">9.</span> <span class="nav-text">Hands-On Practice Guide</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Prerequisites"><span class="nav-number">9.1.</span> <span class="nav-text">Prerequisites</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Practice-1-Full-Fine-Tuning-Small-Model"><span class="nav-number">9.2.</span> <span class="nav-text">Practice 1: Full Fine-Tuning (Small Model)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Practice-2-LoRA-Fine-Tuning-Large-Model"><span class="nav-number">9.3.</span> <span class="nav-text">Practice 2: LoRA Fine-Tuning (Large Model)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Practice-3-Comparing-LoRA-Ranks"><span class="nav-number">9.4.</span> <span class="nav-text">Practice 3: Comparing LoRA Ranks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Advanced-Topics"><span class="nav-number">10.</span> <span class="nav-text">Advanced Topics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-QLoRA-Quantized-LoRA"><span class="nav-number">10.1.</span> <span class="nav-text">1. QLoRA (Quantized LoRA)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-AdaLoRA-Adaptive-LoRA"><span class="nav-number">10.2.</span> <span class="nav-text">2. AdaLoRA (Adaptive LoRA)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-The-%E2%80%9CIntruder-Dimensions%E2%80%9D-Problem"><span class="nav-number">10.3.</span> <span class="nav-text">3. The â€œIntruder Dimensionsâ€ Problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Multi-Adapter-Architecture"><span class="nav-number">10.4.</span> <span class="nav-text">4. Multi-Adapter Architecture</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Decision-Framework"><span class="nav-number">11.</span> <span class="nav-text">Decision Framework</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Complete-Decision-Tree"><span class="nav-number">11.1.</span> <span class="nav-text">The Complete Decision Tree</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Quick-Selection-Matrix"><span class="nav-number">11.2.</span> <span class="nav-text">Quick Selection Matrix</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Best-Practices-Tips"><span class="nav-number">12.</span> <span class="nav-text">Best Practices &amp; Tips</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#For-LoRA-Fine-Tuning"><span class="nav-number">12.1.</span> <span class="nav-text">For LoRA Fine-Tuning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#For-Full-Fine-Tuning"><span class="nav-number">12.2.</span> <span class="nav-text">For Full Fine-Tuning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Common-Mistakes-How-to-Avoid-Them"><span class="nav-number">13.</span> <span class="nav-text">Common Mistakes &amp; How to Avoid Them</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Mistake-1-Using-LoRA-rank-that%E2%80%99s-too-low"><span class="nav-number">13.1.</span> <span class="nav-text">Mistake 1: Using LoRA rank thatâ€™s too low</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mistake-2-Wrong-learning-rate"><span class="nav-number">13.2.</span> <span class="nav-text">Mistake 2: Wrong learning rate</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mistake-3-Not-quantizing-when-memory-is-tight"><span class="nav-number">13.3.</span> <span class="nav-text">Mistake 3: Not quantizing when memory is tight</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mistake-4-Training-on-too-few-examples"><span class="nav-number">13.4.</span> <span class="nav-text">Mistake 4: Training on too few examples</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mistake-5-Not-saving-checkpoints"><span class="nav-number">13.5.</span> <span class="nav-text">Mistake 5: Not saving checkpoints</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Real-Cost-Comparison"><span class="nav-number">14.</span> <span class="nav-text">Real Cost Comparison</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Example-Fine-tuning-LLaMA-2-7B-for-3-epochs-on-10-000-examples"><span class="nav-number">14.1.</span> <span class="nav-text">Example: Fine-tuning LLaMA-2-7B for 3 epochs on 10,000 examples</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Latest-Research-Trends-2024-2025"><span class="nav-number">15.</span> <span class="nav-text">Latest Research &amp; Trends (2024-2025)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-LoRA-and-LoRA-FA"><span class="nav-number">15.1.</span> <span class="nav-text">1. LoRA+ and LoRA-FA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-DoRA-Weight-Decomposed-LoRA"><span class="nav-number">15.2.</span> <span class="nav-text">2. DoRA (Weight-Decomposed LoRA)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-MultiLoRA-LoRA-Composition"><span class="nav-number">15.3.</span> <span class="nav-text">3. MultiLoRA &amp; LoRA Composition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-LoRA-for-Vision-Multimodal-Models"><span class="nav-number">15.4.</span> <span class="nav-text">4. LoRA for Vision &amp; Multimodal Models</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary-Recommendations"><span class="nav-number">16.</span> <span class="nav-text">Summary &amp; Recommendations</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Bottom-Line"><span class="nav-number">16.1.</span> <span class="nav-text">The Bottom Line</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Your-Action-Plan"><span class="nav-number">16.2.</span> <span class="nav-text">Your Action Plan</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Additional-Resources"><span class="nav-number">17.</span> <span class="nav-text">Additional Resources</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Code-Repositories"><span class="nav-number">17.1.</span> <span class="nav-text">Code Repositories</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tutorials"><span class="nav-number">17.2.</span> <span class="nav-text">Tutorials</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Communities"><span class="nav-number">17.3.</span> <span class="nav-text">Communities</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Dazhi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">140</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">126</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">83</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2025/12/01/Full-Fine-Tuning-vs-LoRA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Full Fine-Tuning vs LoRA | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Full Fine-Tuning vs LoRA
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-01 14:37:04 / Modified: 14:43:37" itemprop="dateCreated datePublished" datetime="2025-12-01T14:37:04-05:00">2025-12-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LoRA/" itemprop="url" rel="index"><span itemprop="name">LoRA</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LoRA/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/LoRA/AI/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h2><ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#what-is-fine-tuning">What is Fine-Tuning?</a></li>
<li><a href="#full-fine-tuning-explained">Full Fine-Tuning Explained</a></li>
<li><a href="#lora-low-rank-adaptation-explained">LoRA (Low-Rank Adaptation) Explained</a></li>
<li><a href="#technical-comparison">Technical Comparison</a></li>
<li><a href="#real-world-use-cases">Real-World Use Cases</a></li>
<li><a href="#when-to-use-which-method">When to Use Which Method</a></li>
<li><a href="#hands-on-practice-guide">Hands-On Practice Guide</a></li>
<li><a href="#advanced-topics">Advanced Topics</a></li>
<li><a href="#decision-framework">Decision Framework</a></li>
</ol>
<hr>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In the era of Large Language Models (LLMs), <strong>fine-tuning</strong> has become the key to adapting pre-trained models to specific tasks. Two main approaches dominate the landscape:</p>
<ul>
<li><strong>Full Fine-Tuning</strong>: Training all model parameters</li>
<li><strong>LoRA (Low-Rank Adaptation)</strong>: Training only a small subset of parameters</li>
</ul>
<hr>
<h2 id="What-is-Fine-Tuning"><a href="#What-is-Fine-Tuning" class="headerlink" title="What is Fine-Tuning?"></a>What is Fine-Tuning?</h2><h3 id="Simple-Analogy"><a href="#Simple-Analogy" class="headerlink" title="Simple Analogy"></a>Simple Analogy</h3><p>Think of a pre-trained model as a <strong>medical doctor with general knowledge</strong>. Fine-tuning is like:</p>
<ul>
<li><strong>Full Fine-Tuning</strong>: Sending the doctor back to medical school to relearn everything with a focus on a specialty</li>
<li><strong>LoRA</strong>: Giving the doctor a specialized handbook they can reference without forgetting their general knowledge</li>
</ul>
<h3 id="Technical-Definition"><a href="#Technical-Definition" class="headerlink" title="Technical Definition"></a>Technical Definition</h3><p>Fine-tuning takes a pre-trained model (trained on massive general data) and continues training it on domain-specific data to improve performance on particular tasks.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Pre-trained Model (General Knowledge)</span><br><span class="line">         â†“</span><br><span class="line">    Fine-Tuning (Specialized Training)</span><br><span class="line">         â†“</span><br><span class="line">Task-Specific Model (Expert Knowledge)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Full-Fine-Tuning-Explained"><a href="#Full-Fine-Tuning-Explained" class="headerlink" title="Full Fine-Tuning Explained"></a>Full Fine-Tuning Explained</h2><h3 id="What-is-Full-Fine-Tuning"><a href="#What-is-Full-Fine-Tuning" class="headerlink" title="What is Full Fine-Tuning?"></a>What is Full Fine-Tuning?</h3><p>Full fine-tuning means <strong>updating ALL parameters</strong> in the model during training.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Model Architecture (Example: 7B parameters)</span><br><span class="line">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><br><span class="line">â”‚  Layer 1: [All parameters trainable]â”‚ â† Updated</span><br><span class="line">â”‚  Layer 2: [All parameters trainable]â”‚ â† Updated</span><br><span class="line">â”‚  Layer 3: [All parameters trainable]â”‚ â† Updated</span><br><span class="line">â”‚  ...                                 â”‚ â† Updated</span><br><span class="line">â”‚  Layer N: [All parameters trainable]â”‚ â† Updated</span><br><span class="line">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><br><span class="line">Total Trainable: 7,000,000,000 params</span><br></pre></td></tr></table></figure>

<h3 id="How-It-Works"><a href="#How-It-Works" class="headerlink" title="How It Works"></a>How It Works</h3><ol>
<li><strong>Load pre-trained model</strong> (e.g., GPT-3, LLaMA, ChatGLM)</li>
<li><strong>Prepare task-specific dataset</strong> (e.g., medical Q&amp;A, legal documents)</li>
<li><strong>Train ALL parameters</strong> using your dataset</li>
<li><strong>Save the entire model</strong> (full 7B+ parameters)</li>
</ol>
<h3 id="Advantages-âœ…"><a href="#Advantages-âœ…" class="headerlink" title="Advantages âœ…"></a>Advantages âœ…</h3><ol>
<li><strong>Maximum Performance</strong>: Can achieve the best possible results</li>
<li><strong>Deep Customization</strong>: All parameters adapt to your specific task</li>
<li><strong>Flexible</strong>: Works for any task, especially those very different from pre-training</li>
</ol>
<h3 id="Disadvantages-âŒ"><a href="#Disadvantages-âŒ" class="headerlink" title="Disadvantages âŒ"></a>Disadvantages âŒ</h3><ol>
<li><p><strong>Extremely High Cost</strong>:</p>
<ul>
<li>GPT-3 175B full fine-tuning requires <strong>&gt;2TB GPU memory</strong></li>
<li>Needs high-end GPU clusters (multiple A100s)</li>
<li>Training can cost <strong>$20,000+</strong> per run</li>
</ul>
</li>
<li><p><strong>Long Training Time</strong>: Days or weeks to complete</p>
</li>
<li><p><strong>Storage Overhead</strong>: </p>
<ul>
<li>Each task needs a complete model copy</li>
<li>7B model &#x3D; ~14GB storage per task</li>
<li>10 tasks &#x3D; 140GB storage needed</li>
</ul>
</li>
<li><p><strong>Catastrophic Forgetting</strong>:</p>
<ul>
<li>Model may lose general knowledge</li>
<li>Reduced generalization ability</li>
</ul>
</li>
</ol>
<h3 id="Real-World-Example"><a href="#Real-World-Example" class="headerlink" title="Real-World Example"></a>Real-World Example</h3><p><strong>Googleâ€™s Multilingual Search Optimization</strong></p>
<ul>
<li>Used full fine-tuning on BERT-Large for multilingual search</li>
<li>Result: 25% improvement in low-resource language recall</li>
<li>Cost: Requires massive GPU infrastructure</li>
<li>Benefit: State-of-the-art performance across 100+ languages</li>
</ul>
<hr>
<h2 id="LoRA-Low-Rank-Adaptation-Explained"><a href="#LoRA-Low-Rank-Adaptation-Explained" class="headerlink" title="LoRA (Low-Rank Adaptation) Explained"></a>LoRA (Low-Rank Adaptation) Explained</h2><h3 id="What-is-LoRA"><a href="#What-is-LoRA" class="headerlink" title="What is LoRA?"></a>What is LoRA?</h3><p>LoRA is a <strong>parameter-efficient fine-tuning</strong> method proposed by Microsoft in 2021. Instead of updating all parameters, LoRA:</p>
<ul>
<li><strong>Freezes</strong> the original model weights</li>
<li><strong>Adds small â€œadapterâ€ matrices</strong> to specific layers</li>
<li><strong>Trains only</strong> these tiny adapters (typically 0.1%-1% of total parameters)</li>
</ul>
<h3 id="Visual-Explanation"><a href="#Visual-Explanation" class="headerlink" title="Visual Explanation"></a>Visual Explanation</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Original Transformer Layer</span><br><span class="line">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><br><span class="line">â”‚  Pre-trained Weight Matrix W           â”‚</span><br><span class="line">â”‚  [Frozen - Not Updated]                â”‚</span><br><span class="line">â”‚          +                             â”‚</span><br><span class="line">â”‚  Low-Rank Adapter: A Ã— B               â”‚</span><br><span class="line">â”‚  [Trainable - Only These Updated]      â”‚</span><br><span class="line">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><br><span class="line"></span><br><span class="line">Output = WÂ·x + AÂ·BÂ·x</span><br><span class="line">         â†‘      â†‘</span><br><span class="line">      Frozen  Trained (tiny!)</span><br></pre></td></tr></table></figure>

<h3 id="Mathematical-Foundation"><a href="#Mathematical-Foundation" class="headerlink" title="Mathematical Foundation"></a>Mathematical Foundation</h3><p>For a pre-trained weight matrix <strong>W</strong> (dimension d Ã— k):</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Full Fine-Tuning:</span><br><span class="line">  Updates: Î”W (d Ã— k parameters)</span><br><span class="line">  Total trainable: d Ã— k</span><br><span class="line"></span><br><span class="line">LoRA:</span><br><span class="line">  Decomposes: Î”W â‰ˆ A Ã— B</span><br><span class="line">  Where: A is (d Ã— r), B is (r Ã— k)</span><br><span class="line">  Total trainable: dÃ—r + rÃ—k</span><br><span class="line">  </span><br><span class="line">Example (d=4096, k=4096, r=8):</span><br><span class="line">  Full: 4096 Ã— 4096 = 16,777,216 params</span><br><span class="line">  LoRA: 4096Ã—8 + 8Ã—4096 = 65,536 params</span><br><span class="line">  Reduction: 99.6%! ğŸ‰</span><br></pre></td></tr></table></figure>

<h3 id="How-LoRA-Works-Step-by-Step"><a href="#How-LoRA-Works-Step-by-Step" class="headerlink" title="How LoRA Works (Step-by-Step)"></a>How LoRA Works (Step-by-Step)</h3><ol>
<li><p><strong>Freeze Original Model</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for param in pretrained_model.parameters():</span><br><span class="line">    param.requires_grad = False  # Don&#x27;t update these</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Inject Low-Rank Matrices</strong></p>
<ul>
<li>Insert matrices A and B into attention layers</li>
<li>Initialize: A with random values, B with zeros</li>
<li>Typically apply to Query, Value projection matrices</li>
</ul>
</li>
<li><p><strong>Train Only Adapters</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for param in lora_adapters.parameters():</span><br><span class="line">    param.requires_grad = True  # Only update these</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Inference</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = original_weight @ x + (A @ B) @ x</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Advantages-âœ…-1"><a href="#Advantages-âœ…-1" class="headerlink" title="Advantages âœ…"></a>Advantages âœ…</h3><ol>
<li><p><strong>Extreme Parameter Efficiency</strong>:</p>
<ul>
<li>Reduces trainable parameters by <strong>90-99%</strong></li>
<li>7B model: Train only 7-70M parameters instead of 7B</li>
</ul>
</li>
<li><p><strong>Low Cost, Fast Deployment</strong>:</p>
<ul>
<li>Consumer GPU (RTX 4090, RTX 3090) can fine-tune large models</li>
<li>Training time: Hours instead of days</li>
<li>Cost: <strong>$50-200</strong> instead of $20,000+</li>
</ul>
</li>
<li><p><strong>Multi-Task Flexibility</strong>:</p>
<ul>
<li>Save only adapter weights (~10-100MB per task)</li>
<li>Dynamically load different adapters for different tasks</li>
<li>One base model + multiple adapters &#x3D; multiple specialized models</li>
</ul>
</li>
<li><p><strong>Less Catastrophic Forgetting</strong>:</p>
<ul>
<li>Original weights unchanged</li>
<li>Retains general knowledge better</li>
</ul>
</li>
</ol>
<h3 id="Disadvantages-âŒ-1"><a href="#Disadvantages-âŒ-1" class="headerlink" title="Disadvantages âŒ"></a>Disadvantages âŒ</h3><ol>
<li><p><strong>Rank Parameter Tuning Required</strong>:</p>
<ul>
<li>Too small <code>r</code> (rank) â†’ underfitting</li>
<li>Too large <code>r</code> â†’ loses efficiency</li>
<li>Needs experimentation</li>
</ul>
</li>
<li><p><strong>â€œIntruder Dimensionsâ€ Problem</strong> (Recent Discovery):</p>
<ul>
<li>LoRA introduces high-ranking singular vectors</li>
<li>Reduces out-of-distribution (OOD) generalization by 5-8%</li>
<li>Less robust in continual learning scenarios</li>
</ul>
</li>
<li><p><strong>Slightly Lower Peak Performance</strong>:</p>
<ul>
<li>May not reach absolute best performance</li>
<li>Gap is usually small (&lt;1-3%) for most tasks</li>
</ul>
</li>
</ol>
<h3 id="Real-World-Examples"><a href="#Real-World-Examples" class="headerlink" title="Real-World Examples"></a>Real-World Examples</h3><p><strong>1. Medical Document Summarization</strong></p>
<ul>
<li>Hospital used LoRA to fine-tune GPT-3 for medical report generation</li>
<li>Result: High-quality summaries, doctor efficiency increased 40%</li>
<li>Cost: Single RTX A6000 GPU, trained in 6 hours</li>
<li>Storage: Base model (14GB) + Adapter (50MB)</li>
</ul>
<p><strong>2. E-commerce Customer Service</strong></p>
<ul>
<li>Online retailer fine-tuned ChatGLM for customer support</li>
<li>Result: Response speed improved 3x, satisfaction up 25%</li>
<li>Deployment: 5 different product category adapters</li>
<li>Total storage: One model + 5 adapters &#x3D; 14.3GB (vs 70GB for 5 full models)</li>
</ul>
<p><strong>3. Financial News Generation</strong></p>
<ul>
<li>News agency fine-tuned GPT-3 for real-time financial reporting</li>
<li>Result: News generation latency reduced to seconds, 40% cost reduction</li>
<li>Adaptation time: 4 hours on 2Ã— RTX 4090</li>
</ul>
<hr>
<h2 id="Technical-Comparison"><a href="#Technical-Comparison" class="headerlink" title="Technical Comparison"></a>Technical Comparison</h2><h3 id="Architecture-Comparison"><a href="#Architecture-Comparison" class="headerlink" title="Architecture Comparison"></a>Architecture Comparison</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">FULL FINE-TUNING</span><br><span class="line">â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</span><br><span class="line">Input â†’ [Layer 1 âœï¸] â†’ [Layer 2 âœï¸] â†’ [Layer 3 âœï¸] â†’ Output</span><br><span class="line">        All Updated   All Updated    All Updated</span><br><span class="line"></span><br><span class="line">LoRA</span><br><span class="line">â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</span><br><span class="line">Input â†’ [Layer 1 ğŸ”’] â†’ [Layer 2 ğŸ”’] â†’ [Layer 3 ğŸ”’] â†’ Output</span><br><span class="line">        + Adapterâœï¸   + Adapterâœï¸    + Adapterâœï¸</span><br><span class="line">        </span><br><span class="line">ğŸ”’ = Frozen (unchanged)</span><br><span class="line">âœï¸ = Trainable (updated during training)</span><br></pre></td></tr></table></figure>

<h3 id="Detailed-Comparison-Table"><a href="#Detailed-Comparison-Table" class="headerlink" title="Detailed Comparison Table"></a>Detailed Comparison Table</h3><table>
<thead>
<tr>
<th>Aspect</th>
<th>Full Fine-Tuning</th>
<th>LoRA</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Trainable Parameters</strong></td>
<td>100% (e.g., 7B params)</td>
<td>0.1-1% (e.g., 7-70M params)</td>
</tr>
<tr>
<td><strong>GPU Memory</strong></td>
<td>Very High (&gt;80GB for 7B)</td>
<td>Low (24-48GB for 7B)</td>
</tr>
<tr>
<td><strong>Training Time</strong></td>
<td>Days to weeks</td>
<td>Hours to 1-2 days</td>
</tr>
<tr>
<td><strong>Cost per Training</strong></td>
<td>$10,000 - $100,000+</td>
<td>$50 - $500</td>
</tr>
<tr>
<td><strong>Storage per Task</strong></td>
<td>Full model (~14GB for 7B)</td>
<td>Adapter only (~10-100MB)</td>
</tr>
<tr>
<td><strong>Performance</strong></td>
<td>Highest (100% baseline)</td>
<td>Very High (95-99% of full)</td>
</tr>
<tr>
<td><strong>Multi-Task Deployment</strong></td>
<td>Difficult (one model per task)</td>
<td>Easy (one model + N adapters)</td>
</tr>
<tr>
<td><strong>Catastrophic Forgetting</strong></td>
<td>High risk</td>
<td>Low risk</td>
</tr>
<tr>
<td><strong>Hardware Requirements</strong></td>
<td>High-end GPU cluster (A100Ã—8)</td>
<td>Consumer GPU (RTX 3090&#x2F;4090)</td>
</tr>
<tr>
<td><strong>Generalization (OOD)</strong></td>
<td>Best</td>
<td>Good (5-8% lower)</td>
</tr>
<tr>
<td><strong>Best For</strong></td>
<td>Maximum performance, unlimited budget</td>
<td>Fast iteration, limited resources</td>
</tr>
</tbody></table>
<h3 id="Memory-Comparison-7B-Model-Example"><a href="#Memory-Comparison-7B-Model-Example" class="headerlink" title="Memory Comparison (7B Model Example)"></a>Memory Comparison (7B Model Example)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Full Fine-Tuning (7B parameters):</span><br><span class="line">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><br><span class="line">â”‚ Model: 14GB                     â”‚</span><br><span class="line">â”‚ Optimizer States: 42GB          â”‚</span><br><span class="line">â”‚ Gradients: 14GB                 â”‚</span><br><span class="line">â”‚ Activations: 20GB               â”‚</span><br><span class="line">â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚</span><br><span class="line">â”‚ Total: ~90GB                    â”‚</span><br><span class="line">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><br><span class="line">Required: 4Ã— A100 (40GB each)</span><br><span class="line"></span><br><span class="line">LoRA (7B base + 10M adapter):</span><br><span class="line">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span><br><span class="line">â”‚ Base Model: 14GB (frozen)       â”‚</span><br><span class="line">â”‚ Adapter: 20MB                   â”‚</span><br><span class="line">â”‚ Optimizer States: 60MB          â”‚</span><br><span class="line">â”‚ Gradients: 20MB                 â”‚</span><br><span class="line">â”‚ Activations: 12GB               â”‚</span><br><span class="line">â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚</span><br><span class="line">â”‚ Total: ~27GB                    â”‚</span><br><span class="line">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span><br><span class="line">Required: 1Ã— RTX 3090/4090 (24GB)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Real-World-Use-Cases"><a href="#Real-World-Use-Cases" class="headerlink" title="Real-World Use Cases"></a>Real-World Use Cases</h2><h3 id="Use-Case-1-Healthcare-Clinical-Note-Generation"><a href="#Use-Case-1-Healthcare-Clinical-Note-Generation" class="headerlink" title="Use Case 1: Healthcare - Clinical Note Generation"></a>Use Case 1: Healthcare - Clinical Note Generation</h3><p><strong>Scenario</strong>: Hospital needs AI to generate structured clinical notes from doctor-patient conversations.</p>
<p><strong>Challenge</strong>:</p>
<ul>
<li>Medical terminology requires domain adaptation</li>
<li>HIPAA compliance &#x3D; canâ€™t use cloud APIs</li>
<li>Limited budget and GPU resources</li>
</ul>
<p><strong>Solution: LoRA Fine-Tuning</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Approach</span></span><br><span class="line">Base Model: LLaMA-<span class="number">2</span>-7B</span><br><span class="line">Dataset: <span class="number">10</span>,<span class="number">000</span> anonymized clinical conversations</span><br><span class="line">Training: LoRA (r=<span class="number">16</span>, Î±=<span class="number">32</span>)</span><br><span class="line">Hardware: <span class="number">1</span>Ã— RTX A6000 (48GB)</span><br><span class="line">Time: <span class="number">8</span> hours</span><br><span class="line">Cost: ~$<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Results</span></span><br><span class="line">- Accuracy: <span class="number">94</span>% (vs <span class="number">96</span>% <span class="keyword">with</span> full fine-tuning)</span><br><span class="line">- Deployment: One base model + adapter (<span class="number">14.05</span>GB total)</span><br><span class="line">- Multi-specialty: <span class="number">5</span> adapters <span class="keyword">for</span> different departments (<span class="number">14.3</span>GB total)</span><br></pre></td></tr></table></figure>

<p><strong>Why LoRA Won</strong>:</p>
<ul>
<li>âœ… Budget-friendly</li>
<li>âœ… Fast iteration for different specialties</li>
<li>âœ… Meets accuracy requirements</li>
<li>âœ… Easy deployment on-premise</li>
</ul>
<hr>
<h3 id="Use-Case-2-Legal-Contract-Analysis"><a href="#Use-Case-2-Legal-Contract-Analysis" class="headerlink" title="Use Case 2: Legal - Contract Analysis"></a>Use Case 2: Legal - Contract Analysis</h3><p><strong>Scenario</strong>: Law firm needs to analyze merger &amp; acquisition contracts for risk factors.</p>
<p><strong>Challenge</strong>:</p>
<ul>
<li>Complex legal language</li>
<li>High accuracy requirement (mistakes &#x3D; legal liability)</li>
<li>Contracts vary significantly by jurisdiction</li>
</ul>
<p><strong>Solution: Full Fine-Tuning</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Approach</span></span><br><span class="line">Base Model: GPT-<span class="number">3.5</span>-turbo-instruct</span><br><span class="line">Dataset: <span class="number">50</span>,<span class="number">000</span> labeled M&amp;A contracts</span><br><span class="line">Training: Full fine-tuning <span class="built_in">all</span> parameters</span><br><span class="line">Hardware: <span class="number">8</span>Ã— A100 GPUs (cloud)</span><br><span class="line">Time: <span class="number">4</span> days</span><br><span class="line">Cost: ~$<span class="number">25</span>,<span class="number">000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Results</span></span><br><span class="line">- Accuracy: <span class="number">98.5</span>% (vs <span class="number">95</span>% <span class="keyword">with</span> LoRA r=<span class="number">64</span>)</span><br><span class="line">- Risk detection: <span class="number">99.2</span>% recall (critical <span class="keyword">for</span> legal)</span><br><span class="line">- <span class="literal">False</span> positive rate: <span class="number">1.8</span>% (vs <span class="number">4.2</span>% <span class="keyword">with</span> LoRA)</span><br></pre></td></tr></table></figure>

<p><strong>Why Full Fine-Tuning Won</strong>:</p>
<ul>
<li>âœ… Maximum accuracy needed (legal liability)</li>
<li>âœ… Budget available (law firm can afford)</li>
<li>âœ… Single specialized task</li>
<li>âœ… 3% accuracy improvement &#x3D; millions in risk mitigation</li>
</ul>
<hr>
<h3 id="Use-Case-3-E-Commerce-Multi-Category-Product-Descriptions"><a href="#Use-Case-3-E-Commerce-Multi-Category-Product-Descriptions" class="headerlink" title="Use Case 3: E-Commerce - Multi-Category Product Descriptions"></a>Use Case 3: E-Commerce - Multi-Category Product Descriptions</h3><p><strong>Scenario</strong>: Online marketplace needs to generate product descriptions for 10 different categories (electronics, fashion, home, etc.).</p>
<p><strong>Challenge</strong>:</p>
<ul>
<li>10 different writing styles needed</li>
<li>Rapid product launches (new categories added quarterly)</li>
<li>Budget-conscious startup</li>
</ul>
<p><strong>Solution: LoRA with Multi-Adapter Architecture</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Approach</span></span><br><span class="line">Base Model: Qwen-7B</span><br><span class="line">Training: <span class="number">10</span> separate LoRA adapters (r=<span class="number">8</span>)</span><br><span class="line">  - Electronics adapter</span><br><span class="line">  - Fashion adapter</span><br><span class="line">  - Home &amp; Garden adapter</span><br><span class="line">  - Sports adapter</span><br><span class="line">  - ... (<span class="number">6</span> more)</span><br><span class="line">Hardware: <span class="number">1</span>Ã— RTX <span class="number">4090</span></span><br><span class="line">Time per adapter: <span class="number">3</span> hours</span><br><span class="line">Total cost: ~$<span class="number">300</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Deployment</span></span><br><span class="line">Storage:</span><br><span class="line">  Base model: 14GB</span><br><span class="line">  <span class="number">10</span> adapters: <span class="number">10</span> Ã— 40MB = 400MB</span><br><span class="line">  Total: <span class="number">14.4</span>GB (vs 140GB <span class="keyword">for</span> <span class="number">10</span> full models)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Runtime</span></span><br><span class="line">Load base model once, swap adapters dynamically:</span><br><span class="line">electronics_model = base + electronics_adapter</span><br><span class="line">fashion_model = base + fashion_adapter</span><br></pre></td></tr></table></figure>

<p><strong>Why LoRA Won</strong>:</p>
<ul>
<li>âœ… 10Ã— storage savings</li>
<li>âœ… Can train new category adapter in hours</li>
<li>âœ… Single GPU deployment</li>
<li>âœ… Easy A&#x2F;B testing different adapters</li>
</ul>
<hr>
<h3 id="Use-Case-4-Multilingual-Customer-Support"><a href="#Use-Case-4-Multilingual-Customer-Support" class="headerlink" title="Use Case 4: Multilingual Customer Support"></a>Use Case 4: Multilingual Customer Support</h3><p><strong>Scenario</strong>: Global SaaS company needs chatbots for 20 languages.</p>
<p><strong>Challenge</strong>:</p>
<ul>
<li>20 language-specific models needed</li>
<li>Need to update all models when features change</li>
<li>Some languages low-resource (limited training data)</li>
</ul>
<p><strong>LoRA Approach</strong> (Recommended):</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Base Model: Multilingual LLaMA-2-13B</span><br><span class="line">Training: 20 language adapters (r=16)</span><br><span class="line"></span><br><span class="line">Storage: 26GB base + (20 Ã— 80MB) = 27.6GB</span><br><span class="line">vs Full Fine-Tuning: 20 Ã— 26GB = 520GB</span><br><span class="line"></span><br><span class="line">Benefit: Update base model â†’ all languages benefit</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="When-to-Use-Which-Method"><a href="#When-to-Use-Which-Method" class="headerlink" title="When to Use Which Method"></a>When to Use Which Method</h2><h3 id="Choose-Full-Fine-Tuning-When"><a href="#Choose-Full-Fine-Tuning-When" class="headerlink" title="Choose Full Fine-Tuning When:"></a>Choose Full Fine-Tuning When:</h3><ol>
<li><p><strong>Maximum Performance is Critical</strong> âœ…</p>
<ul>
<li>Legal, medical, financial applications where errors are costly</li>
<li>Need that extra 2-5% accuracy</li>
</ul>
</li>
<li><p><strong>Large Dataset Available</strong> âœ…</p>
<ul>
<li>Have &gt;100,000 high-quality labeled examples</li>
<li>Data justifies training all parameters</li>
</ul>
</li>
<li><p><strong>Unlimited Budget &amp; Resources</strong> âœ…</p>
<ul>
<li>Access to GPU clusters (8+ A100s)</li>
<li>Can afford $10,000-100,000 training costs</li>
</ul>
</li>
<li><p><strong>Single Specialized Task</strong> âœ…</p>
<ul>
<li>Only need one model for one task</li>
<li>No plan for multi-task deployment</li>
</ul>
</li>
<li><p><strong>Task Very Different from Pre-training</strong> âœ…</p>
<ul>
<li>Specialized domains (medical, legal, scientific)</li>
<li>Low-resource languages</li>
</ul>
</li>
</ol>
<p><strong>Example Decision</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Use Full Fine-Tuning if:</span><br><span class="line">  (Accuracy_requirement &gt; 97%) AND</span><br><span class="line">  (Budget &gt; $10,000) AND</span><br><span class="line">  (Single_task OR Task_very_different)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Choose-LoRA-When"><a href="#Choose-LoRA-When" class="headerlink" title="Choose LoRA When:"></a>Choose LoRA When:</h3><ol>
<li><p><strong>Limited Resources</strong> âœ…</p>
<ul>
<li>Budget &lt; $5,000</li>
<li>Only have consumer GPUs (RTX 3090, 4090)</li>
</ul>
</li>
<li><p><strong>Need Fast Iteration</strong> âœ…</p>
<ul>
<li>Startup environment</li>
<li>Frequent model updates</li>
<li>Rapid experimentation</li>
</ul>
</li>
<li><p><strong>Multi-Task Deployment</strong> âœ…</p>
<ul>
<li>Need models for 5+ different tasks&#x2F;domains</li>
<li>Want to switch between tasks dynamically</li>
</ul>
</li>
<li><p><strong>Storage Constraints</strong> âœ…</p>
<ul>
<li>Limited disk space</li>
<li>Edge device deployment</li>
</ul>
</li>
<li><p><strong>Continuous Learning</strong> âœ…</p>
<ul>
<li>Need to add new capabilities over time</li>
<li>Canâ€™t afford catastrophic forgetting</li>
</ul>
</li>
</ol>
<p><strong>Example Decision</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Use LoRA if:</span><br><span class="line">  (Budget &lt; $5,000) OR</span><br><span class="line">  (GPU_memory &lt; 80GB) OR</span><br><span class="line">  (Num_tasks &gt; 3) OR</span><br><span class="line">  (Need_fast_iteration)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Hands-On-Practice-Guide"><a href="#Hands-On-Practice-Guide" class="headerlink" title="Hands-On Practice Guide"></a>Hands-On Practice Guide</h2><h3 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Install required libraries</span></span><br><span class="line">pip install torch transformers peft datasets accelerate bitsandbytes</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check GPU</span></span><br><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<h3 id="Practice-1-Full-Fine-Tuning-Small-Model"><a href="#Practice-1-Full-Fine-Tuning-Small-Model" class="headerlink" title="Practice 1: Full Fine-Tuning (Small Model)"></a>Practice 1: Full Fine-Tuning (Small Model)</h3><p><strong>Task</strong>: Fine-tune GPT-2 (small) for custom text generation</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Load pre-trained model</span></span><br><span class="line">model = GPT2LMHeadModel.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(<span class="string">&quot;gpt2&quot;</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Prepare dataset</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;wikitext&quot;</span>, <span class="string">&quot;wikitext-2-raw-v1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize_function</span>(<span class="params">examples</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[<span class="string">&quot;text&quot;</span>], truncation=<span class="literal">True</span>, </span><br><span class="line">                     max_length=<span class="number">512</span>, padding=<span class="string">&quot;max_length&quot;</span>)</span><br><span class="line"></span><br><span class="line">tokenized_datasets = dataset.<span class="built_in">map</span>(tokenize_function, batched=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Training configuration (FULL FINE-TUNING)</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./gpt2-finetuned-full&quot;</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    save_steps=<span class="number">500</span>,</span><br><span class="line">    save_total_limit=<span class="number">2</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    <span class="comment"># All parameters trainable (default)</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Train</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. Save model</span></span><br><span class="line">model.save_pretrained(<span class="string">&quot;./gpt2-finetuned-full&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;./gpt2-finetuned-full&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Model size: <span class="subst">&#123;<span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())&#125;</span> parameters&quot;</span>)</span><br><span class="line"><span class="comment"># Output: ~124M parameters all trained</span></span><br></pre></td></tr></table></figure>

<p><strong>Resource Requirements</strong>:</p>
<ul>
<li>GPU: GTX 1080 Ti or better (11GB+)</li>
<li>Time: ~2 hours</li>
<li>Storage: ~500MB</li>
</ul>
<hr>
<h3 id="Practice-2-LoRA-Fine-Tuning-Large-Model"><a href="#Practice-2-LoRA-Fine-Tuning-Large-Model" class="headerlink" title="Practice 2: LoRA Fine-Tuning (Large Model)"></a>Practice 2: LoRA Fine-Tuning (Large Model)</h3><p><strong>Task</strong>: Fine-tune LLaMA-2-7B for instruction following using LoRA</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer, TrainingArguments</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, get_peft_model, prepare_model_for_kbit_training</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Load base model (with 4-bit quantization for efficiency)</span></span><br><span class="line">model_name = <span class="string">&quot;meta-llama/Llama-2-7b-hf&quot;</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_name,</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,  <span class="comment"># Quantization to reduce memory</span></span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span></span><br><span class="line">)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Configure LoRA</span></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    r=<span class="number">16</span>,                       <span class="comment"># Rank (try 8, 16, 32, 64)</span></span><br><span class="line">    lora_alpha=<span class="number">32</span>,              <span class="comment"># Scaling factor</span></span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],  <span class="comment"># Apply to attention</span></span><br><span class="line">    lora_dropout=<span class="number">0.05</span>,</span><br><span class="line">    bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Prepare model for LoRA training</span></span><br><span class="line">model = prepare_model_for_kbit_training(model)</span><br><span class="line">model = get_peft_model(model, lora_config)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print trainable parameters</span></span><br><span class="line">model.print_trainable_parameters()</span><br><span class="line"><span class="comment"># Output: trainable params: 4,194,304 || all params: 6,738,415,616 || trainable%: 0.06%</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. Load instruction dataset</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;timdettmers/openassistant-guanaco&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. Training configuration</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./llama2-lora&quot;</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    gradient_accumulation_steps=<span class="number">4</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-4</span>,</span><br><span class="line">    logging_steps=<span class="number">10</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    fp16=<span class="literal">True</span>,  <span class="comment"># Mixed precision</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. Train with SFTTrainer (Supervised Fine-Tuning)</span></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model=model,</span><br><span class="line">    train_dataset=dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    args=training_args,</span><br><span class="line">    peft_config=lora_config,</span><br><span class="line">    dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length=<span class="number">512</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. Save only LoRA adapter (tiny!)</span></span><br><span class="line">model.save_pretrained(<span class="string">&quot;./llama2-lora-adapter&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. Load and use later</span></span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line"></span><br><span class="line">base_model = AutoModelForCausalLM.from_pretrained(model_name)</span><br><span class="line">lora_model = PeftModel.from_pretrained(base_model, <span class="string">&quot;./llama2-lora-adapter&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate</span></span><br><span class="line">inputs = tokenizer(<span class="string">&quot;Explain quantum computing:&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">outputs = lora_model.generate(**inputs, max_length=<span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(tokenizer.decode(outputs[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<p><strong>Resource Requirements</strong>:</p>
<ul>
<li>GPU: RTX 3090 (24GB) or better</li>
<li>Time: 4-8 hours</li>
<li>Storage: Base model (14GB) + Adapter (50MB)</li>
</ul>
<p><strong>Key Observations</strong>:</p>
<ul>
<li>Only 0.06% of parameters trained! (4M out of 6.7B)</li>
<li>Memory usage: ~18GB (vs ~90GB for full fine-tuning)</li>
<li>Can train multiple adapters and switch between them</li>
</ul>
<hr>
<h3 id="Practice-3-Comparing-LoRA-Ranks"><a href="#Practice-3-Comparing-LoRA-Ranks" class="headerlink" title="Practice 3: Comparing LoRA Ranks"></a>Practice 3: Comparing LoRA Ranks</h3><p><strong>Experiment</strong>: Train same model with different ranks and compare</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train adapters with different ranks</span></span><br><span class="line">ranks = [<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>]</span><br><span class="line">results = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> ranks:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;=&#x27;</span>*<span class="number">50</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Training with rank r=<span class="subst">&#123;r&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;=&#x27;</span>*<span class="number">50</span>&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    lora_config = LoraConfig(</span><br><span class="line">        r=r,</span><br><span class="line">        lora_alpha=r*<span class="number">2</span>,  <span class="comment"># Common practice: alpha = 2*r</span></span><br><span class="line">        target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">        lora_dropout=<span class="number">0.05</span>,</span><br><span class="line">        bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">        task_type=<span class="string">&quot;CAUSAL_LM&quot;</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    model = prepare_model_for_kbit_training(base_model)</span><br><span class="line">    model = get_peft_model(model, lora_config)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Train and evaluate</span></span><br><span class="line">    trainer = SFTTrainer(...)</span><br><span class="line">    trainer.train()</span><br><span class="line">    metrics = trainer.evaluate()</span><br><span class="line">    </span><br><span class="line">    results[r] = &#123;</span><br><span class="line">        <span class="string">&#x27;trainable_params&#x27;</span>: <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad),</span><br><span class="line">        <span class="string">&#x27;loss&#x27;</span>: metrics[<span class="string">&#x27;eval_loss&#x27;</span>],</span><br><span class="line">        <span class="string">&#x27;adapter_size_mb&#x27;</span>: get_adapter_size(model)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compare results</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame(results).T</span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Expected output:</span></span><br><span class="line"><span class="comment">#     trainable_params  loss  adapter_size_mb</span></span><br><span class="line"><span class="comment"># 4      2,097,152    2.45       8</span></span><br><span class="line"><span class="comment"># 8      4,194,304    2.31      16</span></span><br><span class="line"><span class="comment"># 16     8,388,608    2.24      32</span></span><br><span class="line"><span class="comment"># 32    16,777,216    2.21      64</span></span><br><span class="line"><span class="comment"># 64    33,554,432    2.19     128</span></span><br></pre></td></tr></table></figure>

<p><strong>Insights</strong>:</p>
<ul>
<li>Rank 4-8: Fast, tiny, good for simple tasks</li>
<li>Rank 16-32: Sweet spot for most tasks</li>
<li>Rank 64+: Approaching full fine-tuning performance</li>
</ul>
<hr>
<h2 id="Advanced-Topics"><a href="#Advanced-Topics" class="headerlink" title="Advanced Topics"></a>Advanced Topics</h2><h3 id="1-QLoRA-Quantized-LoRA"><a href="#1-QLoRA-Quantized-LoRA" class="headerlink" title="1. QLoRA (Quantized LoRA)"></a>1. QLoRA (Quantized LoRA)</h3><p><strong>What</strong>: Combines LoRA with 4-bit quantization for even lower memory usage.</p>
<p><strong>Breakthrough</strong>: Train 65B parameter models on a single 48GB GPU!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BitsAndBytesConfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># QLoRA configuration</span></span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">    bnb_4bit_compute_dtype=torch.bfloat16</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    <span class="string">&quot;meta-llama/Llama-2-70b-hf&quot;</span>,</span><br><span class="line">    quantization_config=bnb_config,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now train with LoRA as before</span></span><br><span class="line"><span class="comment"># Memory usage: ~40GB for 70B model! ğŸ‰</span></span><br></pre></td></tr></table></figure>

<p><strong>Use Case</strong>: Fine-tune massive models (65B, 70B+) on consumer hardware.</p>
<hr>
<h3 id="2-AdaLoRA-Adaptive-LoRA"><a href="#2-AdaLoRA-Adaptive-LoRA" class="headerlink" title="2. AdaLoRA (Adaptive LoRA)"></a>2. AdaLoRA (Adaptive LoRA)</h3><p><strong>What</strong>: Dynamically adjusts rank during training based on importance.</p>
<p><strong>Benefit</strong>: Automatically finds optimal rank per layer.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> AdaLoraConfig, get_peft_model</span><br><span class="line"></span><br><span class="line">adalora_config = AdaLoraConfig(</span><br><span class="line">    init_r=<span class="number">12</span>,              <span class="comment"># Initial rank</span></span><br><span class="line">    target_r=<span class="number">8</span>,             <span class="comment"># Target rank</span></span><br><span class="line">    tinit=<span class="number">200</span>,              <span class="comment"># Warmup steps</span></span><br><span class="line">    tfinal=<span class="number">1000</span>,            <span class="comment"># Total steps</span></span><br><span class="line">    delta_t=<span class="number">10</span>,             <span class="comment"># Rank adjustment frequency</span></span><br><span class="line">    beta1=<span class="number">0.85</span>,</span><br><span class="line">    beta2=<span class="number">0.85</span>,</span><br><span class="line">    orth_reg_weight=<span class="number">0.5</span>,</span><br><span class="line">    lora_alpha=<span class="number">32</span>,</span><br><span class="line">    lora_dropout=<span class="number">0.1</span>,</span><br><span class="line">    target_modules=[<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>],</span><br><span class="line">    task_type=<span class="string">&quot;CAUSAL_LM&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = get_peft_model(model, adalora_config)</span><br></pre></td></tr></table></figure>

<p><strong>Result</strong>: Better performance than fixed-rank LoRA with similar parameter count.</p>
<hr>
<h3 id="3-The-â€œIntruder-Dimensionsâ€-Problem"><a href="#3-The-â€œIntruder-Dimensionsâ€-Problem" class="headerlink" title="3. The â€œIntruder Dimensionsâ€ Problem"></a>3. The â€œIntruder Dimensionsâ€ Problem</h3><p><strong>Recent Discovery (MIT Research, 2024)</strong>:</p>
<p>LoRA introduces high-ranking singular vectors not present in full fine-tuning. These â€œintruder dimensionsâ€:</p>
<ul>
<li>Reduce out-of-distribution generalization by 5-8%</li>
<li>Cause more forgetting in continual learning</li>
<li>Appear more with lower ranks (r â‰¤ 16)</li>
</ul>
<p><strong>Visualization</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Full Fine-Tuning Weight Matrix SVD:</span><br><span class="line">Singular Values: [100, 95, 90, 85, 80, ...]  â† Smooth decay</span><br><span class="line">Singular Vectors: All similar to pre-trained</span><br><span class="line"></span><br><span class="line">LoRA Weight Matrix SVD:</span><br><span class="line">Singular Values: [100, 95, 90, 85, 80, ..., 15, 14, 13]  â† Similar</span><br><span class="line">                                               â†“</span><br><span class="line">                                    [50, 45, 40]  â† INTRUDER!</span><br><span class="line">Singular Vectors: Some very different from pre-trained</span><br></pre></td></tr></table></figure>

<p><strong>Solutions</strong>:</p>
<ol>
<li>Use higher rank (r&#x3D;64+) with rank stabilization</li>
<li>Use â€œrank-stabilized LoRAâ€ techniques</li>
<li>For critical applications, prefer full fine-tuning</li>
</ol>
<hr>
<h3 id="4-Multi-Adapter-Architecture"><a href="#4-Multi-Adapter-Architecture" class="headerlink" title="4. Multi-Adapter Architecture"></a>4. Multi-Adapter Architecture</h3><p><strong>Pattern</strong>: One base model + dynamic adapter loading</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training phase: Train multiple adapters</span></span><br><span class="line">adapters = &#123;</span><br><span class="line">    <span class="string">&#x27;medical&#x27;</span>: train_lora(base_model, medical_data, r=<span class="number">16</span>),</span><br><span class="line">    <span class="string">&#x27;legal&#x27;</span>: train_lora(base_model, legal_data, r=<span class="number">16</span>),</span><br><span class="line">    <span class="string">&#x27;finance&#x27;</span>: train_lora(base_model, finance_data, r=<span class="number">16</span>),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save adapters</span></span><br><span class="line"><span class="keyword">for</span> name, adapter <span class="keyword">in</span> adapters.items():</span><br><span class="line">    adapter.save_pretrained(<span class="string">f&quot;./adapters/<span class="subst">&#123;name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference phase: Dynamically load adapters</span></span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line"></span><br><span class="line">base_model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;llama-2-7b&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># For medical query</span></span><br><span class="line">medical_model = PeftModel.from_pretrained(base_model, <span class="string">&quot;./adapters/medical&quot;</span>)</span><br><span class="line">response = medical_model.generate(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Switch to legal</span></span><br><span class="line">legal_model = PeftModel.from_pretrained(base_model, <span class="string">&quot;./adapters/legal&quot;</span>)</span><br><span class="line">response = legal_model.generate(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Or merge multiple adapters!</span></span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> PeftModel</span><br><span class="line">multi_model = PeftModel.from_pretrained(base_model, <span class="string">&quot;./adapters/medical&quot;</span>)</span><br><span class="line">multi_model.load_adapter(<span class="string">&quot;./adapters/legal&quot;</span>, adapter_name=<span class="string">&quot;legal&quot;</span>)</span><br><span class="line">multi_model.set_adapter([<span class="string">&quot;medical&quot;</span>, <span class="string">&quot;legal&quot;</span>])  <span class="comment"># Use both!</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Decision-Framework"><a href="#Decision-Framework" class="headerlink" title="Decision Framework"></a>Decision Framework</h2><h3 id="The-Complete-Decision-Tree"><a href="#The-Complete-Decision-Tree" class="headerlink" title="The Complete Decision Tree"></a>The Complete Decision Tree</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">START: Do you need to fine-tune a large language model?</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â†’ Q1: What&#x27;s your budget?</span><br><span class="line">â”‚   â”œâ”€â†’ &lt; $1,000: â†’ LoRA (or QLoRA)</span><br><span class="line">â”‚   â”œâ”€â†’ $1,000 - $10,000: â†’ LoRA (consider full if single critical task)</span><br><span class="line">â”‚   â””â”€â†’ &gt; $10,000: â†’ Consider full fine-tuning</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â†’ Q2: What GPU do you have?</span><br><span class="line">â”‚   â”œâ”€â†’ Consumer (RTX 3090/4090): â†’ LoRA or QLoRA</span><br><span class="line">â”‚   â”œâ”€â†’ Single A100 (40-80GB): â†’ LoRA or Full (for &lt;7B models)</span><br><span class="line">â”‚   â””â”€â†’ GPU Cluster (8+ A100s): â†’ Full fine-tuning possible</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â†’ Q3: How many tasks?</span><br><span class="line">â”‚   â”œâ”€â†’ 1 task: â†’ Either (depends on other factors)</span><br><span class="line">â”‚   â”œâ”€â†’ 2-5 tasks: â†’ LoRA (multi-adapter)</span><br><span class="line">â”‚   â””â”€â†’ 5+ tasks: â†’ Definitely LoRA</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â†’ Q4: Accuracy requirements?</span><br><span class="line">â”‚   â”œâ”€â†’ &gt;98% required: â†’ Full fine-tuning</span><br><span class="line">â”‚   â”œâ”€â†’ 95-98%: â†’ LoRA (high rank, r=64+)</span><br><span class="line">â”‚   â””â”€â†’ &lt;95%: â†’ LoRA (standard rank, r=8-16)</span><br><span class="line">â”‚</span><br><span class="line">â”œâ”€â†’ Q5: Deployment constraints?</span><br><span class="line">â”‚   â”œâ”€â†’ Edge devices: â†’ LoRA (smaller)</span><br><span class="line">â”‚   â”œâ”€â†’ Cloud: â†’ Either</span><br><span class="line">â”‚   â””â”€â†’ Need rapid updates: â†’ LoRA</span><br><span class="line">â”‚</span><br><span class="line">â””â”€â†’ Q6: Continual learning needed?</span><br><span class="line">    â”œâ”€â†’ Yes, multiple sequential tasks: â†’ High-rank LoRA or Full</span><br><span class="line">    â”œâ”€â†’ No: â†’ Standard LoRA</span><br><span class="line">    â””â”€â†’ Critical to avoid forgetting: â†’ Full fine-tuning</span><br></pre></td></tr></table></figure>

<h3 id="Quick-Selection-Matrix"><a href="#Quick-Selection-Matrix" class="headerlink" title="Quick Selection Matrix"></a>Quick Selection Matrix</h3><table>
<thead>
<tr>
<th>Your Situation</th>
<th>Recommended Method</th>
<th>Rank&#x2F;Config</th>
</tr>
</thead>
<tbody><tr>
<td>Startup, limited GPU, 3+ tasks</td>
<td>LoRA</td>
<td>r&#x3D;8-16</td>
</tr>
<tr>
<td>Enterprise, single critical task</td>
<td>Full Fine-Tuning</td>
<td>All parameters</td>
</tr>
<tr>
<td>Research, multiple experiments</td>
<td>LoRA</td>
<td>r&#x3D;16-32</td>
</tr>
<tr>
<td>&gt;100B model, limited hardware</td>
<td>QLoRA</td>
<td>r&#x3D;8-16, 4-bit</td>
</tr>
<tr>
<td>Medical&#x2F;Legal high-stakes</td>
<td>Full Fine-Tuning</td>
<td>All parameters</td>
</tr>
<tr>
<td>Multi-lingual deployment</td>
<td>LoRA multi-adapter</td>
<td>r&#x3D;16 per language</td>
</tr>
<tr>
<td>Rapid A&#x2F;B testing</td>
<td>LoRA</td>
<td>r&#x3D;8 (fast training)</td>
</tr>
<tr>
<td>Edge device deployment</td>
<td>QLoRA</td>
<td>r&#x3D;4-8, quantized</td>
</tr>
</tbody></table>
<hr>
<h2 id="Best-Practices-Tips"><a href="#Best-Practices-Tips" class="headerlink" title="Best Practices &amp; Tips"></a>Best Practices &amp; Tips</h2><h3 id="For-LoRA-Fine-Tuning"><a href="#For-LoRA-Fine-Tuning" class="headerlink" title="For LoRA Fine-Tuning"></a>For LoRA Fine-Tuning</h3><ol>
<li><p><strong>Start Small, Scale Up</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Experiment progression</span></span><br><span class="line"><span class="number">1.</span> Try r=<span class="number">8</span> first (fast, good baseline)</span><br><span class="line"><span class="number">2.</span> If underfitting, increase to r=<span class="number">16</span></span><br><span class="line"><span class="number">3.</span> For <span class="built_in">complex</span> tasks, <span class="keyword">try</span> r=<span class="number">32</span> <span class="keyword">or</span> r=<span class="number">64</span></span><br><span class="line"><span class="number">4.</span> Monitor validation loss to find sweet spot</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Target the Right Modules</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For most language models</span></span><br><span class="line">target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>]  <span class="comment"># Minimum (queries &amp; values)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For better performance</span></span><br><span class="line">target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>]  <span class="comment"># All attention</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For maximum adaptation (more params)</span></span><br><span class="line">target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>, </span><br><span class="line">                  <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>]  <span class="comment"># Attention + FFN</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Learning Rate Selection</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LoRA typically needs higher LR than full fine-tuning</span></span><br><span class="line">Full Fine-Tuning: lr = <span class="number">1e-5</span> to <span class="number">5e-5</span></span><br><span class="line">LoRA: lr = <span class="number">1e-4</span> to <span class="number">3e-4</span>  (10x higher!)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Rule of thumb</span></span><br><span class="line">lora_lr = full_finetuning_lr * <span class="number">10</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Rank Selection Guide</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Task Complexity        â†’ Recommended Rank</span><br><span class="line">â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span><br><span class="line">Simple (sentiment)     â†’ r=4-8</span><br><span class="line">Medium (summarization) â†’ r=8-16</span><br><span class="line">Complex (reasoning)    â†’ r=16-32</span><br><span class="line">Very complex (coding)  â†’ r=32-64</span><br><span class="line">Approaching full FT    â†’ r=128-256</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Prevent Intruder Dimensions</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use rank stabilization</span></span><br><span class="line">lora_config = LoraConfig(</span><br><span class="line">    r=<span class="number">32</span>,</span><br><span class="line">    lora_alpha=<span class="number">64</span>,</span><br><span class="line">    use_rslora=<span class="literal">True</span>,  <span class="comment"># Rank-stabilized LoRA</span></span><br><span class="line">    <span class="comment"># ... other params</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="For-Full-Fine-Tuning"><a href="#For-Full-Fine-Tuning" class="headerlink" title="For Full Fine-Tuning"></a>For Full Fine-Tuning</h3><ol>
<li><p><strong>Gradient Checkpointing</strong> (Save Memory)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.gradient_checkpointing_enable()</span><br><span class="line"><span class="comment"># Trades computation for memory</span></span><br><span class="line"><span class="comment"># Enables training larger models on same GPU</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Mixed Precision Training</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(</span><br><span class="line">    fp16=<span class="literal">True</span>,  <span class="comment"># For older GPUs</span></span><br><span class="line">    bf16=<span class="literal">True</span>,  <span class="comment"># For A100s (better for large models)</span></span><br><span class="line">    <span class="comment"># Reduces memory usage by 2x</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Distributed Training</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use DeepSpeed for multi-GPU</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    deepspeed=<span class="string">&quot;ds_config.json&quot;</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">1</span>,</span><br><span class="line">    gradient_accumulation_steps=<span class="number">16</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ds_config.json</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;train_batch_size&quot;</span>: <span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    <span class="string">&quot;zero_optimization&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;stage&quot;</span>: <span class="number">3</span>,  <span class="comment"># ZeRO-3: Shard everything</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Prevent Catastrophic Forgetting</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use lower learning rate</span></span><br><span class="line">learning_rate = <span class="number">1e-5</span>  <span class="comment"># vs 2e-4 for pre-training</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Freeze some layers (partial fine-tuning)</span></span><br><span class="line"><span class="keyword">for</span> i, layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.layers):</span><br><span class="line">    <span class="keyword">if</span> i &lt; <span class="number">20</span>:  <span class="comment"># Freeze first 20 layers</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> layer.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use elastic weight consolidation (EWC)</span></span><br><span class="line"><span class="comment"># Add regularization term penalizing large weight changes</span></span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="Common-Mistakes-How-to-Avoid-Them"><a href="#Common-Mistakes-How-to-Avoid-Them" class="headerlink" title="Common Mistakes &amp; How to Avoid Them"></a>Common Mistakes &amp; How to Avoid Them</h2><h3 id="Mistake-1-Using-LoRA-rank-thatâ€™s-too-low"><a href="#Mistake-1-Using-LoRA-rank-thatâ€™s-too-low" class="headerlink" title="Mistake 1: Using LoRA rank thatâ€™s too low"></a>Mistake 1: Using LoRA rank thatâ€™s too low</h3><p>âŒ <strong>Problem</strong>: r&#x3D;4 for complex instruction following</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lora_config = LoraConfig(r=<span class="number">4</span>, ...)  <span class="comment"># Too small!</span></span><br><span class="line"><span class="comment"># Result: Model can&#x27;t learn complex patterns, poor performance</span></span><br></pre></td></tr></table></figure>

<p>âœ… <strong>Solution</strong>: Start with r&#x3D;16, increase if needed</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lora_config = LoraConfig(r=<span class="number">16</span>, lora_alpha=<span class="number">32</span>, ...)</span><br><span class="line"><span class="comment"># Monitor validation loss, increase to r=32 if plateauing</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Mistake-2-Wrong-learning-rate"><a href="#Mistake-2-Wrong-learning-rate" class="headerlink" title="Mistake 2: Wrong learning rate"></a>Mistake 2: Wrong learning rate</h3><p>âŒ <strong>Problem</strong>: Using same LR for LoRA as full fine-tuning</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Full fine-tuning LR used for LoRA</span></span><br><span class="line">training_args = TrainingArguments(learning_rate=<span class="number">2e-5</span>, ...)</span><br><span class="line"><span class="comment"># Result: Slow convergence, underfitting</span></span><br></pre></td></tr></table></figure>

<p>âœ… <strong>Solution</strong>: Use 10x higher LR for LoRA</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(learning_rate=<span class="number">2e-4</span>, ...)</span><br><span class="line"><span class="comment"># LoRA adapters need stronger signals to learn</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Mistake-3-Not-quantizing-when-memory-is-tight"><a href="#Mistake-3-Not-quantizing-when-memory-is-tight" class="headerlink" title="Mistake 3: Not quantizing when memory is tight"></a>Mistake 3: Not quantizing when memory is tight</h3><p>âŒ <strong>Problem</strong>: Trying to load 7B model in FP16 on 16GB GPU</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">&quot;llama-2-7b&quot;</span>)</span><br><span class="line"><span class="comment"># Result: CUDA Out of Memory error</span></span><br></pre></td></tr></table></figure>

<p>âœ… <strong>Solution</strong>: Use 4-bit&#x2F;8-bit quantization</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    <span class="string">&quot;llama-2-7b&quot;</span>,</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    device_map=<span class="string">&quot;auto&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># Result: Fits in 8GB GPU!</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Mistake-4-Training-on-too-few-examples"><a href="#Mistake-4-Training-on-too-few-examples" class="headerlink" title="Mistake 4: Training on too few examples"></a>Mistake 4: Training on too few examples</h3><p>âŒ <strong>Problem</strong>: Fine-tuning on 100 examples</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = load_dataset(...)[:<span class="number">100</span>]  <span class="comment"># Only 100 examples</span></span><br><span class="line"><span class="comment"># Result: Overfitting, poor generalization</span></span><br></pre></td></tr></table></figure>

<p>âœ… <strong>Solution</strong>: Minimum dataset sizes</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Full Fine-Tuning: 10,000+ examples (ideally 100k+)</span><br><span class="line">LoRA: 1,000+ examples (can work with 500 for simple tasks)</span><br><span class="line">QLoRA: 500+ examples (most efficient)</span><br><span class="line"></span><br><span class="line">If you have &lt;500 examples:</span><br><span class="line">  â†’ Use prompt engineering or few-shot learning instead</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="Mistake-5-Not-saving-checkpoints"><a href="#Mistake-5-Not-saving-checkpoints" class="headerlink" title="Mistake 5: Not saving checkpoints"></a>Mistake 5: Not saving checkpoints</h3><p>âŒ <strong>Problem</strong>: Training crashes after 20 hours, no checkpoints</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(</span><br><span class="line">    save_strategy=<span class="string">&quot;no&quot;</span>,  <span class="comment"># Dangerous!</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>âœ… <strong>Solution</strong>: Regular checkpointing</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">training_args = TrainingArguments(</span><br><span class="line">    save_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">    save_steps=<span class="number">500</span>,</span><br><span class="line">    save_total_limit=<span class="number">3</span>,  <span class="comment"># Keep last 3 checkpoints</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Real-Cost-Comparison"><a href="#Real-Cost-Comparison" class="headerlink" title="Real Cost Comparison"></a>Real Cost Comparison</h2><h3 id="Example-Fine-tuning-LLaMA-2-7B-for-3-epochs-on-10-000-examples"><a href="#Example-Fine-tuning-LLaMA-2-7B-for-3-epochs-on-10-000-examples" class="headerlink" title="Example: Fine-tuning LLaMA-2-7B for 3 epochs on 10,000 examples"></a>Example: Fine-tuning LLaMA-2-7B for 3 epochs on 10,000 examples</h3><p><strong>Full Fine-Tuning</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Hardware: 4Ã— A100 (80GB) via AWS</span><br><span class="line">Cost: $32.77/hour per GPU</span><br><span class="line">Duration: 48 hours</span><br><span class="line">Total: $32.77 Ã— 4 Ã— 48 = $6,293</span><br><span class="line"></span><br><span class="line">Storage: 14GB per model</span><br><span class="line">If 5 tasks: 70GB total</span><br><span class="line"></span><br><span class="line">Total Investment: ~$6,300 + ongoing storage</span><br></pre></td></tr></table></figure>

<p><strong>LoRA (r&#x3D;16)</strong>:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Hardware: 1Ã— RTX 4090 (24GB) - owned or $2/hour cloud</span><br><span class="line">Cost: $2/hour</span><br><span class="line">Duration: 12 hours</span><br><span class="line">Total: $2 Ã— 12 = $24</span><br><span class="line"></span><br><span class="line">Storage: 14GB base + (5 Ã— 50MB adapters) = 14.25GB</span><br><span class="line"></span><br><span class="line">Total Investment: ~$24 + one-time GPU purchase (~$1,600)</span><br></pre></td></tr></table></figure>

<p><strong>Savings: 99.6%</strong> ğŸ‰</p>
<hr>
<h2 id="Latest-Research-Trends-2024-2025"><a href="#Latest-Research-Trends-2024-2025" class="headerlink" title="Latest Research &amp; Trends (2024-2025)"></a>Latest Research &amp; Trends (2024-2025)</h2><h3 id="1-LoRA-and-LoRA-FA"><a href="#1-LoRA-and-LoRA-FA" class="headerlink" title="1. LoRA+ and LoRA-FA"></a>1. LoRA+ and LoRA-FA</h3><ul>
<li><strong>LoRA+</strong>: Different learning rates for A and B matrices</li>
<li><strong>LoRA-FA</strong>: Frozen-A variant (only train B matrix)</li>
<li>Result: Faster convergence, better performance</li>
</ul>
<h3 id="2-DoRA-Weight-Decomposed-LoRA"><a href="#2-DoRA-Weight-Decomposed-LoRA" class="headerlink" title="2. DoRA (Weight-Decomposed LoRA)"></a>2. DoRA (Weight-Decomposed LoRA)</h3><ul>
<li>Decomposes weights into magnitude and direction</li>
<li>Bridges gap between LoRA and full fine-tuning</li>
<li>20% better performance on reasoning tasks</li>
</ul>
<h3 id="3-MultiLoRA-LoRA-Composition"><a href="#3-MultiLoRA-LoRA-Composition" class="headerlink" title="3. MultiLoRA &amp; LoRA Composition"></a>3. MultiLoRA &amp; LoRA Composition</h3><ul>
<li>Train multiple LoRA adapters</li>
<li>Compose them at inference time</li>
<li>Example: (medical_adapter Ã— 0.7) + (general_adapter Ã— 0.3)</li>
</ul>
<h3 id="4-LoRA-for-Vision-Multimodal-Models"><a href="#4-LoRA-for-Vision-Multimodal-Models" class="headerlink" title="4. LoRA for Vision &amp; Multimodal Models"></a>4. LoRA for Vision &amp; Multimodal Models</h3><ul>
<li>VoRA: LoRA for vision transformers</li>
<li>Successful for CLIP, Stable Diffusion fine-tuning</li>
<li>90% memory reduction for image model fine-tuning</li>
</ul>
<hr>
<h2 id="Summary-Recommendations"><a href="#Summary-Recommendations" class="headerlink" title="Summary &amp; Recommendations"></a>Summary &amp; Recommendations</h2><h3 id="The-Bottom-Line"><a href="#The-Bottom-Line" class="headerlink" title="The Bottom Line"></a>The Bottom Line</h3><p><strong>LoRA is the default choice for most practitioners in 2024-2025.</strong></p>
<p>Reasons:</p>
<ul>
<li>âœ… 99% cost reduction</li>
<li>âœ… Accessible on consumer hardware</li>
<li>âœ… Fast iteration (hours vs days)</li>
<li>âœ… Easy multi-task deployment</li>
<li>âœ… Good enough performance for most applications (95-99% of full)</li>
</ul>
<p><strong>Full Fine-Tuning is for special cases:</strong></p>
<ul>
<li>High-stakes applications (medical, legal, financial)</li>
<li>Unlimited budget and resources</li>
<li>Need absolute best performance</li>
<li>Research settings exploring model limits</li>
</ul>
<h3 id="Your-Action-Plan"><a href="#Your-Action-Plan" class="headerlink" title="Your Action Plan"></a>Your Action Plan</h3><p><strong>Week 1: Start with LoRA</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> Choose base model (LLaMA-<span class="number">2</span>-7B, Mistral-7B, Qwen)</span><br><span class="line"><span class="number">2.</span> Prepare <span class="number">1</span>,<span class="number">000</span>+ examples</span><br><span class="line"><span class="number">3.</span> Train LoRA (r=<span class="number">16</span>) on <span class="number">1</span>Ã— GPU</span><br><span class="line"><span class="number">4.</span> Evaluate on validation <span class="built_in">set</span></span><br><span class="line"><span class="number">5.</span> Iterate on rank <span class="keyword">and</span> hyperparameters</span><br></pre></td></tr></table></figure>

<p><strong>Week 2: Optimize</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> Experiment <span class="keyword">with</span> ranks: <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span></span><br><span class="line"><span class="number">2.</span> Try different target modules</span><br><span class="line"><span class="number">3.</span> Test QLoRA <span class="keyword">if</span> memory constrained</span><br><span class="line"><span class="number">4.</span> A/B test different adapters</span><br></pre></td></tr></table></figure>

<p><strong>Month 2+: Scale if Needed</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> performance &lt; requirements:</span><br><span class="line">    <span class="keyword">if</span> budget_available:</span><br><span class="line">        <span class="keyword">try</span> full fine-tuning</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">try</span> higher rank LoRA (r=<span class="number">64</span>-<span class="number">128</span>)</span><br><span class="line">        <span class="keyword">or</span> <span class="keyword">try</span> DoRA/LoRA+ variants</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Additional-Resources"><a href="#Additional-Resources" class="headerlink" title="Additional Resources"></a>Additional Resources</h2><h3 id="Code-Repositories"><a href="#Code-Repositories" class="headerlink" title="Code Repositories"></a>Code Repositories</h3><ul>
<li><strong>Hugging Face PEFT</strong>: <a target="_blank" rel="noopener" href="https://github.com/huggingface/peft">https://github.com/huggingface/peft</a></li>
<li><strong>LoRA Paper</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a></li>
<li><strong>QLoRA Paper</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.14314">https://arxiv.org/abs/2305.14314</a></li>
</ul>
<h3 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h3><ul>
<li>Hugging Face LoRA Tutorial: <a target="_blank" rel="noopener" href="https://huggingface.co/docs/peft">https://huggingface.co/docs/peft</a></li>
<li>Fast.ai Practical Deep Learning: <a target="_blank" rel="noopener" href="https://course.fast.ai/">https://course.fast.ai</a></li>
</ul>
<h3 id="Communities"><a href="#Communities" class="headerlink" title="Communities"></a>Communities</h3><ul>
<li>Hugging Face Forums: <a target="_blank" rel="noopener" href="https://discuss.huggingface.co/">https://discuss.huggingface.co</a></li>
<li>r&#x2F;LocalLLaMA (Reddit): For LoRA discussions</li>
<li>EleutherAI Discord: For research discussions</li>
</ul>
<hr>
<p><strong>Remember</strong>:</p>
<ul>
<li>Start with LoRA (r&#x3D;16)</li>
<li>Scale to full fine-tuning only if truly needed</li>
<li>Focus on data quality over method choice</li>
<li>Iterate quickly and measure results</li>
</ul>
<p><strong>The best method is the one that:</strong></p>
<ol>
<li>Fits your budget</li>
<li>Meets your accuracy requirements</li>
<li>Enables fast iteration</li>
<li>Scales with your needs</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"><i class="fa fa-tag"></i> AI</a>
              <a href="/tags/LoRA/" rel="tag"><i class="fa fa-tag"></i> LoRA</a>
              <a href="/tags/LLM/" rel="tag"><i class="fa fa-tag"></i> LLM</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/11/21/WebFlux-Deep-Dive-Operators-Types-and-Real-World-Use-Cases/" rel="prev" title="WebFlux Deep Dive: Operators, Types, and Real-World Use Cases">
                  <i class="fa fa-angle-left"></i> WebFlux Deep Dive: Operators, Types, and Real-World Use Cases
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Dazhi Zhang</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.1/mermaid.min.js","integrity":"sha256-YbM1pG3wWnzhyYN49g5fPnen+2CKEFaZfopkkwSpNtY="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
