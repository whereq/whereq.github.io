<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.whereq.com","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="WhereQ">
<meta property="og:url" content="https://www.whereq.com/page/9/index.html">
<meta property="og:site_name" content="WhereQ">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Dazhi Zhang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.whereq.com/page/9/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/9/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>WhereQ</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">WhereQ</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-articles"><a href="/articles/" rel="section"><i class="fa fa-file fa-fw"></i>Articles</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Dazhi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">146</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">130</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">85</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Using-GlusterFS-with-Kubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Using-GlusterFS-with-Kubernetes/" class="post-title-link" itemprop="url">Using GlusterFS with Kubernetes</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 21:46:06" itemprop="dateCreated datePublished" datetime="2024-10-28T21:46:06-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Distributed-File-System/" itemprop="url" rel="index"><span itemprop="name">Distributed File System</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Distributed-File-System/GlusterFS/" itemprop="url" rel="index"><span itemprop="name">GlusterFS</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Distributed-File-System/GlusterFS/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#glusterfs-overview">GlusterFS Overview</a><ul>
<li><a href="#-key-features"> Key Features</a></li>
<li><a href="#-architecture"> Architecture</a></li>
<li><a href="#-use-cases"> Use Cases</a></li>
</ul>
</li>
<li><a href="#mounting-glusterfs-with-kubernetes">Mounting GlusterFS with Kubernetes</a><ul>
<li><a href="#-step-1-install-glusterfs-client"> Step 1: Install GlusterFS Client</a></li>
<li><a href="#-step-2-create-a-glusterfs-volume"> Step 2: Create a GlusterFS Volume</a></li>
<li><a href="#-step-3-create-a-persistent-volume-pv"> Step 3: Create a Persistent Volume (PV)</a></li>
<li><a href="#-step-4-create-a-persistent-volume-claim-pvc"> Step 4: Create a Persistent Volume Claim (PVC)</a></li>
<li><a href="#-step-5-use-the-pvc-in-a-pod"> Step 5: Use the PVC in a Pod</a></li>
</ul>
</li>
<li><a href="#textual-diagram-of-glusterfs-architecture">Textual Diagram of GlusterFS Architecture</a></li>
<li><a href="#comparison-with-other-main-alternatives">Comparison with Other Main Alternatives</a><ul>
<li><a href="#-nfs-network-file-system"> NFS (Network File System)</a></li>
<li><a href="#-ceph"> Ceph</a></li>
<li><a href="#-amazon-efs-elastic-file-system"> Amazon EFS (Elastic File System)</a></li>
<li><a href="#-openebs"> OpenEBS</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This article provides a comprehensive guide on using GlusterFS with Kubernetes. It covers the basics of GlusterFS, its architecture, and how to mount GlusterFS as the file system for a Pod in Kubernetes. Additionally, it compares GlusterFS with other main alternatives in the storage landscape.</p>
<hr>
<p><a name="glusterfs-overview"></a></p>
<h2 id="GlusterFS-Overview"><a href="#GlusterFS-Overview" class="headerlink" title="GlusterFS Overview"></a>GlusterFS Overview</h2><p><strong>GlusterFS</strong> (Gluster File System) is an open-source, distributed file system designed to scale out in building-block fashion to store petabytes of data. It aggregates various storage servers over Ethernet or InfiniBand RDMA interconnects into one large parallel network file system. GlusterFS is part of the Gluster project, an effort by Red Hat to provide a unified distributed storage solution.</p>
<h3 id="Key-Features"><a href="#Key-Features" class="headerlink" title=" Key Features"></a><a name="key-features"></a> Key Features</h3><ol>
<li><strong>Scalability</strong>: GlusterFS can scale to several petabytes and handle thousands of clients.</li>
<li><strong>Flexibility</strong>: It uses a stackable user space design, allowing for flexible topologies for data storage and retrieval.</li>
<li><strong>High Availability</strong>: GlusterFS provides features like replication and failover to ensure data availability and reliability.</li>
<li><strong>Performance</strong>: It uses various data access protocols like NFS, SMB, and native GlusterFS protocol to optimize performance.</li>
<li><strong>Elasticity</strong>: GlusterFS can dynamically add or remove storage resources without disrupting services.</li>
</ol>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title=" Architecture"></a><a name="architecture"></a> Architecture</h3><p>GlusterFS architecture is based on a client-server model, where the storage servers (bricks) are the servers, and the clients access the data through the GlusterFS client. The architecture is modular, allowing for various configurations and optimizations.</p>
<ol>
<li><strong>Bricks</strong>: Basic units of storage, represented as directories on servers.</li>
<li><strong>Volumes</strong>: Logical collections of bricks. Data is striped, replicated, or distributed across these bricks.</li>
<li><strong>Translators</strong>: Modules that perform various functions like I&#x2F;O, network, and protocol handling.</li>
</ol>
<h3 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title=" Use Cases"></a><a name="use-cases"></a> Use Cases</h3><ul>
<li><strong>Big Data and Analytics</strong>: Suitable for storing and processing large datasets.</li>
<li><strong>Media Streaming</strong>: Efficiently handles large media files.</li>
<li><strong>Backup and Archiving</strong>: Provides reliable storage for backups and archives.</li>
<li><strong>Cloud Storage</strong>: Acts as a scalable storage backend for cloud services.</li>
</ul>
<hr>
<p><a name="mounting-glusterfs-with-kubernetes"></a></p>
<h2 id="Mounting-GlusterFS-with-Kubernetes"><a href="#Mounting-GlusterFS-with-Kubernetes" class="headerlink" title="Mounting GlusterFS with Kubernetes"></a>Mounting GlusterFS with Kubernetes</h2><p>To use GlusterFS as the file system for a Pod in Kubernetes, you need to create a Persistent Volume (PV) and a Persistent Volume Claim (PVC). Below are the steps to achieve this:</p>
<h3 id="Step-1-Install-GlusterFS-Client"><a href="#Step-1-Install-GlusterFS-Client" class="headerlink" title=" Step 1: Install GlusterFS Client"></a><a name="step-1-install-glusterfs-client"></a> Step 1: Install GlusterFS Client</h3><p>Ensure that the GlusterFS client (<code>glusterfs-client</code>) is installed on all Kubernetes nodes. This client is necessary for mounting GlusterFS volumes.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install glusterfs-client</span><br></pre></td></tr></table></figure>

<h3 id="Step-2-Create-a-GlusterFS-Volume"><a href="#Step-2-Create-a-GlusterFS-Volume" class="headerlink" title=" Step 2: Create a GlusterFS Volume"></a><a name="step-2-create-a-glusterfs-volume"></a> Step 2: Create a GlusterFS Volume</h3><p>Create a GlusterFS volume on your GlusterFS cluster. For example:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create k8s-volume replica 3 server1:/brick1 server2:/brick2 server3:/brick3 force</span><br><span class="line">gluster volume start k8s-volume</span><br></pre></td></tr></table></figure>

<h3 id="Step-3-Create-a-Persistent-Volume-PV"><a href="#Step-3-Create-a-Persistent-Volume-PV" class="headerlink" title=" Step 3: Create a Persistent Volume (PV)"></a><a name="step-3-create-a-persistent-volume-pv"></a> Step 3: Create a Persistent Volume (PV)</h3><p>Create a PV that references the GlusterFS volume.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gluster-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">glusterfs:</span></span><br><span class="line">    <span class="attr">endpoints:</span> <span class="string">&quot;glusterfs-cluster&quot;</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">&quot;k8s-volume&quot;</span></span><br><span class="line">    <span class="attr">readOnly:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<h3 id="Step-4-Create-a-Persistent-Volume-Claim-PVC"><a href="#Step-4-Create-a-Persistent-Volume-Claim-PVC" class="headerlink" title=" Step 4: Create a Persistent Volume Claim (PVC)"></a><a name="step-4-create-a-persistent-volume-claim-pvc"></a> Step 4: Create a Persistent Volume Claim (PVC)</h3><p>Create a PVC that binds to the PV.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gluster-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">10Gi</span></span><br></pre></td></tr></table></figure>

<h3 id="Step-5-Use-the-PVC-in-a-Pod"><a href="#Step-5-Use-the-PVC-in-a-Pod" class="headerlink" title=" Step 5: Use the PVC in a Pod"></a><a name="step-5-use-the-pvc-in-a-pod"></a> Step 5: Use the PVC in a Pod</h3><p>Mount the PVC in a Pod.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gluster-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/usr/share/nginx/html&quot;</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">gluster-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">gluster-volume</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">      <span class="attr">claimName:</span> <span class="string">gluster-pvc</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="textual-diagram-of-glusterfs-architecture"></a></p>
<h2 id="Textual-Diagram-of-GlusterFS-Architecture"><a href="#Textual-Diagram-of-GlusterFS-Architecture" class="headerlink" title="Textual Diagram of GlusterFS Architecture"></a>Textual Diagram of GlusterFS Architecture</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+-------------------+       +-------------------+       +-------------------+</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">|  GlusterFS Client |&lt;-----&gt;|  GlusterFS Server |&lt;-----&gt;|  GlusterFS Server |</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">+-------------------+       +-------------------+       +-------------------+</span><br><span class="line">        |                           |                           |</span><br><span class="line">        |                           |                           |</span><br><span class="line">        v                           v                           v</span><br><span class="line">+-------------------+       +-------------------+       +-------------------+</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">|    Brick 1        |       |    Brick 2        |       |    Brick 3        |</span><br><span class="line">|                   |       |                   |       |                   |</span><br><span class="line">+-------------------+       +-------------------+       +-------------------+</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="comparison-with-other-main-alternatives"></a></p>
<h2 id="Comparison-with-Other-Main-Alternatives"><a href="#Comparison-with-Other-Main-Alternatives" class="headerlink" title="Comparison with Other Main Alternatives"></a>Comparison with Other Main Alternatives</h2><h3 id="NFS-Network-File-System"><a href="#NFS-Network-File-System" class="headerlink" title=" NFS (Network File System)"></a><a name="nfs-network-file-system"></a> NFS (Network File System)</h3><ul>
<li><strong>Pros</strong>:<ul>
<li>Simple to set up and manage.</li>
<li>Widely supported and well-documented.</li>
</ul>
</li>
<li><strong>Cons</strong>:<ul>
<li>Single point of failure.</li>
<li>Limited scalability compared to GlusterFS.</li>
<li>Performance can degrade with high latency.</li>
</ul>
</li>
</ul>
<h3 id="Ceph"><a href="#Ceph" class="headerlink" title=" Ceph"></a><a name="ceph"></a> Ceph</h3><ul>
<li><strong>Pros</strong>:<ul>
<li>Highly scalable and fault-tolerant.</li>
<li>Supports object, block, and file storage.</li>
<li>Active community and strong support.</li>
</ul>
</li>
<li><strong>Cons</strong>:<ul>
<li>Complex to set up and manage.</li>
<li>Requires significant resources for optimal performance.</li>
</ul>
</li>
</ul>
<h3 id="Amazon-EFS-Elastic-File-System"><a href="#Amazon-EFS-Elastic-File-System" class="headerlink" title=" Amazon EFS (Elastic File System)"></a><a name="amazon-efs-elastic-file-system"></a> Amazon EFS (Elastic File System)</h3><ul>
<li><strong>Pros</strong>:<ul>
<li>Fully managed service.</li>
<li>Highly available and durable.</li>
<li>Scales automatically with no need to provision storage.</li>
</ul>
</li>
<li><strong>Cons</strong>:<ul>
<li>Cloud-specific, not suitable for on-premises deployments.</li>
<li>Higher cost compared to self-managed solutions.</li>
</ul>
</li>
</ul>
<h3 id="OpenEBS"><a href="#OpenEBS" class="headerlink" title=" OpenEBS"></a><a name="openebs"></a> OpenEBS</h3><ul>
<li><strong>Pros</strong>:<ul>
<li>Kubernetes-native storage solution.</li>
<li>Easy to deploy and manage.</li>
<li>Supports various storage engines.</li>
</ul>
</li>
<li><strong>Cons</strong>:<ul>
<li>Younger project with a smaller community.</li>
<li>May require more tuning for performance.</li>
</ul>
</li>
</ul>
<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>GlusterFS is a powerful, scalable, and flexible distributed file system that can be effectively integrated with Kubernetes for persistent storage solutions. By following the steps outlined in this guide, you can mount GlusterFS volumes in your Kubernetes Pods. Additionally, understanding the architecture and comparing GlusterFS with other storage alternatives helps in making informed decisions for your storage needs.</p>
<hr>
<p><a name="references"></a></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a target="_blank" rel="noopener" href="https://docs.gluster.org/">GlusterFS Official Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://www.redhat.com/en/technologies/storage/gluster">Red Hat Gluster Storage</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/gluster/glusterfs">GlusterFS GitHub Repository</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gluster">GlusterFS Wiki</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Kubernetes Documentation - Persistent Volumes</a></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Network_File_System">NFS Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.ceph.com/en/pacific/">Ceph Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://aws.amazon.com/efs/">Amazon EFS Documentation</a></li>
<li><a target="_blank" rel="noopener" href="https://openebs.io/docs">OpenEBS Documentation</a></li>
</ol>
<p>By following these steps and understanding the architecture and comparisons, you can effectively use GlusterFS with Kubernetes and make informed decisions about storage solutions for your Kubernetes clusters.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Troubleshooting-Kubernetes-Pod-Stuck-in-Terminating-State-After-Deletion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Troubleshooting-Kubernetes-Pod-Stuck-in-Terminating-State-After-Deletion/" class="post-title-link" itemprop="url">Troubleshooting Kubernetes: Pod Stuck in Terminating State After Deletion</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 21:10:13" itemprop="dateCreated datePublished" datetime="2024-10-28T21:10:13-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kubernetes/Troubleshooting/" itemprop="url" rel="index"><span itemprop="name">Troubleshooting</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#problem-background">Problem Background</a></li>
<li><a href="#cause-analysis">Cause Analysis</a><ul>
<li><a href="#-initial-investigation"> Initial Investigation</a></li>
<li><a href="#-kubelet-logs-analysis"> Kubelet Logs Analysis</a><ul>
<li><a href="#suspicious-point-1-pod-ip-retrieval-failure">Suspicious Point 1: Pod IP Retrieval Failure</a></li>
<li><a href="#suspicious-point-2-unmount-failure">Suspicious Point 2: Unmount Failure</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#suspicious-points">Suspicious Points</a><ul>
<li><a href="#-suspicious-point-1-pod-ip-retrieval-failure"> Suspicious Point 1: Pod IP Retrieval Failure</a></li>
<li><a href="#-suspicious-point-2-unmount-failure"> Suspicious Point 2: Unmount Failure</a></li>
</ul>
</li>
<li><a href="#pod-deletion-process">Pod Deletion Process</a></li>
<li><a href="#verification-and-testing">Verification and Testing</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This document provides a detailed troubleshooting guide for a common Kubernetes issue where a Pod remains in the <code>Terminating</code> state after being deleted using the <code>kubectl delete</code> command. The analysis includes examining logs, identifying suspicious points, and understanding the underlying causes.</p>
<hr>
<p><a name="problem-background"></a></p>
<h2 id="Problem-Background"><a href="#Problem-Background" class="headerlink" title="Problem Background"></a>Problem Background</h2><p>After deleting a business Pod using the <code>kubectl delete</code> command, the Pod remained in the <code>Terminating</code> state.</p>
<hr>
<p><a name="cause-analysis"></a></p>
<h2 id="Cause-Analysis"><a href="#Cause-Analysis" class="headerlink" title="Cause Analysis"></a>Cause Analysis</h2><h3 id="Initial-Investigation"><a href="#Initial-Investigation" class="headerlink" title=" Initial Investigation"></a><a name="initial-investigation"></a> Initial Investigation</h3><p>To begin with, the <code>kubectl describe</code> command was used to inspect the Pod:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]# kubectl describe pod -n xxx cam1-78b6fc6bc8-cjsw5</span><br></pre></td></tr></table></figure>

<p>No obvious anomalies were found in the output.</p>
<h3 id="Kubelet-Logs-Analysis"><a href="#Kubelet-Logs-Analysis" class="headerlink" title=" Kubelet Logs Analysis"></a><a name="kubelet-logs-analysis"></a> Kubelet Logs Analysis</h3><p>Next, the kubelet component logs were examined for any anomalies during the Pod deletion process. The following logs were filtered for relevance:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">I0728 16:24:57.339295    9744 kubelet.go:1904] SyncLoop (DELETE, <span class="string">&quot;api&quot;</span>): <span class="string">&quot;cam1-78b6fc6bc8-cjsw5_cam(5c948341-c030-4996-b888-f032577d97b0)&quot;</span></span><br><span class="line">I0728 16:24:57.339720    9744 kuberuntime_container.go:581] Killing container <span class="string">&quot;docker://a73082a4a9a4cec174bb0d1c256cc11d804d93137551b9bfd3e6fa1522e98589&quot;</span> with 60 second grace period</span><br><span class="line">I0728 16:25:18.259418    9744 kubelet.go:1904] SyncLoop (DELETE, <span class="string">&quot;api&quot;</span>): <span class="string">&quot;cam1-78b6fc6bc8-cjsw5_cam(5c948341-c030-4996-b888-f032577d97b0)&quot;</span></span><br><span class="line">2021-07-28 16:25:19.247 [INFO][394011] ipam.go 1173: Releasing all IPs with handle <span class="string">&#x27;cam.cam1-78b6fc6bc8-cjsw5&#x27;</span></span><br><span class="line">2021-07-28 16:25:19.254 [INFO][393585] k8s.go 498: Teardown processing complete.</span><br></pre></td></tr></table></figure>

<h4 id="Suspicious-Point-1-Pod-IP-Retrieval-Failure"><a href="#Suspicious-Point-1-Pod-IP-Retrieval-Failure" class="headerlink" title="Suspicious Point 1: Pod IP Retrieval Failure"></a>Suspicious Point 1: Pod IP Retrieval Failure</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W0728 16:25:19.303513    9744 docker_sandbox.go:384] failed to <span class="built_in">read</span> pod IP from plugin/docker: NetworkPlugin cni failed on the status hook <span class="keyword">for</span> pod <span class="string">&quot;cam1-78b6fc6bc8-cjsw5_cam&quot;</span>: Unexpected <span class="built_in">command</span> output Device <span class="string">&quot;eth0&quot;</span> does not exist.</span><br><span class="line"> with error: <span class="built_in">exit</span> status 1</span><br></pre></td></tr></table></figure>

<h4 id="Suspicious-Point-2-Unmount-Failure"><a href="#Suspicious-Point-2-Unmount-Failure" class="headerlink" title="Suspicious Point 2: Unmount Failure"></a>Suspicious Point 2: Unmount Failure</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E0728 16:25:20.939400    9744 nestedpendingoperations.go:301] Operation <span class="keyword">for</span> <span class="string">&quot;&#123;volumeName:kubernetes.io/glusterfs/5c948341-c030-4996-b888-f032577d97b0-cam-pv-50g podName:5c948341-c030-4996-b888-f032577d97b0 nodeName:&#125;&quot;</span> failed. No retries permitted <span class="keyword">until</span> 2021-07-28 16:25:21.439325811 +0800 CST m=+199182.605079651 (durationBeforeRetry 500ms). Error: <span class="string">&quot;UnmountVolume.TearDown failed for volume \&quot;diag-log\&quot; (UniqueName: \&quot;kubernetes.io/glusterfs/5c948341-c030-4996-b888-f032577d97b0-cam-pv-50g\&quot;) pod \&quot;5c948341-c030-4996-b888-f032577d97b0\&quot; (UID: \&quot;5c948341-c030-4996-b888-f032577d97b0\&quot;) : Unmount failed: exit status 32\nUnmounting arguments: /var/lib/kubelet/pods/5c948341-c030-4996-b888-f032577d97b0/volumes/kubernetes.io~glusterfs/cam-pv-50g\nOutput: umount: /var/lib/kubelet/pods/5c948341-c030-4996-b888-f032577d97b0/volumes/kubernetes.io~glusterfs/cam-pv-50g：Target is busy.\n        (In some case using lsof(8) or fuser(1) can\n find useful information about the process using the device)\n\n&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="suspicious-points"></a></p>
<h2 id="Suspicious-Points"><a href="#Suspicious-Points" class="headerlink" title="Suspicious Points"></a>Suspicious Points</h2><h3 id="Suspicious-Point-1-Pod-IP-Retrieval-Failure-1"><a href="#Suspicious-Point-1-Pod-IP-Retrieval-Failure-1" class="headerlink" title=" Suspicious Point 1: Pod IP Retrieval Failure"></a><a name="suspicious-point-1-pod-ip-retrieval-failure"></a> Suspicious Point 1: Pod IP Retrieval Failure</h3><p>The log indicates a failure to retrieve the Pod IP:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">W0728 16:25:19.303513    9744 docker_sandbox.go:384] failed to <span class="built_in">read</span> pod IP from plugin/docker: NetworkPlugin cni failed on the status hook <span class="keyword">for</span> pod <span class="string">&quot;cam1-78b6fc6bc8-cjsw5_cam&quot;</span>: Unexpected <span class="built_in">command</span> output Device <span class="string">&quot;eth0&quot;</span> does not exist.</span><br><span class="line"> with error: <span class="built_in">exit</span> status 1</span><br></pre></td></tr></table></figure>

<p>This error was traced to the <code>getIP</code> method in the <code>docker_sandbox.go</code> file:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ds *dockerService)</span></span> getIP(podSandboxID <span class="type">string</span>, sandbox *dockertypes.ContainerJSON) <span class="type">string</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> sandbox.NetworkSettings == <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> networkNamespaceMode(sandbox) == runtimeapi.NamespaceMode_NODE &#123;</span><br><span class="line">        <span class="comment">// For sandboxes using host network, the shim is not responsible for</span></span><br><span class="line">        <span class="comment">// reporting the IP.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Don&#x27;t bother getting IP if the pod is known and networking isn&#x27;t ready</span></span><br><span class="line">    ready, ok := ds.getNetworkReady(podSandboxID)</span><br><span class="line">    <span class="keyword">if</span> ok &amp;&amp; !ready &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ip, err := ds.getIPFromPlugin(sandbox)</span><br><span class="line">    <span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ip</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> sandbox.NetworkSettings.IPAddress != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sandbox.NetworkSettings.IPAddress</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> sandbox.NetworkSettings.GlobalIPv6Address != <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sandbox.NetworkSettings.GlobalIPv6Address</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Error log here</span></span><br><span class="line">    klog.Warningf(<span class="string">&quot;failed to read pod IP from plugin/docker: %v&quot;</span>, err)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Suspicious-Point-2-Unmount-Failure-1"><a href="#Suspicious-Point-2-Unmount-Failure-1" class="headerlink" title=" Suspicious Point 2: Unmount Failure"></a><a name="suspicious-point-2-unmount-failure"></a> Suspicious Point 2: Unmount Failure</h3><p>The unmount failure was logged as an ERROR:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E0728 16:25:20.939400    9744 nestedpendingoperations.go:301] Operation <span class="keyword">for</span> <span class="string">&quot;&#123;volumeName:kubernetes.io/glusterfs/5c948341-c030-4996-b888-f032577d97b0-cam-pv-50g podName:5c948341-c030-4996-b888-f032577d97b0 nodeName:&#125;&quot;</span> failed. No retries permitted <span class="keyword">until</span> 2021-07-28 16:25:21.439325811 +0800 CST m=+199182.605079651 (durationBeforeRetry 500ms). Error: <span class="string">&quot;UnmountVolume.TearDown failed for volume \&quot;diag-log\&quot; (UniqueName: \&quot;kubernetes.io/glusterfs/5c948341-c030-4996-b888-f032577d97b0-cam-pv-50g\&quot;) pod \&quot;5c948341-c030-4996-b888-f032577d97b0\&quot; (UID: \&quot;5c948341-c030-4996-b888-f032577d97b0\&quot;) : Unmount failed: exit status 32\nUnmounting arguments: /var/lib/kubelet/pods/5c948341-c030-4996-b888-f032577d97b0/volumes/kubernetes.io~glusterfs/cam-pv-50g\nOutput: umount: /var/lib/kubelet/pods/5c948341-c030-4996-b888-f032577d97b0/volumes/kubernetes.io~glusterfs/cam-pv-50g：Target is busy.\n        (In some case using lsof(8) or fuser(1) can\n find useful information about the process using the device)\n\n&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="pod-deletion-process"></a></p>
<h2 id="Pod-Deletion-Process"><a href="#Pod-Deletion-Process" class="headerlink" title="Pod Deletion Process"></a>Pod Deletion Process</h2><p>The deletion of a Pod in Kubernetes follows these steps:</p>
<ol>
<li><strong>API Server DELETE Call</strong>: The <code>kubectl delete</code> command triggers a DELETE request to the Kubernetes API server with a default grace period of 30 seconds.</li>
<li><strong>Update Pod Metadata</strong>: The Pod’s metadata is updated with <code>DeletionTimestamp</code> and <code>DeletionGracePeriodSeconds</code> fields, but the Pod is not yet deleted from etcd.</li>
<li><strong>Kubelet Event Handling</strong>: The kubelet component listens for Pod updates and initiates the <code>killPod()</code> method.</li>
<li><strong>Second DELETE Call</strong>: The kubelet makes a second DELETE request to the API server with a grace period of 0 seconds.</li>
<li><strong>Pod Deletion from etcd</strong>: The API server deletes the Pod from etcd.</li>
</ol>
<hr>
<p><a name="verification-and-testing"></a></p>
<h2 id="Verification-and-Testing"><a href="#Verification-and-Testing" class="headerlink" title="Verification and Testing"></a>Verification and Testing</h2><p>To verify the deletion process, a test was conducted in a test environment:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 ~]# kubectl delete pod -n xxx testpodrc2-7b749f6c9c-qh68l</span><br><span class="line">pod <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l&quot;</span> deleted</span><br></pre></td></tr></table></figure>

<p>Filtered kubelet logs:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">I0730 13:27:31.854178   24588 kubelet.go:1904] SyncLoop (DELETE, <span class="string">&quot;api&quot;</span>): <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span></span><br><span class="line">I0730 13:27:31.854511   24588 kuberuntime_container.go:581] Killing container <span class="string">&quot;docker://e2a1cd5f2165e12cf0b46e12f9cd4d656d593f75e85c0de058e0a2f376a5557e&quot;</span> with 30 second grace period</span><br><span class="line">I0730 13:27:32.203167   24588 kubelet.go:1904] SyncLoop (DELETE, <span class="string">&quot;api&quot;</span>): <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span></span><br><span class="line">I0730 13:27:32.993294   24588 kubelet.go:1933] SyncLoop (PLEG): <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span>, event: &amp;pleg.PodLifecycleEvent&#123;ID:<span class="string">&quot;85ee282f-a843-4f10-a99c-79d447f83f2a&quot;</span>, Type:<span class="string">&quot;ContainerDied&quot;</span>, Data:<span class="string">&quot;e2a1cd5f2165e12cf0b46e12f9cd4d656d593f75e85c0de058e0a2f376a5557e&quot;</span>&#125;</span><br><span class="line">I0730 13:27:32.993428   24588 kubelet.go:1933] SyncLoop (PLEG): <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span>, event: &amp;pleg.PodLifecycleEvent&#123;ID:<span class="string">&quot;85ee282f-a843-4f10-a99c-79d447f83f2a&quot;</span>, Type:<span class="string">&quot;ContainerDied&quot;</span>, Data:<span class="string">&quot;c6a587614976beed0cbb6e5fabf70a2d039eec6c160154fce007fe2bb1ba3b4f&quot;</span>&#125;</span><br><span class="line">I0730 13:27:34.072494   24588 kubelet_pods.go:1090] Killing unwanted pod <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l&quot;</span></span><br><span class="line">I0730 13:27:40.084182   24588 kubelet.go:1904] SyncLoop (DELETE, <span class="string">&quot;api&quot;</span>): <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span></span><br><span class="line">I0730 13:27:40.085735   24588 kubelet.go:1898] SyncLoop (REMOVE, <span class="string">&quot;api&quot;</span>): <span class="string">&quot;testpodrc2-7b749f6c9c-qh68l_testpod(85ee282f-a843-4f10-a99c-79d447f83f2a)&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The analysis revealed that the Pod remained in the <code>Terminating</code> state due to a failure in unmounting the GlusterFS volume. The unmount failure was caused by the volume being busy, which prevented the second DELETE</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Deep-Dive-into-Avro-and-Parquet-Together/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Deep-Dive-into-Avro-and-Parquet-Together/" class="post-title-link" itemprop="url">Deep Dive into Avro and Parquet Together</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 17:33:14" itemprop="dateCreated datePublished" datetime="2024-10-28T17:33:14-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/" itemprop="url" rel="index"><span itemprop="name">Deep Dive</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/Avro/" itemprop="url" rel="index"><span itemprop="name">Avro</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/Avro/Parquet/" itemprop="url" rel="index"><span itemprop="name">Parquet</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#architecture-overview">Architecture Overview</a></li>
<li><a href="#data-pipeline-design">Data Pipeline Design</a><ul>
<li><a href="#ingesting-data-from-messaging-system">Ingesting Data from Messaging System</a></li>
<li><a href="#processing-and-converting-avro-to-parquet">Processing and Converting Avro to Parquet</a></li>
<li><a href="#saving-to-big-data-storage-s3">Saving to Big Data Storage (S3)</a></li>
</ul>
</li>
<li><a href="#understanding-the-structural-differences">Understanding the Structural Differences</a><ul>
<li><a href="#avro-to-parquet-conversion">Avro to Parquet Conversion</a></li>
<li><a href="#reading-from-parquet-and-converting-back-to-avro">Reading from Parquet and Converting Back to Avro</a></li>
</ul>
</li>
<li><a href="#parquets-row-groups-and-column-chunks">Parquet’s Row Groups and Column Chunks</a><ul>
<li><a href="#-ensuring-data-belongs-to-the-same-record"> Ensuring Data Belongs to the Same Record</a></li>
<li><a href="#reading-from-parquet-and-converting-back-to-avro-1">Reading from Parquet and Converting Back to Avro</a></li>
</ul>
</li>
<li><a href="#what-if-null-values-in-parquet">What if Null Values in Parquet</a><ul>
<li><a href="#1-null-values-in-columns">1. <strong>Null Values in Columns</strong></a></li>
<li><a href="#2-encodings-for-efficient-storage">2. <strong>Encodings for Efficient Storage</strong></a></li>
<li><a href="#3-metadata-tracking-and-optional-fields">3. <strong>Metadata Tracking and Optional Fields</strong></a></li>
<li><a href="#example-scenario">Example Scenario</a></li>
<li><a href="#example-in-spark">Example in Spark</a></li>
</ul>
</li>
<li><a href="#real-life-production-sample-code-in-spark">Real-Life Production Sample Code in Spark</a><ul>
<li><a href="#-reading-from-kafka"> Reading from Kafka</a></li>
<li><a href="#-converting-avro-to-parquet"> Converting Avro to Parquet</a></li>
<li><a href="#-writing-to-s3"> Writing to S3</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In modern data architectures, Avro data is often used in messaging systems like Apache Kafka due to its compact binary format and schema evolution support. However, in data lakes or data warehouses, Parquet is preferred for storage due to its columnar format and efficient read performance. This article covers the architecture, pipeline design, and real-life sample code for implementing a pipeline that ingests Avro data from a messaging system and saves it in Parquet format in a big data storage solution like Amazon S3.</p>
<hr>
<p><a name="architecture-overview"></a></p>
<h2 id="Architecture-Overview"><a href="#Architecture-Overview" class="headerlink" title="Architecture Overview"></a>Architecture Overview</h2><p>This section provides an overview of the components in a typical architecture that ingests Avro from a messaging system and saves it as Parquet in big data storage.</p>
<p><strong>Diagram: Avro to Parquet Pipeline Architecture</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Messaging System (Kafka)  ----&gt;  Stream Processing (Spark)  ----&gt;  S3 Storage (Parquet Format)</span><br></pre></td></tr></table></figure>

<p><a name="avro-and-parquet-formats"></a>###  Avro and Parquet Formats</p>
<ul>
<li><strong>Avro</strong>: A row-based binary format, commonly used for serializing data in messaging systems due to its compact size and schema evolution capabilities.</li>
<li><strong>Parquet</strong>: A columnar storage format optimized for reading specific columns, making it highly efficient for analytics and big data storage solutions.</li>
</ul>
<p><a name="role-of-messaging-systems"></a>###  Role of Messaging Systems</p>
<p>Messaging systems like <strong>Apache Kafka</strong> are widely used to transport streaming data across systems in real time. Kafka provides fault-tolerance and durability, ensuring data is safely delivered to downstream applications for processing.</p>
<p><a name="storage-in-big-data-storage-solutions"></a>###  Storage in Big Data Storage Solutions</p>
<p>Big data storage solutions, such as <strong>Amazon S3</strong>, offer durable and cost-effective storage for large-scale data. Storing data in Parquet format on S3 enables easy integration with data analytics frameworks like Spark, Presto, and Hive.</p>
<hr>
<p><a name="data-pipeline-design"></a></p>
<h2 id="Data-Pipeline-Design"><a href="#Data-Pipeline-Design" class="headerlink" title="Data Pipeline Design"></a>Data Pipeline Design</h2><p>The pipeline includes the following key stages:</p>
<ol>
<li><strong>Data Ingestion</strong>: Consuming Avro-encoded messages from Kafka.</li>
<li><strong>Processing and Transformation</strong>: Converting Avro data to Parquet format.</li>
<li><strong>Storage</strong>: Saving the transformed Parquet files to Amazon S3.</li>
</ol>
<p><a name="ingesting-data-from-messaging-system"></a></p>
<h3 id="Ingesting-Data-from-Messaging-System"><a href="#Ingesting-Data-from-Messaging-System" class="headerlink" title="Ingesting Data from Messaging System"></a>Ingesting Data from Messaging System</h3><p>The first step in the pipeline is ingesting data from a messaging system like Kafka. Spark Structured Streaming can be used to consume Avro-encoded messages from Kafka topics in real-time.</p>
<p><strong>Diagram: Ingesting Avro Data from Kafka</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka Topic (Avro Messages)  ---&gt;  Spark Structured Streaming  ---&gt;  Data Transformation</span><br></pre></td></tr></table></figure>

<p><a name="processing-and-converting-avro-to-parquet"></a></p>
<h3 id="Processing-and-Converting-Avro-to-Parquet"><a href="#Processing-and-Converting-Avro-to-Parquet" class="headerlink" title="Processing and Converting Avro to Parquet"></a>Processing and Converting Avro to Parquet</h3><p>Spark Structured Streaming allows us to process and transform the incoming Avro data. To convert Avro to Parquet, the schema needs to be mapped, and the data is then serialized to the Parquet format.</p>
<p><strong>Diagram: Converting Avro to Parquet in Spark</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Avro Data (Spark DataFrame)  ---&gt;  Schema Mapping  ---&gt;  Parquet Data</span><br></pre></td></tr></table></figure>

<p><a name="saving-to-big-data-storage-s3"></a></p>
<h3 id="Saving-to-Big-Data-Storage-S3"><a href="#Saving-to-Big-Data-Storage-S3" class="headerlink" title="Saving to Big Data Storage (S3)"></a>Saving to Big Data Storage (S3)</h3><p>Once converted to Parquet, the data can be written to Amazon S3 in a structured format. Parquet files in S3 are organized by partitions (e.g., by date or another logical grouping) to optimize retrieval and querying performance.</p>
<p><strong>Diagram: Saving to S3</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Parquet Data (Partitioned by Date)  ---&gt;  Amazon S3 Bucket  ---&gt;  Analytics-ready Storage</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="understanding-the-structural-differences"></a></p>
<h2 id="Understanding-the-Structural-Differences"><a href="#Understanding-the-Structural-Differences" class="headerlink" title="Understanding the Structural Differences"></a>Understanding the Structural Differences</h2><p>In Avro and Parquet formats, the <strong>data organization</strong> is fundamentally different:</p>
<ul>
<li><strong>Avro</strong>: A row-based format where each record is serialized as a single entity, storing all fields of each row together.</li>
<li><strong>Parquet</strong>: A columnar storage format where data is grouped by columns rather than rows, optimizing for efficient reads on specific columns (ideal for analytical workloads).</li>
</ul>
<p>To illustrate, let’s consider an Avro record with two attributes:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;John Doe&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="number">30</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>In Avro, the above record would be stored as a single contiguous block of binary data, with fields appearing in the order defined by the schema.</p>
<p>When converting this record to <strong>Parquet</strong>, the storage layout changes to a <strong>column-oriented format</strong>. Parquet organizes data by columns:</p>
<ul>
<li>Each column (e.g., “name” and “age”) is stored separately in <strong>column chunks</strong>.</li>
<li>Parquet organizes records into <strong>row groups</strong>, where each row group has column chunks for each column defined in the schema.</li>
</ul>
<p><strong>Diagram: Avro to Parquet Conversion for Record <code>&#123; &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 30 &#125;</code></strong></p>
<table>
<thead>
<tr>
<th><strong>Parquet Column Chunk</strong></th>
<th><strong>Data Stored</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Name Column Chunk</td>
<td>John Doe</td>
</tr>
<tr>
<td>Age Column Chunk</td>
<td>30</td>
</tr>
</tbody></table>
<p>In a more extensive dataset with thousands of records, Parquet’s layout significantly optimizes read performance because each column chunk can be accessed independently. For instance, if only the “age” column is required for analysis, Parquet reads only the relevant chunk, skipping over unrelated columns like “name.”</p>
<hr>
<p><a name="avro-to-parquet-conversion"></a></p>
<h3 id="Avro-to-Parquet-Conversion"><a href="#Avro-to-Parquet-Conversion" class="headerlink" title="Avro to Parquet Conversion"></a>Avro to Parquet Conversion</h3><p>The steps for converting Avro to Parquet in a system like Apache Spark generally follow this sequence:</p>
<ol>
<li><p><strong>Avro Data Loading</strong>:</p>
<ul>
<li>Avro-encoded data is parsed and loaded into an intermediate in-memory structure, such as a DataFrame in Spark.</li>
<li>Avro schema is either read from the Avro file (or topic in case of Kafka) or supplied separately.</li>
</ul>
</li>
<li><p><strong>Schema Mapping</strong>:</p>
<ul>
<li>Spark maps the Avro schema to an equivalent internal schema (e.g., Spark schema), which is essential to support Parquet’s columnar structure.</li>
<li>Fields in the Avro schema (like “name” and “age”) are mapped to equivalent columns.</li>
</ul>
</li>
<li><p><strong>Data Conversion</strong>:</p>
<ul>
<li>Each Avro record is then serialized into a format compatible with Parquet’s column-oriented layout.</li>
<li>Each attribute is transformed to be written in column chunks rather than row-by-row.</li>
</ul>
</li>
<li><p><strong>Data Writing (Parquet)</strong>:</p>
<ul>
<li>Parquet organizes data into <strong>row groups</strong>, and within each row group, column data is stored in contiguous chunks.</li>
<li>Additional metadata (e.g., min, max, dictionary encoding) is recorded for each column chunk, which is useful for optimizations in querying.</li>
</ul>
</li>
</ol>
<p><strong>Example</strong>:<br>In Spark, a sample code to convert Avro to Parquet may look like this:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Load Avro data into a DataFrame</span></span><br><span class="line">Dataset&lt;Row&gt; avroDF = spark.read().format(<span class="string">&quot;avro&quot;</span>).load(<span class="string">&quot;path/to/avro/file&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write data to Parquet format</span></span><br><span class="line">avroDF.write().parquet(<span class="string">&quot;path/to/output/parquet&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>This process reorganizes the data from a row-based layout (Avro) to a columnar layout (Parquet).</p>
<hr>
<p><a name="reading-from-parquet-and-converting-back-to-avro"></a></p>
<h3 id="Reading-from-Parquet-and-Converting-Back-to-Avro"><a href="#Reading-from-Parquet-and-Converting-Back-to-Avro" class="headerlink" title="Reading from Parquet and Converting Back to Avro"></a>Reading from Parquet and Converting Back to Avro</h3><p>When reading Parquet data and converting it back to Avro, the system reverses the process, transforming columnar data back into row-based data.</p>
<p><strong>Steps</strong>:</p>
<ol>
<li><p><strong>Load Parquet Data</strong>:</p>
<ul>
<li>Parquet files are read into memory. In a Spark-based setup, this would involve loading Parquet files into a DataFrame.</li>
</ul>
</li>
<li><p><strong>Column Extraction</strong>:</p>
<ul>
<li>Parquet retrieves data by accessing each relevant column chunk. Parquet’s metadata allows efficient navigation to the specific data of interest.</li>
</ul>
</li>
<li><p><strong>Row Assembly</strong>:</p>
<ul>
<li>As each column’s data is accessed, the system assembles rows by gathering data from each column chunk.</li>
<li>The row-based structure compatible with Avro is recreated by combining values from each column for every row.</li>
</ul>
</li>
<li><p><strong>Schema Mapping</strong>:</p>
<ul>
<li>Parquet columns are mapped to Avro fields based on a schema. This schema alignment ensures that columns match Avro’s row-oriented requirements.</li>
<li>The DataFrame (or equivalent data structure) is serialized back into the Avro format.</li>
</ul>
</li>
<li><p><strong>Write to Avro</strong>:</p>
<ul>
<li>The row-based structure is serialized in Avro’s binary format, and the schema is either embedded or referenced as needed.</li>
</ul>
</li>
</ol>
<p><strong>Example Code: Converting Parquet to Avro in Spark</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Load Parquet data into a DataFrame</span></span><br><span class="line">Dataset&lt;Row&gt; parquetDF = spark.read().parquet(<span class="string">&quot;path/to/parquet/file&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write data back to Avro format</span></span><br><span class="line">parquetDF.write().format(<span class="string">&quot;avro&quot;</span>).save(<span class="string">&quot;path/to/output/avro&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>This code converts the columnar Parquet format back into Avro’s row-based format.</p>
<hr>
<p><a name="parquets-row-groups-and-column-chunks"></a></p>
<h2 id="Parquet’s-Row-Groups-and-Column-Chunks"><a href="#Parquet’s-Row-Groups-and-Column-Chunks" class="headerlink" title="Parquet’s Row Groups and Column Chunks"></a>Parquet’s Row Groups and Column Chunks</h2><p>In Parquet, data is stored in <strong>row groups</strong>. Each row group contains data for a set number of rows, and within each row group, data is stored in <strong>column chunks</strong> (one for each column). The row group is Parquet’s key structural element that ensures the association between column data across multiple rows:</p>
<ul>
<li><strong>Row Group</strong>: A set of rows is organized as a contiguous data block. Each row group in Parquet represents a batch of rows from the original dataset.</li>
<li><strong>Column Chunk</strong>: Within each row group, each column’s data is stored in a separate column chunk.</li>
</ul>
<p>For example, if we have a dataset with 10,000 records, it might be divided into several row groups (say 5,000 rows per row group). Each row group then contains the data for the columns <code>name</code> and <code>age</code> in its respective column chunks.</p>
<h3 id="Ensuring-Data-Belongs-to-the-Same-Record"><a href="#Ensuring-Data-Belongs-to-the-Same-Record" class="headerlink" title=" Ensuring Data Belongs to the Same Record"></a><a name="ensuring-data-belongs-to-the-same-record"></a> Ensuring Data Belongs to the Same Record</h3><p>To ensure data from each column belongs to the same record, Parquet relies on <strong>row ordering</strong> within each row group. The ordering within each column chunk of a row group matches across all columns:</p>
<ul>
<li><strong>Ordering</strong>: Each row in a row group corresponds to the same index across all column chunks within that row group. For instance, the first value in the <code>name</code> column chunk of a row group corresponds to the first value in the <code>age</code> column chunk for the same row group.</li>
<li><strong>Offset Metadata</strong>: Parquet uses metadata about the offsets within each column chunk to ensure each row can be reconstructed correctly when reading.</li>
</ul>
<p>So, in your example, the row group might look like this:</p>
<table>
<thead>
<tr>
<th>Row Index</th>
<th>Name Column Chunk</th>
<th>Age Column Chunk</th>
</tr>
</thead>
<tbody><tr>
<td>Row 1</td>
<td>“John Doe”</td>
<td>30</td>
</tr>
<tr>
<td>Row 2</td>
<td>“Jane Smith”</td>
<td>25</td>
</tr>
<tr>
<td>Row 3</td>
<td>“Alice Brown”</td>
<td>28</td>
</tr>
</tbody></table>
<p>Each entry in the <code>name</code> and <code>age</code> column chunks corresponds by index. Parquet uses metadata within the row group and column chunks to indicate where each row begins and ends, making sure that during reads, each row’s data across columns is aligned.</p>
<p><a name="reading-from-parquet-and-converting-back-to-avro"></a></p>
<h3 id="Reading-from-Parquet-and-Converting-Back-to-Avro-1"><a href="#Reading-from-Parquet-and-Converting-Back-to-Avro-1" class="headerlink" title="Reading from Parquet and Converting Back to Avro"></a>Reading from Parquet and Converting Back to Avro</h3><p>When reading Parquet data back into a row-based format (like Avro), the system iterates over each row group:</p>
<ul>
<li><strong>Row Assembly</strong>: For each row in a row group, Parquet retrieves the respective values from each column chunk based on their row index. This reassembles each row’s fields together to form the original record.</li>
<li><strong>Schema Mapping</strong>: The column metadata stored in Parquet includes the schema, allowing the correct assignment of values back to each field in the record.</li>
</ul>
<p><a name="what-if-null-values-in-parquet"></a></p>
<h2 id="What-if-Null-Values-in-Parquet"><a href="#What-if-Null-Values-in-Parquet" class="headerlink" title="What if Null Values in Parquet"></a>What if Null Values in Parquet</h2><p>In Parquet, each <strong>column chunk</strong> within a <strong>row group</strong> holds data in columnar format, and Parquet efficiently handles cases where some rows may lack a value for a given column by using specific encoding and metadata, rather than empty placeholders. Here’s how it manages the scenario:</p>
<h3 id="1-Null-Values-in-Columns"><a href="#1-Null-Values-in-Columns" class="headerlink" title="1. Null Values in Columns"></a>1. <strong>Null Values in Columns</strong></h3><p>   If a column lacks a value for a particular row, Parquet does not insert an empty placeholder. Instead:</p>
<ul>
<li><strong>Definition Levels</strong> are used to indicate whether a value is present or null. Each level specifies if a field has a value or is missing at that row.</li>
<li><strong>Repetition Levels</strong> track nested structures within rows, so nested nulls and repeated fields can be handled in one scan.</li>
</ul>
<h3 id="2-Encodings-for-Efficient-Storage"><a href="#2-Encodings-for-Efficient-Storage" class="headerlink" title="2. Encodings for Efficient Storage"></a>2. <strong>Encodings for Efficient Storage</strong></h3><p>   Parquet uses encodings like <strong>Run-Length Encoding (RLE)</strong> and <strong>Dictionary Encoding</strong> to represent repeated or missing values compactly:</p>
<ul>
<li><strong>Run-Length Encoding</strong> groups consecutive null values (or any repeating values) into a single representation, saving space when large chunks are missing in a column.</li>
<li><strong>Dictionary Encoding</strong> can efficiently map common values (like repeated nulls or default values) using dictionary lookup tables.</li>
</ul>
<h3 id="3-Metadata-Tracking-and-Optional-Fields"><a href="#3-Metadata-Tracking-and-Optional-Fields" class="headerlink" title="3. Metadata Tracking and Optional Fields"></a>3. <strong>Metadata Tracking and Optional Fields</strong></h3><ul>
<li>If a field is defined as <code>optional</code> in the schema, it allows a row to be saved without a value for that field. Parquet only includes these rows in the row group metadata, which helps query engines like Spark identify missing values.</li>
</ul>
<h3 id="Example-Scenario"><a href="#Example-Scenario" class="headerlink" title="Example Scenario"></a>Example Scenario</h3><p>Let’s say we have a Parquet file with three rows and three columns, where one column lacks values for some rows.</p>
<table>
<thead>
<tr>
<th>Row Group</th>
<th>Column A</th>
<th>Column B</th>
<th>Column C</th>
</tr>
</thead>
<tbody><tr>
<td>Row 1</td>
<td>Value 1</td>
<td>Null</td>
<td>Value 3</td>
</tr>
<tr>
<td>Row 2</td>
<td>Value 4</td>
<td>Value 5</td>
<td>Null</td>
</tr>
<tr>
<td>Row 3</td>
<td>Null</td>
<td>Value 6</td>
<td>Value 7</td>
</tr>
</tbody></table>
<p>In this case:</p>
<ul>
<li><strong>Definition Levels</strong> for <code>Column B</code> and <code>Column C</code> would show which rows contain nulls.</li>
<li>The data structure itself would store only the non-null values, reducing storage without explicit placeholders.</li>
</ul>
<p>This approach is particularly useful when handling sparse data, as it minimizes the storage footprint and increases reading efficiency.</p>
<h3 id="Example-in-Spark"><a href="#Example-in-Spark" class="headerlink" title="Example in Spark"></a>Example in Spark</h3><p>Here’s how Spark handles this under the hood when reading Parquet data and converting it back to Avro:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reading from Parquet</span></span><br><span class="line">Dataset&lt;Row&gt; parquetDF = spark.read().parquet(<span class="string">&quot;path/to/parquet/file&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Writing back to Avro, reassembling rows</span></span><br><span class="line">parquetDF.write().format(<span class="string">&quot;avro&quot;</span>).save(<span class="string">&quot;path/to/output/avro&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>During this process, Spark ensures that each row’s values across columns are correctly aligned by leveraging Parquet’s row group and column chunk metadata. This alignment allows it to convert back to Avro’s row-based format without losing the association between <code>name</code> and <code>age</code> in each record.</p>
<hr>
<p><a name="real-life-production-sample-code-in-spark"></a></p>
<h2 id="Real-Life-Production-Sample-Code-in-Spark"><a href="#Real-Life-Production-Sample-Code-in-Spark" class="headerlink" title="Real-Life Production Sample Code in Spark"></a>Real-Life Production Sample Code in Spark</h2><p>The following sample code demonstrates how to implement this pipeline in <strong>Apache Spark</strong> with <strong>Structured Streaming</strong>.</p>
<h3 id="Reading-from-Kafka"><a href="#Reading-from-Kafka" class="headerlink" title=" Reading from Kafka"></a><a name="reading-from-kafka"></a> Reading from Kafka</h3><p>Use Spark to read Avro data from a Kafka topic in real-time.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.avro.functions.from_avro;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AvroToParquetPipeline</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder()</span><br><span class="line">                .appName(<span class="string">&quot;Avro to Parquet Pipeline&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">kafkaBootstrapServers</span> <span class="operator">=</span> <span class="string">&quot;kafka-broker1:9092,kafka-broker2:9092&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">kafkaTopic</span> <span class="operator">=</span> <span class="string">&quot;avro-topic&quot;</span>;</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; avroDF = spark</span><br><span class="line">                .readStream()</span><br><span class="line">                .format(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;kafka.bootstrap.servers&quot;</span>, kafkaBootstrapServers)</span><br><span class="line">                .option(<span class="string">&quot;subscribe&quot;</span>, kafkaTopic)</span><br><span class="line">                .load()</span><br><span class="line">                .selectExpr(<span class="string">&quot;CAST(value AS BINARY) as avroData&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Define the Avro schema (can be fetched from Schema Registry if available)</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">avroSchema</span> <span class="operator">=</span> <span class="string">&quot;&#123; \&quot;type\&quot;: \&quot;record\&quot;, \&quot;name\&quot;: \&quot;User\&quot;, \&quot;fields\&quot;: [ &#123;\&quot;name\&quot;: \&quot;id\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;, &#123;\&quot;name\&quot;: \&quot;name\&quot;, \&quot;type\&quot;: \&quot;string\&quot;&#125;, &#123;\&quot;name\&quot;: \&quot;age\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125; ] &#125;&quot;</span>;</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; parsedDF = avroDF</span><br><span class="line">                .select(from_avro(avroDF.col(<span class="string">&quot;avroData&quot;</span>), avroSchema).as(<span class="string">&quot;data&quot;</span>))</span><br><span class="line">                .select(<span class="string">&quot;data.*&quot;</span>);</span><br><span class="line"></span><br><span class="line">        parsedDF.printSchema(); <span class="comment">// Debugging schema after parsing Avro</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Converting-Avro-to-Parquet"><a href="#Converting-Avro-to-Parquet" class="headerlink" title=" Converting Avro to Parquet"></a><a name="converting-avro-to-parquet"></a> Converting Avro to Parquet</h3><p>Once we have parsed the Avro data into a DataFrame, we can convert it into Parquet format.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Dataset&lt;Row&gt; parquetDF = parsedDF.repartition(<span class="number">1</span>); <span class="comment">// Optional: Customize partitioning as needed</span></span><br></pre></td></tr></table></figure>

<h3 id="Writing-to-S3"><a href="#Writing-to-S3" class="headerlink" title=" Writing to S3"></a><a name="writing-to-s3"></a> Writing to S3</h3><p>Writing the data to Amazon S3 requires specifying the destination path and configuring partitioning if necessary.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.streaming.Trigger;</span><br><span class="line"></span><br><span class="line"><span class="type">String</span> <span class="variable">s3Path</span> <span class="operator">=</span> <span class="string">&quot;s3a://your-bucket/path/to/destination/&quot;</span>;</span><br><span class="line"></span><br><span class="line">parquetDF.writeStream()</span><br><span class="line">        .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">        .option(<span class="string">&quot;path&quot;</span>, s3Path)</span><br><span class="line">        .option(<span class="string">&quot;checkpointLocation&quot;</span>, <span class="string">&quot;s3a://your-bucket/path/to/checkpoint/&quot;</span>)</span><br><span class="line">        .partitionBy(<span class="string">&quot;date&quot;</span>) <span class="comment">// Optional: Partitioning by a specific column (e.g., date)</span></span><br><span class="line">        .trigger(Trigger.ProcessingTime(<span class="string">&quot;5 minutes&quot;</span>)) <span class="comment">// Controls batch frequency</span></span><br><span class="line">        .start()</span><br><span class="line">        .awaitTermination();</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This article covered an architecture for ingesting Avro data from a messaging system, converting it to Parquet, and saving it in Amazon S3. Using Spark Structured Streaming and Amazon S3 for storage, this pipeline is a robust solution for managing Avro-to-Parquet transformations in big data applications. Understanding the structural differences between Avro and Parquet, as well as the conversion process, enables data engineers to design efficient and scalable data pipelines.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Avro-to-Parquet-Pipeline-in-Big-Data-Applications/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Avro-to-Parquet-Pipeline-in-Big-Data-Applications/" class="post-title-link" itemprop="url">Avro to Parquet Pipeline in Big Data Applications</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 16:32:41" itemprop="dateCreated datePublished" datetime="2024-10-28T16:32:41-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Avro/" itemprop="url" rel="index"><span itemprop="name">Avro</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Avro/Parquet/" itemprop="url" rel="index"><span itemprop="name">Parquet</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#architecture-overview">Architecture Overview</a><ul>
<li><a href="#-avro-and-parquet-formats"> Avro and Parquet Formats</a></li>
<li><a href="#-role-of-messaging-systems"> Role of Messaging Systems</a></li>
<li><a href="#-storage-in-big-data-storage-solutions"> Storage in Big Data Storage Solutions</a></li>
</ul>
</li>
<li><a href="#data-pipeline-design">Data Pipeline Design</a><ul>
<li><a href="#ingesting-data-from-messaging-system">Ingesting Data from Messaging System</a></li>
<li><a href="#processing-and-converting-avro-to-parquet">Processing and Converting Avro to Parquet</a></li>
<li><a href="#saving-to-big-data-storage-s3">Saving to Big Data Storage (S3)</a></li>
</ul>
</li>
<li><a href="#real-life-production-sample-code-in-spark">Real-Life Production Sample Code in Spark</a><ul>
<li><a href="#-reading-from-kafka"> Reading from Kafka</a></li>
<li><a href="#-converting-avro-to-parquet"> Converting Avro to Parquet</a></li>
<li><a href="#-writing-to-s3"> Writing to S3</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In modern data architectures, Avro data is often used in messaging systems like Apache Kafka due to its compact binary format and schema evolution support. However, in data lakes or data warehouses, Parquet is preferred for storage due to its columnar format and efficient read performance. This article covers the architecture, pipeline design, and real-life sample code for implementing a pipeline that ingests Avro data from a messaging system and saves it in Parquet format in a big data storage solution like Amazon S3.</p>
<hr>
<p><a name="architecture-overview"></a></p>
<h2 id="Architecture-Overview"><a href="#Architecture-Overview" class="headerlink" title="Architecture Overview"></a>Architecture Overview</h2><p>This section provides an overview of the components in a typical architecture that ingests Avro from a messaging system and saves it as Parquet in big data storage.</p>
<p><strong>Diagram: Avro to Parquet Pipeline Architecture</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Messaging System (Kafka)  ----&gt;  Stream Processing (Spark)  ----&gt;  S3 Storage (Parquet Format)</span><br></pre></td></tr></table></figure>

<h3 id="Avro-and-Parquet-Formats"><a href="#Avro-and-Parquet-Formats" class="headerlink" title=" Avro and Parquet Formats"></a><a name="avro-and-parquet-formats"></a> Avro and Parquet Formats</h3><ul>
<li><strong>Avro</strong>: A row-based binary format, commonly used for serializing data in messaging systems due to its compact size and schema evolution capabilities.</li>
<li><strong>Parquet</strong>: A columnar storage format optimized for reading specific columns, making it highly efficient for analytics and big data storage solutions.</li>
</ul>
<h3 id="Role-of-Messaging-Systems"><a href="#Role-of-Messaging-Systems" class="headerlink" title=" Role of Messaging Systems"></a><a name="role-of-messaging-systems"></a> Role of Messaging Systems</h3><p>Messaging systems like <strong>Apache Kafka</strong> are widely used to transport streaming data across systems in real time. Kafka provides fault-tolerance and durability, ensuring data is safely delivered to downstream applications for processing.</p>
<h3 id="Storage-in-Big-Data-Storage-Solutions"><a href="#Storage-in-Big-Data-Storage-Solutions" class="headerlink" title=" Storage in Big Data Storage Solutions"></a><a name="storage-in-big-data-storage-solutions"></a> Storage in Big Data Storage Solutions</h3><p>Big data storage solutions, such as <strong>Amazon S3</strong>, offer durable and cost-effective storage for large-scale data. Storing data in Parquet format on S3 enables easy integration with data analytics frameworks like Spark, Presto, and Hive.</p>
<hr>
<p><a name="data-pipeline-design"></a></p>
<h2 id="Data-Pipeline-Design"><a href="#Data-Pipeline-Design" class="headerlink" title="Data Pipeline Design"></a>Data Pipeline Design</h2><p>The pipeline includes the following key stages:</p>
<ol>
<li><strong>Data Ingestion</strong>: Consuming Avro-encoded messages from Kafka.</li>
<li><strong>Processing and Transformation</strong>: Converting Avro data to Parquet format.</li>
<li><strong>Storage</strong>: Saving the transformed Parquet files to Amazon S3.</li>
</ol>
<p><a name="ingesting-data-from-messaging-system"></a></p>
<h3 id="Ingesting-Data-from-Messaging-System"><a href="#Ingesting-Data-from-Messaging-System" class="headerlink" title="Ingesting Data from Messaging System"></a>Ingesting Data from Messaging System</h3><p>The first step in the pipeline is ingesting data from a messaging system like Kafka. Spark Structured Streaming can be used to consume Avro-encoded messages from Kafka topics in real-time.</p>
<p><strong>Diagram: Ingesting Avro Data from Kafka</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka Topic (Avro Messages)  ---&gt;  Spark Structured Streaming  ---&gt;  Data Transformation</span><br></pre></td></tr></table></figure>

<p><a name="processing-and-converting-avro-to-parquet"></a></p>
<h3 id="Processing-and-Converting-Avro-to-Parquet"><a href="#Processing-and-Converting-Avro-to-Parquet" class="headerlink" title="Processing and Converting Avro to Parquet"></a>Processing and Converting Avro to Parquet</h3><p>Spark Structured Streaming allows us to process and transform the incoming Avro data. To convert Avro to Parquet, the schema needs to be mapped, and the data is then serialized to the Parquet format.</p>
<p><strong>Diagram: Converting Avro to Parquet in Spark</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Avro Data (Spark DataFrame)  ---&gt;  Schema Mapping  ---&gt;  Parquet Data</span><br></pre></td></tr></table></figure>

<p><a name="saving-to-big-data-storage-s3"></a></p>
<h3 id="Saving-to-Big-Data-Storage-S3"><a href="#Saving-to-Big-Data-Storage-S3" class="headerlink" title="Saving to Big Data Storage (S3)"></a>Saving to Big Data Storage (S3)</h3><p>Once converted to Parquet, the data can be written to Amazon S3 in a structured format. Parquet files in S3 are organized by partitions (e.g., by date or another logical grouping) to optimize retrieval and querying performance.</p>
<p><strong>Diagram: Saving to S3</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Parquet Data (Partitioned by Date)  ---&gt;  Amazon S3 Bucket  ---&gt;  Analytics-ready Storage</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="real-life-production-sample-code-in-spark"></a></p>
<h2 id="Real-Life-Production-Sample-Code-in-Spark"><a href="#Real-Life-Production-Sample-Code-in-Spark" class="headerlink" title="Real-Life Production Sample Code in Spark"></a>Real-Life Production Sample Code in Spark</h2><p>The following sample code demonstrates how to implement this pipeline in <strong>Apache Spark</strong> with <strong>Structured Streaming</strong>.</p>
<h3 id="Reading-from-Kafka"><a href="#Reading-from-Kafka" class="headerlink" title=" Reading from Kafka"></a><a name="reading-from-kafka"></a> Reading from Kafka</h3><p>Use Spark to read Avro data from a Kafka topic in real-time.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.SparkSession;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Dataset;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.Row;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.avro.functions.from_avro;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AvroToParquetPipeline</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder()</span><br><span class="line">                .appName(<span class="string">&quot;Avro to Parquet Pipeline&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">kafkaBootstrapServers</span> <span class="operator">=</span> <span class="string">&quot;kafka-broker1:9092,kafka-broker2:9092&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">kafkaTopic</span> <span class="operator">=</span> <span class="string">&quot;avro-topic&quot;</span>;</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; avroDF = spark</span><br><span class="line">                .readStream()</span><br><span class="line">                .format(<span class="string">&quot;kafka&quot;</span>)</span><br><span class="line">                .option(<span class="string">&quot;kafka.bootstrap.servers&quot;</span>, kafkaBootstrapServers)</span><br><span class="line">                .option(<span class="string">&quot;subscribe&quot;</span>, kafkaTopic)</span><br><span class="line">                .load()</span><br><span class="line">                .selectExpr(<span class="string">&quot;CAST(value AS BINARY) as avroData&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Define the Avro schema (can be fetched from Schema Registry if available)</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">avroSchema</span> <span class="operator">=</span> <span class="string">&quot;&#123; \&quot;type\&quot;: \&quot;record\&quot;, \&quot;name\&quot;: \&quot;User\&quot;, \&quot;fields\&quot;: [ &#123;\&quot;name\&quot;: \&quot;id\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125;, &#123;\&quot;name\&quot;: \&quot;name\&quot;, \&quot;type\&quot;: \&quot;string\&quot;&#125;, &#123;\&quot;name\&quot;: \&quot;age\&quot;, \&quot;type\&quot;: \&quot;int\&quot;&#125; ] &#125;&quot;</span>;</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; parsedDF = avroDF</span><br><span class="line">                .select(from_avro(avroDF.col(<span class="string">&quot;avroData&quot;</span>), avroSchema).as(<span class="string">&quot;data&quot;</span>))</span><br><span class="line">                .select(<span class="string">&quot;data.*&quot;</span>);</span><br><span class="line"></span><br><span class="line">        parsedDF.printSchema(); <span class="comment">// Debugging schema after parsing Avro</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Converting-Avro-to-Parquet"><a href="#Converting-Avro-to-Parquet" class="headerlink" title=" Converting Avro to Parquet"></a><a name="converting-avro-to-parquet"></a> Converting Avro to Parquet</h3><p>Once we have parsed the Avro data into a DataFrame, we can convert it into Parquet format.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Dataset&lt;Row&gt; parquetDF = parsedDF.repartition(<span class="number">1</span>); <span class="comment">// Optional: Customize partitioning as needed</span></span><br></pre></td></tr></table></figure>

<h3 id="Writing-to-S3"><a href="#Writing-to-S3" class="headerlink" title=" Writing to S3"></a><a name="writing-to-s3"></a> Writing to S3</h3><p>Writing the data to Amazon S3 requires specifying the destination path and configuring partitioning if necessary.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.streaming.Trigger;</span><br><span class="line"></span><br><span class="line"><span class="type">String</span> <span class="variable">s3Path</span> <span class="operator">=</span> <span class="string">&quot;s3a://your-bucket/path/to/destination/&quot;</span>;</span><br><span class="line"></span><br><span class="line">parquetDF.writeStream()</span><br><span class="line">        .format(<span class="string">&quot;parquet&quot;</span>)</span><br><span class="line">        .option(<span class="string">&quot;path&quot;</span>, s3Path)</span><br><span class="line">        .option(<span class="string">&quot;checkpointLocation&quot;</span>, <span class="string">&quot;s3a://your-bucket/path/to/checkpoint/&quot;</span>)</span><br><span class="line">        .partitionBy(<span class="string">&quot;date&quot;</span>) <span class="comment">// Optional: Partitioning by a specific column (e.g., date)</span></span><br><span class="line">        .trigger(Trigger.ProcessingTime(<span class="string">&quot;5 minutes&quot;</span>)) <span class="comment">// Controls batch frequency</span></span><br><span class="line">        .start()</span><br><span class="line">        .awaitTermination();</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This article covered an architecture for ingesting Avro data from a messaging system, converting it to Parquet, and saving it in Amazon S3. Using Spark Structured Streaming and Amazon S3 for storage, this pipeline is a robust solution for managing Avro-to-Parquet transformations in big data applications.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Deep-Dive-into-Spring-Scheduler/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Deep-Dive-into-Spring-Scheduler/" class="post-title-link" itemprop="url">Deep Dive into Spring Scheduler</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 16:20:09" itemprop="dateCreated datePublished" datetime="2024-10-28T16:20:09-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/" itemprop="url" rel="index"><span itemprop="name">Deep Dive</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/Spring-Boot/" itemprop="url" rel="index"><span itemprop="name">Spring Boot</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/Spring-Boot/Spring-Scheduler/" itemprop="url" rel="index"><span itemprop="name">Spring Scheduler</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#understanding-spring-scheduler-basics">Understanding Spring Scheduler Basics</a><ul>
<li><a href="#enabling-scheduling">Enabling Scheduling</a></li>
<li><a href="#simple-scheduling-with-scheduled">Simple Scheduling with <code>@Scheduled</code></a></li>
</ul>
</li>
<li><a href="#scheduling-scenarios">Scheduling Scenarios</a><ul>
<li><a href="#sequential-job-execution">Sequential Job Execution</a></li>
<li><a href="#parallel-job-execution">Parallel Job Execution</a></li>
<li><a href="#job-waiting-until-previous-job-completes">Job Waiting Until Previous Job Completes</a></li>
</ul>
</li>
<li><a href="#cron-expressions-and-fixed-rates">Cron Expressions and Fixed Rates</a><ul>
<li><a href="#fixed-rate-vs-fixed-delay">Fixed Rate vs Fixed Delay</a></li>
<li><a href="#using-cron-expressions">Using Cron Expressions</a></li>
</ul>
</li>
<li><a href="#conditional-scheduling-with-annotations">Conditional Scheduling with Annotations</a><ul>
<li><a href="#conditional-scheduling-example">Conditional Scheduling Example</a></li>
</ul>
</li>
<li><a href="#all-in-one-sample">All-In-One Sample</a></li>
<li><a href="#conditionalonproperty-with-scheduled-job-in-depth">ConditionalOnProperty with Scheduled Job in Depth</a><ul>
<li><a href="#scenario-running-a-scheduled-job-in-only-one-pod-in-a-kubernetes-cluster">Scenario: Running a Scheduled Job in Only One Pod in a Kubernetes Cluster</a><ul>
<li><a href="#solution-outline">Solution Outline</a></li>
<li><a href="#steps-to-implement">Steps to Implement</a></li>
<li><a href="#additional-consideration-use-leader-election">Additional Consideration: Use Leader Election</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Spring Scheduler</strong> provides a simple way to schedule tasks within a Spring application. It offers flexibility in managing <strong>time-based events</strong> and <strong>task execution</strong>, allowing developers to configure tasks in a variety of ways, including sequential, parallel, and conditional execution.</p>
<hr>
<p><a name="understanding-spring-scheduler-basics"></a></p>
<h2 id="Understanding-Spring-Scheduler-Basics"><a href="#Understanding-Spring-Scheduler-Basics" class="headerlink" title="Understanding Spring Scheduler Basics"></a>Understanding Spring Scheduler Basics</h2><p>Spring Scheduler uses annotations to simplify the scheduling of methods within beans. The primary annotation used is <code>@Scheduled</code>, which can define various timing configurations, such as fixed rate, fixed delay, and cron expressions.</p>
<p><a name="enabling-scheduling"></a></p>
<h3 id="Enabling-Scheduling"><a href="#Enabling-Scheduling" class="headerlink" title="Enabling Scheduling"></a>Enabling Scheduling</h3><p>Before defining tasks, enable scheduling in your Spring application by adding the <code>@EnableScheduling</code> annotation.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.EnableScheduling;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableScheduling</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SchedulingConfig</span> &#123;</span><br><span class="line">    <span class="comment">// Any other scheduling-related configuration if needed</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="simple-scheduling-with-scheduled"></a></p>
<h3 id="Simple-Scheduling-with-Scheduled"><a href="#Simple-Scheduling-with-Scheduled" class="headerlink" title="Simple Scheduling with @Scheduled"></a>Simple Scheduling with <code>@Scheduled</code></h3><p>The <code>@Scheduled</code> annotation can be applied to any method to enable scheduling. Below is a simple example:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SimpleScheduler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedRate = 5000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">printMessage</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;This message prints every 5 seconds.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In this example, <code>printMessage()</code> runs every 5 seconds.</p>
<hr>
<p><a name="scheduling-scenarios"></a></p>
<h2 id="Scheduling-Scenarios"><a href="#Scheduling-Scenarios" class="headerlink" title="Scheduling Scenarios"></a>Scheduling Scenarios</h2><p>Spring Scheduler supports various scenarios for task scheduling, which can be useful for specific use cases in a production environment.</p>
<p><a name="sequential-job-execution"></a></p>
<h3 id="Sequential-Job-Execution"><a href="#Sequential-Job-Execution" class="headerlink" title="Sequential Job Execution"></a>Sequential Job Execution</h3><p>In sequential execution, jobs run in a specific order, with each job waiting for the previous one to complete before starting.</p>
<p><strong>Example: Sequential Scheduling Using Fixed Delay</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequentialScheduler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedDelay = 10000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">job1</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Job 1 started.&quot;</span>);</span><br><span class="line">        <span class="comment">// simulate a delay</span></span><br><span class="line">        <span class="keyword">try</span> &#123; Thread.sleep(<span class="number">2000</span>); &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;&#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;Job 1 completed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedDelay = 10000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">job2</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Job 2 started after Job 1.&quot;</span>);</span><br><span class="line">        <span class="comment">// simulate a delay</span></span><br><span class="line">        <span class="keyword">try</span> &#123; Thread.sleep(<span class="number">3000</span>); &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;&#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;Job 2 completed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>With <code>fixedDelay</code>, Job 2 only begins after Job 1 completes.</p>
<p><a name="parallel-job-execution"></a></p>
<h3 id="Parallel-Job-Execution"><a href="#Parallel-Job-Execution" class="headerlink" title="Parallel Job Execution"></a>Parallel Job Execution</h3><p>To execute jobs in parallel, we configure a task executor that runs multiple tasks concurrently.</p>
<p><strong>Example: Parallel Scheduling Using a Custom Task Executor</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.EnableAsync;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableAsync</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ParallelSchedulingConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ThreadPoolTaskExecutor <span class="title function_">taskExecutor</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">ThreadPoolTaskExecutor</span> <span class="variable">executor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolTaskExecutor</span>();</span><br><span class="line">        executor.setCorePoolSize(<span class="number">2</span>); <span class="comment">// Number of concurrent tasks allowed</span></span><br><span class="line">        executor.setMaxPoolSize(<span class="number">5</span>);</span><br><span class="line">        executor.initialize();</span><br><span class="line">        <span class="keyword">return</span> executor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Async;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ParallelScheduler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Async</span></span><br><span class="line">    <span class="meta">@Scheduled(fixedRate = 10000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">jobA</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Parallel Job A started.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Async</span></span><br><span class="line">    <span class="meta">@Scheduled(fixedRate = 10000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">jobB</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Parallel Job B started concurrently with Job A.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>With <code>@Async</code>, <code>jobA</code> and <code>jobB</code> run concurrently, allowing for parallel execution.</p>
<p><a name="job-waiting-until-previous-job-completes"></a></p>
<h3 id="Job-Waiting-Until-Previous-Job-Completes"><a href="#Job-Waiting-Until-Previous-Job-Completes" class="headerlink" title="Job Waiting Until Previous Job Completes"></a>Job Waiting Until Previous Job Completes</h3><p>To configure jobs to wait for previous jobs to finish, use <code>fixedDelay</code> with asynchronous methods to ensure that each task waits until its predecessor is completed.</p>
<p><strong>Diagram: Job Waiting until Previous Job Completes</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Job 1   ---&gt; Wait ---&gt;   Job 2   ---&gt; Wait ---&gt;   Job 3</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WaitingScheduler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedDelay = 12000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">job</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Job started and waits until the previous instance completes.&quot;</span>);</span><br><span class="line">        <span class="comment">// Simulate processing time</span></span><br><span class="line">        <span class="keyword">try</span> &#123; Thread.sleep(<span class="number">5000</span>); &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;&#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;Job completed.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In this scenario, each new execution waits until the previous one finishes.</p>
<hr>
<p><a name="cron-expressions-and-fixed-rates"></a></p>
<h2 id="Cron-Expressions-and-Fixed-Rates"><a href="#Cron-Expressions-and-Fixed-Rates" class="headerlink" title="Cron Expressions and Fixed Rates"></a>Cron Expressions and Fixed Rates</h2><p>Spring Scheduler allows defining precise timing patterns using <strong>fixed rate</strong>, <strong>fixed delay</strong>, and <strong>cron expressions</strong>.</p>
<p><a name="fixed-rate-vs-fixed-delay"></a></p>
<h3 id="Fixed-Rate-vs-Fixed-Delay"><a href="#Fixed-Rate-vs-Fixed-Delay" class="headerlink" title="Fixed Rate vs Fixed Delay"></a>Fixed Rate vs Fixed Delay</h3><ul>
<li><strong>Fixed Rate</strong>: Executes a task at a specified interval, regardless of task completion time.</li>
<li><strong>Fixed Delay</strong>: Executes a task with a delay between the end of the previous execution and the start of the next.</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Scheduled(fixedRate = 60000)</span> <span class="comment">// Executes every 60 seconds</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">fixedRateTask</span><span class="params">()</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Fixed Rate Task&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Scheduled(fixedDelay = 60000)</span> <span class="comment">// Executes with a 60-second delay after completion</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">fixedDelayTask</span><span class="params">()</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Fixed Delay Task&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="using-cron-expressions"></a></p>
<h3 id="Using-Cron-Expressions"><a href="#Using-Cron-Expressions" class="headerlink" title="Using Cron Expressions"></a>Using Cron Expressions</h3><p>Cron expressions allow precise scheduling based on time. Format: <code>second minute hour day month weekday</code>.</p>
<p><strong>Example: Scheduling a Task for 5:00 AM Every Day</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Scheduled(cron = &quot;0 0 5 * * ?&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dailyTask</span><span class="params">()</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;This task runs at 5:00 AM every day.&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="conditional-scheduling-with-annotations"></a></p>
<h2 id="Conditional-Scheduling-with-Annotations"><a href="#Conditional-Scheduling-with-Annotations" class="headerlink" title="Conditional Scheduling with Annotations"></a>Conditional Scheduling with Annotations</h2><p>Spring allows scheduling tasks based on conditions. Combining <code>@ConditionalOnProperty</code> with <code>@Scheduled</code>, we can configure tasks to run only when certain conditions are met.</p>
<p><a name="conditional-scheduling-example"></a></p>
<h3 id="Conditional-Scheduling-Example"><a href="#Conditional-Scheduling-Example" class="headerlink" title="Conditional Scheduling Example"></a>Conditional Scheduling Example</h3><p>This example schedules a job only if a specific property is set to <code>true</code>.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConditionalOnProperty(name = &quot;scheduler.enabled&quot;, havingValue = &quot;true&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConditionalScheduler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedRate = 10000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">conditionalTask</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;This task runs only if &#x27;scheduler.enabled=true&#x27;.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>To enable or disable this task, add <code>scheduler.enabled=true</code> or <code>false</code> in the configuration.</p>
<hr>
<p><a name="all-in-one-sample"></a></p>
<h2 id="All-In-One-Sample"><a href="#All-In-One-Sample" class="headerlink" title="All-In-One Sample"></a>All-In-One Sample</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.EnableScheduling;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@EnableScheduling</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProductionSchedulerConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ThreadPoolTaskExecutor <span class="title function_">taskExecutor</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">ThreadPoolTaskExecutor</span> <span class="variable">executor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolTaskExecutor</span>();</span><br><span class="line">        executor.setCorePoolSize(<span class="number">3</span>);</span><br><span class="line">        executor.setMaxPoolSize(<span class="number">5</span>);</span><br><span class="line">        executor.initialize();</span><br><span class="line">        <span class="keyword">return</span> executor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Async;</span><br><span class="line"><span class="keyword">import</span> org.springframework.scheduling.annotation.Scheduled;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConditionalOnProperty(name = &quot;scheduler.enabled&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProductionScheduler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Async</span></span><br><span class="line">    <span class="meta">@Scheduled(cron = &quot;0 0 12 * * ?&quot;)</span> <span class="comment">// Executes at noon daily</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">dailySummaryJob</span><span class="params">()</span> &#123;</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line"> System.out.println(<span class="string">&quot;Executing daily summary job...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Async</span></span><br><span class="line">    <span class="meta">@Scheduled(fixedDelay = 15000)</span> <span class="comment">// Executes every 15 seconds after the previous execution ends</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">periodicCleanupJob</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Running periodic cleanup job...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a name="conditionalonproperty-with-scheduled-job-in-depth"></a></p>
<h2 id="ConditionalOnProperty-with-Scheduled-Job-in-Depth"><a href="#ConditionalOnProperty-with-Scheduled-Job-in-Depth" class="headerlink" title="ConditionalOnProperty with Scheduled Job in Depth"></a>ConditionalOnProperty with Scheduled Job in Depth</h2><p>The <code>@ConditionalOnProperty</code> annotation in Spring is typically used to conditionally enable or disable beans based on specific configuration properties. In this case:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ConditionalOnProperty(name = &quot;scheduler.enabled&quot;, havingValue = &quot;true&quot;)</span></span><br></pre></td></tr></table></figure>

<p>This will activate the annotated bean only if the <code>scheduler.enabled</code> property is set to <code>true</code> in your configuration (like in <code>application.properties</code> or environment variables).</p>
<h3 id="Scenario-Running-a-Scheduled-Job-in-Only-One-Pod-in-a-Kubernetes-Cluster"><a href="#Scenario-Running-a-Scheduled-Job-in-Only-One-Pod-in-a-Kubernetes-Cluster" class="headerlink" title="Scenario: Running a Scheduled Job in Only One Pod in a Kubernetes Cluster"></a>Scenario: Running a Scheduled Job in Only One Pod in a Kubernetes Cluster</h3><p>When deploying a Spring application in a Kubernetes cluster across multiple containers (pods), ensuring that a scheduled job only runs in one specific pod can be tricky because Spring’s <code>@Scheduled</code> jobs will run in every instance where the job bean is active. Here’s how to solve this problem by using the <code>@ConditionalOnProperty</code> annotation in combination with Kubernetes configurations.</p>
<h4 id="Solution-Outline"><a href="#Solution-Outline" class="headerlink" title="Solution Outline"></a>Solution Outline</h4><ol>
<li><strong>Set a Leader Pod</strong>: Configure only one of the pods to have <code>scheduler.enabled=true</code> using Kubernetes annotations and environment variables, making it the leader pod responsible for running the scheduled job.</li>
<li><strong>Configure Pods with Unique Environment Variables</strong>: Use Kubernetes <code>configMaps</code> or <code>Secrets</code> to assign the <code>scheduler.enabled</code> property as <code>true</code> only in the leader pod’s environment. Other pods should not have this property set to <code>true</code>, so they won’t run the job.</li>
</ol>
<h4 id="Steps-to-Implement"><a href="#Steps-to-Implement" class="headerlink" title="Steps to Implement"></a>Steps to Implement</h4><ol>
<li><p><strong>Create a ConfigMap or Secret for the Scheduler Property</strong>:</p>
<ul>
<li>Define a ConfigMap that holds the <code>scheduler.enabled</code> setting for the lead pod.</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">scheduler-config</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">scheduler.enabled:</span> <span class="string">&quot;true&quot;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Use Pod Annotations to Select the Leader Pod</strong>:</p>
<ul>
<li>When deploying multiple replicas, use a label selector or custom script to ensure only one pod is given the <code>scheduler.enabled=true</code> setting.</li>
</ul>
</li>
<li><p><strong>Configure the Deployment to Pass the <code>scheduler.enabled</code> Environment Variable</strong>:</p>
<ul>
<li>In your Kubernetes Deployment file, you can use <code>envFrom</code> to load the environment variables from the ConfigMap, but with a selector so only one pod uses this ConfigMap.</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">scheduler-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span>  <span class="comment"># Running multiple instances</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">scheduler-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">scheduler-app</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">scheduler-container</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">your-image</span></span><br><span class="line">          <span class="attr">envFrom:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">configMapRef:</span></span><br><span class="line">                <span class="attr">name:</span> <span class="string">scheduler-config</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POD_NAME</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.name</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Conditional Logic in Spring Boot</strong>:</p>
<ul>
<li>With <code>@ConditionalOnProperty</code>, the <code>@Scheduled</code> method will only activate if the <code>scheduler.enabled</code> property is <code>true</code>. So, only the pod with the <code>scheduler.enabled=true</code> environment variable will run the job.</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@ConditionalOnProperty(name = &quot;scheduler.enabled&quot;, havingValue = &quot;true&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ScheduledJob</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Scheduled(fixedRate = 5000)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">performTask</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Scheduled job is running on the leader pod!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="Additional-Consideration-Use-Leader-Election"><a href="#Additional-Consideration-Use-Leader-Election" class="headerlink" title="Additional Consideration: Use Leader Election"></a>Additional Consideration: Use Leader Election</h4><p>For robust setups, you could implement leader election to dynamically select the leader pod. This can be achieved using tools like <a target="_blank" rel="noopener" href="https://spring.io/projects/spring-cloud-kubernetes">Spring Cloud Kubernetes Leader Election</a> or implementing a custom leader election mechanism based on a shared lock in an external data store, such as Redis or ZooKeeper.</p>
<p>By setting <code>scheduler.enabled=true</code> conditionally based on which pod is the elected leader, you can ensure the scheduled job runs in only one container at a time, with the ability to switch seamlessly if the leader pod goes down.</p>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Spring Scheduler provides flexibility and control over task scheduling. By using <code>@Scheduled</code> with different configurations, we can create complex scheduling workflows that address specific business needs.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Deep-Dive-into-Avro-and-Parquet-Formats/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Deep-Dive-into-Avro-and-Parquet-Formats/" class="post-title-link" itemprop="url">Deep Dive into Avro and Parquet Formats</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 16:10:12" itemprop="dateCreated datePublished" datetime="2024-10-28T16:10:12-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/" itemprop="url" rel="index"><span itemprop="name">Deep Dive</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/Avro/" itemprop="url" rel="index"><span itemprop="name">Avro</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Deep-Dive/Avro/Parquet/" itemprop="url" rel="index"><span itemprop="name">Parquet</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#understanding-avro-format">Understanding Avro Format</a><ul>
<li><a href="#avro-schema">Avro Schema</a></li>
<li><a href="#avro-schema-in-depth">Avro Schema in Depth</a><ul>
<li><a href="#1-schema-basics">1. <strong>Schema Basics</strong></a></li>
<li><a href="#2-primitive-data-types">2. <strong>Primitive Data Types</strong></a></li>
<li><a href="#3-complex-data-types">3. <strong>Complex Data Types</strong></a></li>
<li><a href="#4-union-types">4. <strong>Union Types</strong></a></li>
<li><a href="#5-default-values">5. <strong>Default Values</strong></a></li>
<li><a href="#6-schema-evolution">6. <strong>Schema Evolution</strong></a></li>
<li><a href="#7-named-types-and-namespaces">7. <strong>Named Types and Namespaces</strong></a></li>
<li><a href="#8-schema-example-with-namespaces">8. <strong>Schema Example with Namespaces</strong></a></li>
</ul>
</li>
<li><a href="#schema-registry">Schema Registry</a></li>
<li><a href="#storage-architecture-for-avro-in-hdfss3">Storage Architecture for Avro in HDFS&#x2F;S3</a></li>
<li><a href="#sample-code-in-spark">Sample Code in Spark</a></li>
</ul>
</li>
<li><a href="#exploring-parquet-format">Exploring Parquet Format</a><ul>
<li><a href="#parquet-schema-and-compression">Parquet Schema and Compression</a></li>
<li><a href="#parquet-schema">Parquet Schema</a><ul>
<li><a href="#1-schema-hierarchy-and-structure">1. <strong>Schema Hierarchy and Structure</strong></a></li>
<li><a href="#2-column-definition-required-optional-repeated">2. <strong>Column Definition: Required, Optional, Repeated</strong></a></li>
<li><a href="#3-definition-and-repetition-levels">3. <strong>Definition and Repetition Levels</strong></a><ul>
<li><a href="#example-parquet-schema">Example Parquet Schema</a></li>
<li><a href="#parquet-structure-definition-and-repetition-levels">Parquet Structure: Definition and Repetition Levels</a></li>
<li><a href="#1-field-name">1. Field: <code>name</code></a></li>
<li><a href="#2-field-contacts">2. Field: <code>contacts</code></a></li>
<li><a href="#3-fields-inside-contacts-type-address-number">3. Fields Inside <code>contacts</code>: <code>type</code>, <code>address</code>, <code>number</code></a></li>
<li><a href="#4-field-addresses">4. Field: <code>addresses</code></a></li>
<li><a href="#5-fields-inside-addresses-street-city">5. Fields Inside <code>addresses</code>: <code>street</code>, <code>city</code></a></li>
<li><a href="#example-encoding-with-levels">Example Encoding with Levels</a></li>
</ul>
</li>
<li><a href="#4-logical-types-and-annotations">4. <strong>Logical Types and Annotations</strong></a></li>
<li><a href="#5-column-index-and-row-group-metadata">5. <strong>Column Index and Row Group Metadata</strong></a></li>
<li><a href="#example-of-a-parquet-schema-in-json-representation">Example of a Parquet Schema in JSON Representation</a></li>
</ul>
</li>
<li><a href="#storage-architecture-for-parquet-in-hdfss3">Storage Architecture for Parquet in HDFS&#x2F;S3</a></li>
<li><a href="#sample-code-in-spark-1">Sample Code in Spark</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>As data systems grow in complexity and scale, choosing efficient data serialization formats becomes crucial. This article provides a deep dive into <strong>Apache Avro</strong> and <strong>Apache Parquet</strong>, two popular formats in the <strong>Big Data</strong> ecosystem. Both formats have distinct characteristics, making them suitable for different types of data and use cases.</p>
<hr>
<p><a name="understanding-avro-format"></a></p>
<h2 id="Understanding-Avro-Format"><a href="#Understanding-Avro-Format" class="headerlink" title="Understanding Avro Format"></a>Understanding Avro Format</h2><p><strong>Apache Avro</strong> is a data serialization format that facilitates the encoding of complex data structures into a compact, binary format, making it highly efficient for streaming and storage.</p>
<p><a name="avro-schema"></a></p>
<h3 id="Avro-Schema"><a href="#Avro-Schema" class="headerlink" title="Avro Schema"></a>Avro Schema</h3><p>The Avro schema describes the structure of data stored in Avro format and is defined using <strong>JSON</strong>. Avro schemas allow the specification of nested fields, and each schema comprises two parts:</p>
<ul>
<li><strong>Primitive types</strong>: <code>null</code>, <code>boolean</code>, <code>int</code>, <code>long</code>, <code>float</code>, <code>double</code>, <code>bytes</code>, and <code>string</code>.</li>
<li><strong>Complex types</strong>: <code>record</code>, <code>enum</code>, <code>array</code>, <code>map</code>, <code>union</code>, and <code>fixed</code>.</li>
</ul>
<p><strong>Example Avro Schema</strong>:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Employee&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;id&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;int&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;name&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;email&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span> <span class="string">&quot;string&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;salary&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;double&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>In this schema:</p>
<ul>
<li>The <code>Employee</code> record has fields <code>id</code>, <code>name</code>, <code>email</code>, and <code>salary</code>.</li>
<li>The <code>email</code> field is optional, allowing <code>null</code> values.</li>
</ul>
<p><a name="avro-schema-in-depth"></a></p>
<h3 id="Avro-Schema-in-Depth"><a href="#Avro-Schema-in-Depth" class="headerlink" title="Avro Schema in Depth"></a>Avro Schema in Depth</h3><p>Apache Avro is a data serialization framework with a focus on compact storage, schema evolution, and interoperability, especially popular in data pipelines with tools like Apache Kafka, Hadoop, and Spark. Avro schema is a JSON-based definition that describes the structure, types, and constraints of the data. This schema allows for efficient serialization and deserialization, making it versatile for data storage and streaming applications.</p>
<p>Avro’s schema format is highly adaptable, supporting both simple and complex data structures and allowing schema evolution without disrupting data compatibility. This makes Avro particularly suited for big data pipelines and environments where schemas may need frequent updates. Its JSON-based structure is easy to read and interpret while enabling efficient storage and retrieval in binary format, ideal for high-performance data processing.</p>
<p>Here’s an in-depth look at Avro schemas:</p>
<p><a name="1-schema-basics"></a></p>
<h4 id="1-Schema-Basics"><a href="#1-Schema-Basics" class="headerlink" title="1. Schema Basics"></a>1. <strong>Schema Basics</strong></h4><p>   Avro schemas are written in JSON and define the data types and structure. A schema specifies:</p>
<ul>
<li><strong>Type</strong>: The data type, like <code>string</code>, <code>int</code>, <code>float</code>, or complex types like <code>record</code> and <code>array</code>.</li>
<li><strong>Name</strong>: The name of the field (only required for named types like <code>record</code>).</li>
<li><strong>Namespace</strong>: Optional, used to provide a unique context for named types, helpful in managing type names in larger systems.</li>
<li><strong>Fields</strong>: Defines each field within complex types, like <code>record</code>.</li>
</ul>
<p>   Example of a simple Avro schema:<br>   <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;User&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;id&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;int&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;name&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;email&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><br>   This schema defines a <code>User</code> record with three fields: <code>id</code>, <code>name</code>, and <code>email</code>.</p>
<p><a name="2-primitive-data-types"></a></p>
<h4 id="2-Primitive-Data-Types"><a href="#2-Primitive-Data-Types" class="headerlink" title="2. Primitive Data Types"></a>2. <strong>Primitive Data Types</strong></h4><p>   Avro supports several primitive data types:</p>
<ul>
<li><strong>Null</strong>: Represents a null value.</li>
<li><strong>Boolean</strong>: Represents <code>true</code> or <code>false</code>.</li>
<li><strong>Int</strong>: 32-bit signed integer.</li>
<li><strong>Long</strong>: 64-bit signed integer.</li>
<li><strong>Float</strong>: 32-bit IEEE floating-point number.</li>
<li><strong>Double</strong>: 64-bit IEEE floating-point number.</li>
<li><strong>Bytes</strong>: Sequence of bytes, useful for binary data.</li>
<li><strong>String</strong>: Unicode character sequence.</li>
</ul>
<p><a name="3-complex-data-types"></a></p>
<h4 id="3-Complex-Data-Types"><a href="#3-Complex-Data-Types" class="headerlink" title="3. Complex Data Types"></a>3. <strong>Complex Data Types</strong></h4><p>   Avro supports complex data types to handle more advanced data structures:</p>
<ul>
<li><strong>Record</strong>: Similar to a structured data object or table row; contains fields, each with its own name and type.</li>
<li><strong>Enum</strong>: Defines a list of allowed values.</li>
<li><strong>Array</strong>: An ordered collection of values of a specified type.</li>
<li><strong>Map</strong>: A collection of key-value pairs with <code>string</code> keys and values of a specified type.</li>
<li><strong>Union</strong>: Allows fields to have multiple types, which supports optional fields and complex structures.</li>
<li><strong>Fixed</strong>: Represents a fixed-size binary value, useful for things like fixed-length IDs.</li>
</ul>
<p>   Example of complex types:<br>   <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Person&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;name&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;age&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span> <span class="string">&quot;int&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;emails&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;array&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;items&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;address&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Address&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;street&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;city&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><br>   This schema defines a <code>Person</code> record with an optional <code>age</code>, a list of <code>emails</code>, and a nested <code>Address</code> record.</p>
<p><a name="4-union-types"></a></p>
<h4 id="4-Union-Types"><a href="#4-Union-Types" class="headerlink" title="4. Union Types"></a>4. <strong>Union Types</strong></h4><p>   Unions in Avro schemas allow a field to hold one of multiple types, helping to represent optional fields:</p>
<ul>
<li>A union is represented by an array of types, such as <code>[&quot;null&quot;, &quot;int&quot;]</code> for a nullable integer.</li>
<li>The first type in the union is considered the default.</li>
</ul>
<p>   Example:<br>   <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;birthdate&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span> <span class="string">&quot;string&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><br>   Here, <code>birthdate</code> is either <code>null</code> or a <code>string</code>, allowing it to be optional.</p>
<p><a name="5-default-values"></a></p>
<h4 id="5-Default-Values"><a href="#5-Default-Values" class="headerlink" title="5. Default Values"></a>5. <strong>Default Values</strong></h4><ul>
<li>Fields can have default values if they are missing in the data, which is particularly useful when evolving schemas.</li>
<li>Default values must match the field type and are defined within the schema.</li>
</ul>
<p>   Example:<br>   <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;isActive&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;boolean&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></p>
<p><a name="6-schema-evolution"></a></p>
<h4 id="6-Schema-Evolution"><a href="#6-Schema-Evolution" class="headerlink" title="6. Schema Evolution"></a>6. <strong>Schema Evolution</strong></h4><p>   Avro is designed to handle schema evolution, meaning new schemas can be applied to existing data files without breaking compatibility:</p>
<ul>
<li><strong>Backward Compatibility</strong>: New schema can read old data (e.g., adding new fields with default values).</li>
<li><strong>Forward Compatibility</strong>: Old schema can read new data (e.g., adding optional fields).</li>
<li><strong>Full Compatibility</strong>: Both backward and forward compatible.</li>
</ul>
<p>   Schema evolution rules include:</p>
<ul>
<li>Adding a new field with a default value is backward-compatible.</li>
<li>Removing a field is backward-compatible if it is not required by consumers.</li>
<li>Changing a field type requires careful consideration to ensure compatibility.</li>
</ul>
<p><a name="7-named-types-and-namespaces"></a></p>
<h4 id="7-Named-Types-and-Namespaces"><a href="#7-Named-Types-and-Namespaces" class="headerlink" title="7. Named Types and Namespaces"></a>7. <strong>Named Types and Namespaces</strong></h4><p>   In Avro, named types like <code>record</code> and <code>enum</code> require unique names, often scoped by namespaces:</p>
<ul>
<li><strong>Name</strong>: The unique identifier for a type.</li>
<li><strong>Namespace</strong>: Provides context to prevent naming conflicts, similar to a package in Java or a module in Python.</li>
</ul>
<p><a name="8-schema-example-with-namespaces"></a></p>
<h4 id="8-Schema-Example-with-Namespaces"><a href="#8-Schema-Example-with-Namespaces" class="headerlink" title="8. Schema Example with Namespaces"></a>8. <strong>Schema Example with Namespaces</strong></h4><p>   Example using namespace for managing complex data:<br>   <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;namespace&quot;</span><span class="punctuation">:</span> <span class="string">&quot;com.example&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Customer&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;id&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;int&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;contact&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;record&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ContactInfo&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;email&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;phone&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;null&quot;</span><span class="punctuation">,</span> <span class="string">&quot;string&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;default&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></p>
<p><a name="schema-registry"></a></p>
<h3 id="Schema-Registry"><a href="#Schema-Registry" class="headerlink" title="Schema Registry"></a>Schema Registry</h3><p><strong>Schema Registry</strong> is a crucial component that allows the storage and retrieval of schemas used by producers and consumers of data. It ensures that producers and consumers agree on the data structure, supporting <strong>schema evolution</strong> and <strong>compatibility checks</strong>.</p>
<p><strong>Diagram: Schema Registry Workflow</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+-----------+             +--------------------+</span><br><span class="line">| Producer  |   Write     |  Schema Registry   |</span><br><span class="line">|           | ----------&gt; |                    |</span><br><span class="line">+-----------+             +--------------------+</span><br><span class="line">    |</span><br><span class="line">    |</span><br><span class="line">    |    Write</span><br><span class="line">    v</span><br><span class="line">+-----------+                  +-----------------+</span><br><span class="line">|  Data     |    Read/Write    |    Consumer     |</span><br><span class="line">|  Storage  | &lt;--------------&gt; |                 |</span><br><span class="line">+-----------+                  +-----------------+</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Producers</strong> register the schema before sending data to storage.</li>
<li><strong>Consumers</strong> fetch the schema from the registry to deserialize and understand the data.</li>
</ul>
<p><a name="storage-architecture-for-avro-in-hdfs-s3"></a></p>
<h3 id="Storage-Architecture-for-Avro-in-HDFS-S3"><a href="#Storage-Architecture-for-Avro-in-HDFS-S3" class="headerlink" title="Storage Architecture for Avro in HDFS&#x2F;S3"></a>Storage Architecture for Avro in HDFS&#x2F;S3</h3><p>When storing Avro data in <strong>HDFS</strong> or <strong>S3</strong>, Avro files contain both the schema and data, allowing each file to be fully self-contained and readable independently.</p>
<p><strong>Diagram: Avro Storage in HDFS&#x2F;S3</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">+------------------------+</span><br><span class="line">|   HDFS or S3 Storage   |</span><br><span class="line">+------------------------+</span><br><span class="line">          |</span><br><span class="line">+------------------------+</span><br><span class="line">|       Avro File        |</span><br><span class="line">|      + Schema          |</span><br><span class="line">+------------------------+</span><br><span class="line">         |</span><br><span class="line">+------------------------+</span><br><span class="line">|       Blocks           |</span><br><span class="line">+------------------------+</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Each Avro file</strong> contains schema and data blocks, making it easily portable across storage platforms.</li>
<li><strong>Data Access</strong>: Avro files can be read without external dependencies, as each file includes the required schema.</li>
</ul>
<p><a name="sample-code-in-spark-avro"></a></p>
<h3 id="Sample-Code-in-Spark"><a href="#Sample-Code-in-Spark" class="headerlink" title="Sample Code in Spark"></a>Sample Code in Spark</h3><p>Below is a Spark example that reads data from an Avro file, processes it, and writes it back to HDFS as Avro format.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.avro._</span><br><span class="line"></span><br><span class="line"><span class="comment">// Initialize Spark session</span></span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder</span><br><span class="line">    .appName(<span class="string">&quot;AvroExample&quot;</span>)</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Define the Avro schema as JSON</span></span><br><span class="line"><span class="keyword">val</span> avroSchema = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;type&quot;: &quot;record&quot;,</span></span><br><span class="line"><span class="string">  &quot;name&quot;: &quot;Employee&quot;,</span></span><br><span class="line"><span class="string">  &quot;fields&quot;: [</span></span><br><span class="line"><span class="string">    &#123;&quot;name&quot;: &quot;id&quot;, &quot;type&quot;: &quot;int&quot;&#125;,</span></span><br><span class="line"><span class="string">    &#123;&quot;name&quot;: &quot;name&quot;, &quot;type&quot;: &quot;string&quot;&#125;,</span></span><br><span class="line"><span class="string">    &#123;&quot;name&quot;: &quot;email&quot;, &quot;type&quot;: [&quot;null&quot;, &quot;string&quot;], &quot;default&quot;: null&#125;,</span></span><br><span class="line"><span class="string">    &#123;&quot;name&quot;: &quot;salary&quot;, &quot;type&quot;: &quot;double&quot;&#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Read Avro file from HDFS</span></span><br><span class="line"><span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read</span><br><span class="line">    .format(<span class="string">&quot;avro&quot;</span>)</span><br><span class="line">    .load(<span class="string">&quot;hdfs://path/to/input/avro/file&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Process the DataFrame (example: filter employees with salary &gt; 5000)</span></span><br><span class="line"><span class="keyword">val</span> filteredDf = df.filter(<span class="string">&quot;salary &gt; 5000&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write back to HDFS in Avro format</span></span><br><span class="line">filteredDf.write</span><br><span class="line">    .format(<span class="string">&quot;avro&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;avroSchema&quot;</span>, avroSchema)</span><br><span class="line">    .save(<span class="string">&quot;hdfs://path/to/output/avro/file&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="exploring-parquet-format"></a></p>
<h2 id="Exploring-Parquet-Format"><a href="#Exploring-Parquet-Format" class="headerlink" title="Exploring Parquet Format"></a>Exploring Parquet Format</h2><p><strong>Apache Parquet</strong> is a columnar storage format optimized for complex nested data structures, making it an ideal choice for <strong>big data processing</strong>.</p>
<p><a name="parquet-schema-and-compression"></a></p>
<h3 id="Parquet-Schema-and-Compression"><a href="#Parquet-Schema-and-Compression" class="headerlink" title="Parquet Schema and Compression"></a>Parquet Schema and Compression</h3><p>Parquet organizes data in columns, allowing for efficient compression and encoding. This format is particularly beneficial for queries that scan specific columns.</p>
<p><strong>Compression Techniques</strong>:</p>
<ul>
<li><strong>Dictionary Encoding</strong>: Reduces data size by replacing duplicate values with codes.</li>
<li><strong>Bit Packing</strong>: Optimizes storage by packing multiple values into smaller data units.</li>
</ul>
<p><strong>Diagram: Parquet File Structure</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+------------------------------+</span><br><span class="line">|           Parquet            |</span><br><span class="line">+------------------------------+</span><br><span class="line">|      Row Group 1             |</span><br><span class="line">|    +--------------------+    |</span><br><span class="line">|    | Column 1           |    |</span><br><span class="line">|    | Column 2           |    |</span><br><span class="line">|    | ...                |    |</span><br><span class="line">|    +--------------------+    |</span><br><span class="line">|                              |</span><br><span class="line">|      Row Group 2             |</span><br><span class="line">|    +--------------------+    |</span><br><span class="line">|    | Column 1           |    |</span><br><span class="line">|    | Column 2           |    |</span><br><span class="line">|    | ...                |    |</span><br><span class="line">|    +--------------------+    |</span><br><span class="line">+------------------------------+</span><br></pre></td></tr></table></figure>

<ul>
<li>Each <strong>Row Group</strong> contains columns stored together, optimizing compression and query performance.</li>
<li><strong>Columnar storage</strong> allows quick access to specific fields, reducing read and write times.</li>
</ul>
<p><a name="parquet-schema"></a></p>
<h3 id="Parquet-Schema"><a href="#Parquet-Schema" class="headerlink" title="Parquet Schema"></a>Parquet Schema</h3><p>Parquet’s schema defines the structure, types, and layout of the data stored in the file, making it highly efficient for analytics and queries. This schema is stored in the file’s metadata and allows query engines to interpret the data without needing to read the entire file, which speeds up operations significantly.</p>
<p>The Parquet schema plays a crucial role in its columnar storage efficiency, managing data sparsity, and enabling rich, nested data structures with low storage overhead. It facilitates schema evolution, where additional columns or fields can be added without rewriting the entire file, and supports advanced filtering and optimizations for large data analytics tasks.</p>
<p>Here’s an overview of the main components of the Parquet schema:</p>
<p><a name="1-schema-hierarchy-and-structure"></a></p>
<h4 id="1-Schema-Hierarchy-and-Structure"><a href="#1-Schema-Hierarchy-and-Structure" class="headerlink" title="1. Schema Hierarchy and Structure"></a>1. <strong>Schema Hierarchy and Structure</strong></h4><p>   Parquet schema is organized hierarchically and supports complex nested structures:</p>
<ul>
<li><strong>Message Type</strong>: This is the root element in a Parquet schema, defining the data structure at the highest level.</li>
<li><strong>Fields</strong>: Each field in the schema has a name, data type, and potentially nested subfields if the data structure is complex. Parquet supports:<ul>
<li><strong>Primitive Types</strong>: such as <code>int32</code>, <code>int64</code>, <code>boolean</code>, <code>float</code>, <code>double</code>, and <code>binary</code>.</li>
<li><strong>Nested Types</strong>: Parquet can store complex structures like lists, maps, and structs, which are stored as nested types in the schema.</li>
</ul>
</li>
</ul>
<p>   For example, a Parquet schema could look like:<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">message schema &#123;</span><br><span class="line">    required int32 id;</span><br><span class="line">    optional group address &#123;</span><br><span class="line">        required binary street (UTF8);</span><br><span class="line">        optional int32 zip_code;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>   This schema describes a record with an <code>id</code> and an optional nested <code>address</code> group, which contains a <code>street</code> and an optional <code>zip_code</code>.</p>
<p><a name="2-column-definition-required-optional-repeated"></a></p>
<h4 id="2-Column-Definition-Required-Optional-Repeated"><a href="#2-Column-Definition-Required-Optional-Repeated" class="headerlink" title="2. Column Definition: Required, Optional, Repeated"></a>2. <strong>Column Definition: Required, Optional, Repeated</strong></h4><p>   Each field in the Parquet schema has a <strong>repetition level</strong>:</p>
<ul>
<li><strong>Required</strong>: Every row must contain a value for this field.</li>
<li><strong>Optional</strong>: A field that can be present or absent in each row.</li>
<li><strong>Repeated</strong>: Used to model lists or repeated elements, allowing multiple values for the field in a row.</li>
</ul>
<p><a name="3-definition-and-repetition-levels"></a></p>
<h4 id="3-Definition-and-Repetition-Levels"><a href="#3-Definition-and-Repetition-Levels" class="headerlink" title="3. Definition and Repetition Levels"></a>3. <strong>Definition and Repetition Levels</strong></h4><p>  Parquet’s schema model is hierarchical and optimized for efficient storage and retrieval in columnar format. It uses <strong>Definition Levels</strong> and <strong>Repetition Levels</strong> to handle nullability, optional fields, and nested data structures. Let’s walk through an example to show how these levels work.</p>
<p>   To manage complex data structures and sparsity, Parquet uses <strong>definition levels</strong> and <strong>repetition levels</strong>:</p>
<ul>
<li><strong>Definition Levels</strong> track whether each level in the hierarchy has data or is <code>null</code>, it tells us how deep in the structure a field is defined.</li>
<li><strong>Repetition Levels</strong> track whether an element is the first instance or a repeated instance in nested lists or repeated fields, it tells us if the field is part of a repeated structure and, if so, how deep the repeat goes.</li>
</ul>
<p>   For instance, if a row has a list of addresses, the repetition levels can indicate the position of each address within the list, while definition levels show whether each element is present or missing.</p>
<h5 id="Example-Parquet-Schema"><a href="#Example-Parquet-Schema" class="headerlink" title="Example Parquet Schema"></a>Example Parquet Schema</h5><p>Consider the following JSON structure, which could be a nested data schema for a Parquet file:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Alice&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;contacts&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;email&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span> <span class="string">&quot;alice@example.com&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;phone&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;number&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;addresses&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;street&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123 Main St&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Wonderland&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>Here’s the corresponding Parquet schema:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">message Person &#123;</span><br><span class="line">  required binary name (UTF8);</span><br><span class="line">  repeated group contacts &#123;</span><br><span class="line">    required binary type (UTF8);</span><br><span class="line">    optional binary address (UTF8);</span><br><span class="line">    optional binary number (UTF8);</span><br><span class="line">  &#125;</span><br><span class="line">  repeated group addresses &#123;</span><br><span class="line">    required binary street (UTF8);</span><br><span class="line">    required binary city (UTF8);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Parquet-Structure-Definition-and-Repetition-Levels"><a href="#Parquet-Structure-Definition-and-Repetition-Levels" class="headerlink" title="Parquet Structure: Definition and Repetition Levels"></a>Parquet Structure: Definition and Repetition Levels</h5><ol>
<li><strong>Definition Level</strong>: Indicates the presence or absence of values at each level in a schema. This level is used to define nullability and optional fields.</li>
<li><strong>Repetition Level</strong>: Indicates if a field is part of a repeated structure (e.g., a list or an array). This is useful for nested or repeated structures, telling the reader if a given level repeats within the hierarchy.</li>
</ol>
<p>Let’s break down how these levels work for each field in the example above:</p>
<h5 id="1-Field-name"><a href="#1-Field-name" class="headerlink" title="1. Field: name"></a>1. Field: <code>name</code></h5><ul>
<li><strong>Definition Level</strong>: 1 (required field, so it’s always defined)</li>
<li><strong>Repetition Level</strong>: 0 (not repeated)</li>
</ul>
<h5 id="2-Field-contacts"><a href="#2-Field-contacts" class="headerlink" title="2. Field: contacts"></a>2. Field: <code>contacts</code></h5><ul>
<li><strong>Definition Level</strong>: 1 to 2, depending on the presence of <code>address</code> and <code>number</code> fields.<ul>
<li>If both <code>address</code> and <code>number</code> are <code>null</code>, the definition level is lower.</li>
</ul>
</li>
<li><strong>Repetition Level</strong>: 1 (this field is repeated since <code>contacts</code> is a list)</li>
</ul>
<h5 id="3-Fields-Inside-contacts-type-address-number"><a href="#3-Fields-Inside-contacts-type-address-number" class="headerlink" title="3. Fields Inside contacts: type, address, number"></a>3. Fields Inside <code>contacts</code>: <code>type</code>, <code>address</code>, <code>number</code></h5><ul>
<li><strong>type</strong><ul>
<li><strong>Definition Level</strong>: 2 (required field within the repeated group)</li>
<li><strong>Repetition Level</strong>: 1</li>
</ul>
</li>
<li><strong>address</strong> and <strong>number</strong><ul>
<li><strong>Definition Level</strong>: 2 or 3 (optional fields)<ul>
<li>A definition level of 2 means the <code>contacts</code> object is present but <code>address</code> or <code>number</code> is <code>null</code>.</li>
<li>A definition level of 3 indicates both fields are filled.</li>
</ul>
</li>
<li><strong>Repetition Level</strong>: 1 (repeated inside <code>contacts</code>)</li>
</ul>
</li>
</ul>
<h5 id="4-Field-addresses"><a href="#4-Field-addresses" class="headerlink" title="4. Field: addresses"></a>4. Field: <code>addresses</code></h5><ul>
<li><strong>Definition Level</strong>: 1 to 2</li>
<li><strong>Repetition Level</strong>: 1 (repeated field)</li>
</ul>
<h5 id="5-Fields-Inside-addresses-street-city"><a href="#5-Fields-Inside-addresses-street-city" class="headerlink" title="5. Fields Inside addresses: street, city"></a>5. Fields Inside <code>addresses</code>: <code>street</code>, <code>city</code></h5><ul>
<li>Both <code>street</code> and <code>city</code> are required within the repeated <code>addresses</code> group.</li>
<li><strong>Definition Level</strong>: 2</li>
<li><strong>Repetition Level</strong>: 1 (both are repeated with each <code>addresses</code> group entry)</li>
</ul>
<h5 id="Example-Encoding-with-Levels"><a href="#Example-Encoding-with-Levels" class="headerlink" title="Example Encoding with Levels"></a>Example Encoding with Levels</h5><p>Assuming data with these values:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Alice&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;contacts&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;email&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;address&quot;</span><span class="punctuation">:</span> <span class="string">&quot;alice@example.com&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;number&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;phone&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;number&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123-456-7890&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;addresses&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;street&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123 Main St&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;city&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Wonderland&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>The encoded levels might look like this:</p>
<table>
<thead>
<tr>
<th>Field</th>
<th>Value</th>
<th>Definition Level</th>
<th>Repetition Level</th>
</tr>
</thead>
<tbody><tr>
<td>name</td>
<td>“Alice”</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>contacts[0].type</td>
<td>“email”</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>contacts[0].address</td>
<td>“<a href="mailto:&#x61;&#x6c;&#x69;&#x63;&#101;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#108;&#101;&#46;&#99;&#x6f;&#109;">&#x61;&#x6c;&#x69;&#x63;&#101;&#64;&#101;&#120;&#x61;&#x6d;&#x70;&#108;&#101;&#46;&#99;&#x6f;&#109;</a>“</td>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>contacts[0].number</td>
<td>null</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>contacts[1].type</td>
<td>“phone”</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>contacts[1].address</td>
<td>null</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>contacts[1].number</td>
<td>“123-456-7890”</td>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>addresses[0].street</td>
<td>“123 Main St”</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>addresses[0].city</td>
<td>“Wonderland”</td>
<td>2</td>
<td>1</td>
</tr>
</tbody></table>
<p>These levels help Parquet efficiently handle complex nested and repeated data structures, enabling better data compression and faster querying by only storing relevant levels and values for each entry.</p>
<p><a name="4-logical-types-and-annotations"></a></p>
<h4 id="4-Logical-Types-and-Annotations"><a href="#4-Logical-Types-and-Annotations" class="headerlink" title="4. Logical Types and Annotations"></a>4. <strong>Logical Types and Annotations</strong></h4><p>   Parquet supports logical types that provide additional context for primitive types:</p>
<ul>
<li><strong>Logical Types</strong>: These are type annotations like <code>UTF8</code> for text strings, <code>DATE</code> for dates, and <code>DECIMAL</code> for high-precision decimals.</li>
<li>Logical types help map data from systems that use richer data types (like SQL databases) to Parquet’s primitive types.</li>
</ul>
<p>   Example:<br>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optional int32 birthdate (DATE);</span><br></pre></td></tr></table></figure></p>
<p><a name="5-column-index-and-row-group-metadata"></a></p>
<h4 id="5-Column-Index-and-Row-Group-Metadata"><a href="#5-Column-Index-and-Row-Group-Metadata" class="headerlink" title="5. Column Index and Row Group Metadata"></a>5. <strong>Column Index and Row Group Metadata</strong></h4><ul>
<li><strong>Column Index</strong>: Parquet files include metadata about each column, such as min&#x2F;max values, null counts, and distinct counts. This allows query engines to skip entire blocks if they don’t match the filter criteria.</li>
<li><strong>Row Group Metadata</strong>: Parquet stores data in row groups (blocks of rows), each containing column data for that group. Each row group stores metadata like the number of rows and data size, which helps with efficient reads.</li>
</ul>
<p><a name="example-of-a-parquet-schema-in-json-representation"></a></p>
<h4 id="Example-of-a-Parquet-Schema-in-JSON-Representation"><a href="#Example-of-a-Parquet-Schema-in-JSON-Representation" class="headerlink" title="Example of a Parquet Schema in JSON Representation"></a>Example of a Parquet Schema in JSON Representation</h4><p>A Parquet schema can also be represented in JSON format to show the hierarchy and structure clearly. For instance:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;schema&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;message&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;id&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;INT32&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;repetition_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;REQUIRED&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;address&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;group&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;repetition_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;OPTIONAL&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;street&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;BINARY&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;logicalType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;UTF8&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;repetition_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;REQUIRED&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;zip_code&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;INT32&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;repetition_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;OPTIONAL&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>In this JSON schema:</p>
<ul>
<li>The <code>id</code> field is required.</li>
<li>The <code>address</code> field is optional and has two nested fields: a required <code>street</code> and an optional <code>zip_code</code>.</li>
</ul>
<p><a name="storage-architecture-for-parquet-in-hdfs-s3"></a></p>
<h3 id="Storage-Architecture-for-Parquet-in-HDFS-S3"><a href="#Storage-Architecture-for-Parquet-in-HDFS-S3" class="headerlink" title="Storage Architecture for Parquet in HDFS&#x2F;S3"></a>Storage Architecture for Parquet in HDFS&#x2F;S3</h3><p>In HDFS&#x2F;S3 storage, Parquet files are organized in row groups with each column stored independently within those groups.</p>
<p><strong>Diagram: Parquet Storage in HDFS&#x2F;S3</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">+------------------------+</span><br><span class="line">|   HDFS or S3 Storage   |</span><br><span class="line">+------------------------+</span><br><span class="line">          |</span><br><span class="line">+------------------------+</span><br><span class="line">|     Parquet File       |</span><br><span class="line">+------------------------+</span><br><span class="line">         |</span><br><span class="line">+------------------------+</span><br><span class="line">|   Row Groups           |</span><br><span class="line">+------------------------+</span><br><span class="line">         |</span><br><span class="line">+------------------------+</span><br><span class="line">| Columns within Groups  |</span><br><span class="line">+------------------------+</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Row Groups</strong>: Partitioned sections that allow for distributed reads.</li>
<li><strong>Columns</strong>: Stored separately within each row group for efficient access.</li>
</ul>
<p><a name="sample-code-in-spark-parquet"></a></p>
<h3 id="Sample-Code-in-Spark-1"><a href="#Sample-Code-in-Spark-1" class="headerlink" title="Sample Code in Spark"></a>Sample Code in Spark</h3><p>Below is a Spark example that reads data from a Parquet file, performs transformations, and writes it back to HDFS as Parquet format.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Initialize Spark session</span></span><br><span class="line"><span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder</span><br><span class="line">    .appName(<span class="string">&quot;ParquetExample&quot;</span>)</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Read Parquet file from HDFS</span></span><br><span class="line"><span class="keyword">val</span> df: <span class="type">DataFrame</span> = spark.read</span><br><span class="line">    .parquet(<span class="string">&quot;hdfs://path/to/input/parquet/file&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Process the DataFrame (example: select employees with salary &gt; 5000)</span></span><br><span class="line"><span class="keyword">val</span> filteredDf = df.filter(<span class="string">&quot;salary &gt; 5000&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write back to HDFS in Parquet format</span></span><br><span class="line">filteredDf.write</span><br><span class="line">    .parquet(<span class="string">&quot;hdfs://path/to/output/parquet/file&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This article provided an in-depth look at <strong>Avro</strong> and <strong>Parquet</strong> formats, exploring their unique characteristics, schema management, and storage architectures. With examples in <strong>Spark</strong>, we demonstrated practical implementations in a <strong>real-world</strong> production environment, highlighting the versatility of both formats for big data solutions.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Building-a-ChatGPT-like-System-II/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Building-a-ChatGPT-like-System-II/" class="post-title-link" itemprop="url">Building a ChatGPT-like System - II</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 16:01:29" itemprop="dateCreated datePublished" datetime="2024-10-28T16:01:29-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ChatGPT/" itemprop="url" rel="index"><span itemprop="name">ChatGPT</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#system-overview">System Overview</a></li>
<li><a href="#1-core-dialogue-architecture">1. Core Dialogue Architecture</a><ul>
<li><a href="#diagram-core-dialogue-flow">Diagram: Core Dialogue Flow</a></li>
</ul>
</li>
<li><a href="#2-session-and-history-management">2. Session and History Management</a><ul>
<li><a href="#problem-of-stateless-inference">Problem of Stateless Inference</a></li>
<li><a href="#diagram-enhanced-system-with-session-and-history-management">Diagram: Enhanced System with Session and History Management</a></li>
</ul>
</li>
<li><a href="#3-rest-api-design">3. REST API Design</a></li>
<li><a href="#4-message-structure-and-prompt-format">4. Message Structure and Prompt Format</a></li>
<li><a href="#5-managing-history-and-context">5. Managing History and Context</a><ul>
<li><a href="#techniques-for-history-management">Techniques for History Management</a></li>
</ul>
</li>
<li><a href="#6-system-extensions-and-scalability">6. System Extensions and Scalability</a></li>
<li><a href="#7-caching-strategies">7. Caching Strategies</a><ul>
<li><a href="#diagram-cache-with-vector-embeddings-for-similar-query-detection">Diagram: Cache with Vector Embeddings for Similar Query Detection</a></li>
<li><a href="#cache-scope-considerations">Cache Scope Considerations</a></li>
</ul>
</li>
<li><a href="#8-elastic-scaling-and-load-balancing">8. Elastic Scaling and Load Balancing</a><ul>
<li><a href="#diagram-load-balanced-system-architecture-with-elastic-scaling">Diagram: Load Balanced System Architecture with Elastic Scaling</a></li>
</ul>
</li>
<li><a href="#9-production-readiness">9. Production Readiness</a><ul>
<li><a href="#checklist-for-production">Checklist for Production</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<hr>
<p>This guide provides an in-depth exploration of building a ChatGPT-style conversational AI system. We cover everything from model setup and inference engine design to system architecture, incorporating caching, scalability, and production-ready features.</p>
<p><a name="system-overview"></a></p>
<h2 id="System-Overview"><a href="#System-Overview" class="headerlink" title="System Overview"></a>System Overview</h2><p>A conversational AI system has several core components responsible for processing, generating, and managing dialogue flow with users. This overview explains the minimal structure for a functional, extensible ChatGPT-style system.</p>
<p><a name="1-core-dialogue-architecture"></a></p>
<h2 id="1-Core-Dialogue-Architecture"><a href="#1-Core-Dialogue-Architecture" class="headerlink" title="1. Core Dialogue Architecture"></a>1. Core Dialogue Architecture</h2><p>The architecture focuses on the interaction between the user, the web interface, and the inference engine that generates responses.</p>
<h3 id="Diagram-Core-Dialogue-Flow"><a href="#Diagram-Core-Dialogue-Flow" class="headerlink" title="Diagram: Core Dialogue Flow"></a>Diagram: Core Dialogue Flow</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---------------+               +-------------------+               +-----------------------+</span><br><span class="line">|    Web UI     | &lt;-- HTTP --&gt;  |   Server/API      | &lt;-- REST --&gt;  |   Inference Runtime   |</span><br><span class="line">| (User Access) |               | (Request Routing) |               | (LLM Model Handling)  |</span><br><span class="line">+---------------+               +-------------------+               +-----------------------+</span><br><span class="line">            ^                                                         |</span><br><span class="line">            |&lt;--------------------------------------------------------+</span><br></pre></td></tr></table></figure>

<ol>
<li><strong>Web UI</strong>: Handles user interaction and displays responses.</li>
<li><strong>Server&#x2F;API</strong>: Receives requests and forwards them to the <code>inference runtime</code>.</li>
<li><strong>Inference Runtime</strong>: Loads the large language model (LLM), processes the input, and generates a response.</li>
</ol>
<p><a name="2-session-and-history-management"></a></p>
<h2 id="2-Session-and-History-Management"><a href="#2-Session-and-History-Management" class="headerlink" title="2. Session and History Management"></a>2. Session and History Management</h2><h3 id="Problem-of-Stateless-Inference"><a href="#Problem-of-Stateless-Inference" class="headerlink" title="Problem of Stateless Inference"></a>Problem of Stateless Inference</h3><p>Standard <code>inference runtimes</code> are typically stateless, meaning they cannot recall previous messages in a conversation. To handle multi-turn dialogue, we integrate a database to persist session data and user message history.</p>
<h3 id="Diagram-Enhanced-System-with-Session-and-History-Management"><a href="#Diagram-Enhanced-System-with-Session-and-History-Management" class="headerlink" title="Diagram: Enhanced System with Session and History Management"></a>Diagram: Enhanced System with Session and History Management</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+---------------+               +-------------------+               +-----------------------+</span><br><span class="line">|    Web UI     | &lt;-- HTTP --&gt;  |   Server/API      | &lt;-- REST --&gt;  |   Inference Runtime   |</span><br><span class="line">|               |               |                   |               |                       |</span><br><span class="line">+---------------+               +-------------------+               +-----------------------+</span><br><span class="line">                                          |</span><br><span class="line">                +---------------- Database ----------------+</span><br><span class="line">                |   User Session, ChatID, and Messages     |</span><br><span class="line">                +------------------------------------------+</span><br></pre></td></tr></table></figure>

<ol>
<li><strong>Database</strong>: Stores user sessions, chat histories, and other metadata.</li>
<li><strong>Server&#x2F;API</strong>: Uses REST endpoints to interact with the database, retrieving history when needed.</li>
</ol>
<p><a name="3-rest-api-design"></a></p>
<h2 id="3-REST-API-Design"><a href="#3-REST-API-Design" class="headerlink" title="3. REST API Design"></a>3. REST API Design</h2><p>The Server&#x2F;API manages communication with the Web UI via REST APIs, handling user requests, responses, and session tracking.</p>
<p><strong>REST Endpoints:</strong></p>
<ul>
<li><strong>POST &#x2F;chat</strong>: Starts a new conversation.</li>
<li><strong>POST &#x2F;chat&#x2F;:chatID&#x2F;completion</strong>: Continues a conversation in an existing session.</li>
<li><strong>GET &#x2F;chats</strong>: Retrieves the list of active sessions.</li>
<li><strong>DELETE &#x2F;chat&#x2F;:chatID</strong>: Deletes a specified session.</li>
</ul>
<p><strong>Sample API Call to Start a Conversation</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST http://yourserver.com/chat \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;&quot;userID&quot;: &quot;12345&quot;, &quot;message&quot;: &quot;Hello, ChatGPT!&quot;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<p><a name="4-message-structure-and-prompt-format"></a></p>
<h2 id="4-Message-Structure-and-Prompt-Format"><a href="#4-Message-Structure-and-Prompt-Format" class="headerlink" title="4. Message Structure and Prompt Format"></a>4. Message Structure and Prompt Format</h2><p>The <strong>prompt format</strong> structures conversation history and provides context to the model.</p>
<p><strong>Example Prompt Format in JSON</strong></p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;You are a helpful assistant.&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Hello!&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Hello there, how may I assist you today?&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;How are you?&quot;</span> <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<ol>
<li><strong>Role</strong>: Indicates the message source (<code>system</code>, <code>user</code>, or <code>assistant</code>).</li>
<li><strong>Content</strong>: The message text.</li>
</ol>
<p><a name="5-managing-history-and-context"></a></p>
<h2 id="5-Managing-History-and-Context"><a href="#5-Managing-History-and-Context" class="headerlink" title="5. Managing History and Context"></a>5. Managing History and Context</h2><h3 id="Techniques-for-History-Management"><a href="#Techniques-for-History-Management" class="headerlink" title="Techniques for History Management"></a>Techniques for History Management</h3><ul>
<li><strong>Direct Prompt Fill</strong>: Append all previous messages to the prompt, suitable for short interactions.</li>
<li><strong>Context Truncation</strong>: Omit older messages when context length exceeds the model’s token limit.</li>
<li><strong>History Summarization</strong>: Generate a summary of prior messages to condense the context, enabling longer conversations within token limits.</li>
</ul>
<p><a name="6-system-extensions-and-scalability"></a></p>
<h2 id="6-System-Extensions-and-Scalability"><a href="#6-System-Extensions-and-Scalability" class="headerlink" title="6. System Extensions and Scalability"></a>6. System Extensions and Scalability</h2><p>In a high-traffic environment, it is essential to scale the system horizontally and incorporate caching for repeated requests.</p>
<p><a name="7-caching-strategies"></a></p>
<h2 id="7-Caching-Strategies"><a href="#7-Caching-Strategies" class="headerlink" title="7. Caching Strategies"></a>7. Caching Strategies</h2><p>Implementing caching reduces redundant processing for similar queries. This approach involves caching semantic meanings of requests rather than exact matches.</p>
<h3 id="Diagram-Cache-with-Vector-Embeddings-for-Similar-Query-Detection"><a href="#Diagram-Cache-with-Vector-Embeddings-for-Similar-Query-Detection" class="headerlink" title="Diagram: Cache with Vector Embeddings for Similar Query Detection"></a>Diagram: Cache with Vector Embeddings for Similar Query Detection</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">+---------------+                  +------------+               +----------------+</span><br><span class="line">|   User Query  |  -&gt; Embedding -&gt; |   Cache    |  Cache Hit -&gt; |   Response     |</span><br><span class="line">+---------------+                  +------------+               +----------------+</span><br><span class="line">               | No Hit                                      </span><br><span class="line">               v</span><br><span class="line">+---------------------------+          +--------------------+               </span><br><span class="line">|  Text Embedding Model     |   --&gt;    | Vector Storage and |</span><br><span class="line">|  (e.g., BERT/Word2Vec)    |          |  Search Database   |</span><br><span class="line">+---------------------------+          +--------------------+</span><br></pre></td></tr></table></figure>

<ol>
<li><strong>Embedding Runtime</strong>: Converts queries into vector embeddings.</li>
<li><strong>Vector Storage</strong>: Stores embeddings to detect semantically similar queries.</li>
</ol>
<h3 id="Cache-Scope-Considerations"><a href="#Cache-Scope-Considerations" class="headerlink" title="Cache Scope Considerations"></a>Cache Scope Considerations</h3><ul>
<li><strong>Single User Cache</strong>: Stores responses per user session.</li>
<li><strong>Global Cache</strong>: Shared across all users, introducing potential privacy considerations.</li>
</ul>
<p><a name="8-elastic-scaling-and-load-balancing"></a></p>
<h2 id="8-Elastic-Scaling-and-Load-Balancing"><a href="#8-Elastic-Scaling-and-Load-Balancing" class="headerlink" title="8. Elastic Scaling and Load Balancing"></a>8. Elastic Scaling and Load Balancing</h2><p>Scaling is crucial for supporting high traffic. Stateless components like the server and <code>inference runtime</code> can be scaled horizontally using Kubernetes.</p>
<h3 id="Diagram-Load-Balanced-System-Architecture-with-Elastic-Scaling"><a href="#Diagram-Load-Balanced-System-Architecture-with-Elastic-Scaling" class="headerlink" title="Diagram: Load Balanced System Architecture with Elastic Scaling"></a>Diagram: Load Balanced System Architecture with Elastic Scaling</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+--------------------------+           +---------------+         +--------------------------+</span><br><span class="line">|  Gateway                 |   ---&gt;    |   Server      |   ---&gt;  |  Inference               |</span><br><span class="line">|                          |           |               |         |  Runtime (Auto-scalable) |</span><br><span class="line">|  Load Balancer           |           |  (Stateless)  |         |                          |</span><br><span class="line">+--------------------------+           +---------------+         +--------------------------+</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Gateway</strong>: Distributes traffic across multiple servers.</li>
<li><strong>Message Queue (MQ)</strong>: Handles requests asynchronously for stable inference.</li>
</ul>
<p><a name="9-production-readiness"></a></p>
<h2 id="9-Production-Readiness"><a href="#9-Production-Readiness" class="headerlink" title="9. Production Readiness"></a>9. Production Readiness</h2><p>To make the system production-ready, additional steps are essential.</p>
<h3 id="Checklist-for-Production"><a href="#Checklist-for-Production" class="headerlink" title="Checklist for Production"></a>Checklist for Production</h3><ul>
<li><strong>Technology Selection</strong>:<ul>
<li><strong>Database</strong>: PostgreSQL or MongoDB for session persistence.</li>
<li><strong>Inference Engine</strong>: Use efficient models like <code>llama.cpp</code>, <code>HuggingFace Transformers</code>, or <code>vLLM</code>.</li>
</ul>
</li>
<li><strong>Observability</strong>:<ul>
<li>Implement logging, tracing, and metrics.</li>
</ul>
</li>
<li><strong>CI&#x2F;CD and Deployment</strong>:<ul>
<li>Use Kubernetes or cloud-based deployment environments.</li>
</ul>
</li>
</ul>
<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This guide provides a foundational approach to building a ChatGPT-like system, managing sessions, scaling the architecture, and ensuring production reliability. From basic dialogue to advanced caching and scalability, these steps can help create a highly responsive and robust conversational AI.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Building-a-ChatGPT-like-System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Building-a-ChatGPT-like-System/" class="post-title-link" itemprop="url">Building a ChatGPT-like System</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 15:42:35" itemprop="dateCreated datePublished" datetime="2024-10-28T15:42:35-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ChatGPT/" itemprop="url" rel="index"><span itemprop="name">ChatGPT</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#system-overview">System Overview</a></li>
<li><a href="#session-and-historical-message-management">Session and Historical Message Management</a><ul>
<li><a href="#communication-protocols-and-apis">Communication Protocols and APIs</a></li>
<li><a href="#standardized-prompt-format">Standardized Prompt Format</a></li>
<li><a href="#managing-historical-messages">Managing Historical Messages</a></li>
</ul>
</li>
<li><a href="#system-expansion">System Expansion</a><ul>
<li><a href="#adding-cache-mechanism">Adding Cache Mechanism</a></li>
<li><a href="#scope-of-caching">Scope of Caching</a></li>
<li><a href="#elastic-scalability">Elastic Scalability</a></li>
</ul>
</li>
<li><a href="#production-readiness">Production Readiness</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
<hr>
<p><a name="introduction"></a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>ChatGPT</strong> is a conversational system based on <strong>Large Language Models (LLMs)</strong>. This article introduces the process of building a system similar to ChatGPT, covering everything from the <strong>model</strong>, <strong>inference engine</strong>, to the overall <strong>architecture</strong>.</p>
<hr>
<p><a name="system-overview"></a></p>
<h2 id="System-Overview"><a href="#System-Overview" class="headerlink" title="System Overview"></a>System Overview</h2><p>Our primary focus will be on the core of the conversation system.</p>
<p><strong>System Diagram:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">       +--------------+</span><br><span class="line">       |    Web       |</span><br><span class="line">       |  Interface   |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">       +--------------+</span><br><span class="line">       |   Server     |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">|   Inference Runtime      |</span><br><span class="line">|   (LLM Inference Engine) |</span><br><span class="line">+--------------------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">       +--------------+</span><br><span class="line">       |   Response   |</span><br><span class="line">       +--------------+</span><br></pre></td></tr></table></figure>

<p><img src="/images/Building-a-ChatGPT-like-System/Image-1.png" alt="Core Dialogue Flow"></p>
<p>In this basic system framework:</p>
<ul>
<li>The <strong>web interface</strong> interacts with users, </li>
<li>The <strong>server</strong> receives user requests and forwards them to the <strong>inference runtime</strong> (inference engine), </li>
<li>The <strong>inference runtime</strong> loads the <strong>LLM</strong> to generate a response, returning it to the user.</li>
</ul>
<hr>
<p><a name="session-and-historical-message-management"></a></p>
<h2 id="Session-and-Historical-Message-Management"><a href="#Session-and-Historical-Message-Management" class="headerlink" title="Session and Historical Message Management"></a>Session and Historical Message Management</h2><p>However, the above system has a critical flaw: it lacks <strong>session</strong> and <strong>historical message management</strong> for users. Common <strong>inference runtimes</strong> are typically <strong>stateless</strong> and do not directly support multi-turn conversations with historical context storage, meaning the system “forgets” previous exchanges within a single session.</p>
<p>To address this, we need some essential modifications.</p>
<p><strong>Enhanced System Diagram:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">       +--------------+</span><br><span class="line">       |    Web       |</span><br><span class="line">       |  Interface   |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">       +--------------+</span><br><span class="line">       |   Server     |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">|   Inference Runtime      |</span><br><span class="line">|   (LLM Inference Engine) |</span><br><span class="line">+--------------------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">       +--------------+</span><br><span class="line">       |  Database    |</span><br><span class="line">       +--------------+</span><br></pre></td></tr></table></figure>

<p><img src="/images/Building-a-ChatGPT-like-System/Image-2.png" alt="Enhanced System with Session ahdn History Management"></p>
<p>In this setup, we introduce a <strong>database component</strong> to store user sessions and historical messages.</p>
<h3 id="Communication-Protocols-and-APIs"><a href="#Communication-Protocols-and-APIs" class="headerlink" title="Communication Protocols and APIs"></a>Communication Protocols and APIs</h3><p>For communication, the <strong>web interface</strong> and <strong>server</strong> can use <strong>HTTP</strong> protocols. Basic REST APIs might include:</p>
<ul>
<li><strong><code>POST /chat</code></strong>: Initiate a new session.</li>
<li><strong><code>POST /chat/:chatID/completion</code></strong>: Continue a conversation within an existing session.</li>
<li><strong><code>GET /chats</code></strong>: Retrieve a list of sessions.</li>
<li><strong><code>DELETE /chat/:chatID</code></strong>: Delete a specific session.</li>
</ul>
<p>The <strong>server</strong> persists data in the database, structuring conversation messages with essential fields like <code>userID</code>, <code>chatID</code>, <code>userMessage</code>, and <code>assistantMessage</code>.</p>
<h3 id="Standardized-Prompt-Format"><a href="#Standardized-Prompt-Format" class="headerlink" title="Standardized Prompt Format"></a>Standardized Prompt Format</h3><p>When sending data to the <strong>inference runtime</strong>, the server uses a standardized <strong>prompt format</strong>:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;You are a helpful assistant.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Hello!&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Hello there, how may I assist you today?&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;How are you?&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<p>The <code>role</code> field represents different participants: <code>system</code> defines the conversation context, <code>user</code> represents user input, and <code>assistant</code> represents the model’s output.</p>
<h3 id="Managing-Historical-Messages"><a href="#Managing-Historical-Messages" class="headerlink" title="Managing Historical Messages"></a>Managing Historical Messages</h3><p>There are several ways to handle historical messages:</p>
<ul>
<li><strong>Direct Prompt Filling</strong>: Add historical messages in the prompt as <code>user</code> and <code>assistant</code> entries. This works well for short conversations.</li>
<li><strong>Dynamic Context Adjustment</strong>: Discard earlier messages to fit within the LLM’s token limit.</li>
<li><strong>Message Summarization</strong>: Use the inference engine to summarize conversation history, compressing information before filling the prompt.</li>
</ul>
<p>With session and historical message management, we establish a basic system framework.</p>
<hr>
<p><a name="system-expansion"></a></p>
<h2 id="System-Expansion"><a href="#System-Expansion" class="headerlink" title="System Expansion"></a>System Expansion</h2><p>As the user base grows, the system will require further scalability.</p>
<h3 id="Adding-Cache-Mechanism"><a href="#Adding-Cache-Mechanism" class="headerlink" title="Adding Cache Mechanism"></a>Adding Cache Mechanism</h3><p>One approach to scalability is implementing a <strong>cache</strong> to avoid repeated inference processes. The cache <strong>key-value</strong> pair would be the user’s question and the AI’s response. A cache hit would depend on whether the semantic content of the question is similar. For example, if two questions have different wording but the same meaning, the system should return the same response.</p>
<p><strong>Enhanced Caching System Diagram:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">       +--------------+</span><br><span class="line">       |    Web       |</span><br><span class="line">       |  Interface   |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">       +--------------+</span><br><span class="line">       |   Server     |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">|   Inference Runtime      |</span><br><span class="line">|   (LLM Inference Engine) |</span><br><span class="line">+--------------------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">|       Embedding          |</span><br><span class="line">|    Runtime &amp; Model       |</span><br><span class="line">+--------------------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">| Vector Storage &amp; Search  |</span><br><span class="line">+--------------------------+</span><br></pre></td></tr></table></figure>

<p><img src="/images/Building-a-ChatGPT-like-System/Image-3.png" alt="Cache with Vector Embeddings for Similar Query Detection"></p>
<p>Apart from the <strong>cache module</strong>, we add <strong>embedding runtime</strong> and a <strong>text embedding model</strong> to convert text into <strong>vectors</strong>. If two vectors are close, their text content is semantically similar. <strong>Vector storage and search</strong> modules are used to store and retrieve vectors.</p>
<h3 id="Scope-of-Caching"><a href="#Scope-of-Caching" class="headerlink" title="Scope of Caching"></a>Scope of Caching</h3><p>Caching can be scoped to:</p>
<ul>
<li><strong>Single-user cache</strong>: Caching value is low as users rarely repeat the same question.</li>
<li><strong>Global cache</strong>: Allows reuse across users, but risks exposing sensitive data.</li>
</ul>
<p>After data analysis and validation, decide if cache implementation is beneficial.</p>
<h3 id="Elastic-Scalability"><a href="#Elastic-Scalability" class="headerlink" title="Elastic Scalability"></a>Elastic Scalability</h3><p><strong>Elastic scaling</strong> is another key to handling high concurrency. The <strong>server</strong> is stateless, which allows for easy horizontal scaling.</p>
<p><strong>Scalability System Diagram:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">       +--------------+</span><br><span class="line">       |    Web       |</span><br><span class="line">       |  Interface   |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">       +--------------+</span><br><span class="line">       |   Gateway    |</span><br><span class="line">       |  (Load Bal.) |</span><br><span class="line">       +--------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">|   Server Instances       |</span><br><span class="line">+--------------------------+</span><br><span class="line">              |</span><br><span class="line">              |</span><br><span class="line">              v</span><br><span class="line">+--------------------------+</span><br><span class="line">|   Inference Runtimes     |</span><br><span class="line">+--------------------------+</span><br></pre></td></tr></table></figure>

<p><img src="/images/Building-a-ChatGPT-like-System/Image-4.png" alt="Load Balanced System Architecture with Elastic Scaling"></p>
<p>Here, we introduce a <strong>gateway</strong> for load balancing. The <strong>inference runtime</strong> is also stateless and supports elastic scaling, but it requires more hardware resources and may respond slower than the server. To maintain stability under peak load, add a <strong>message queue (MQ)</strong> and change request handling to asynchronous, improving system resilience.</p>
<hr>
<p><a name="production-readiness"></a></p>
<h2 id="Production-Readiness"><a href="#Production-Readiness" class="headerlink" title="Production Readiness"></a>Production Readiness</h2><p>The system architecture covers the basic logic, but to achieve <strong>production-readiness</strong>, further steps are necessary:</p>
<ul>
<li><strong>Technology Selection</strong>: Choose a database (e.g., PostgreSQL or MongoDB) and inference engine (e.g., <code>llama.cpp</code>, <code>HuggingFace Transformers</code>, <code>vLLM</code>) and map logical components to physical components.</li>
<li><strong>Observability</strong>: Integrate <strong>logging</strong>, <strong>tracing</strong>, <strong>metrics</strong>, and set up monitoring and alerting.</li>
<li><strong>CI&#x2F;CD and Deployment Environment</strong>: Configure automation pipelines for continuous integration and deployment, and select the appropriate environment (e.g., <strong>cloud platforms</strong> or <strong>Kubernetes</strong>).</li>
</ul>
<hr>
<p><a name="conclusion"></a></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This article provides an overview of constructing a ChatGPT-like system, covering the core conversation flow and expanding to include session management and historical message storage. We discussed strategies for system expansion and laid out steps toward production readiness.</p>
<hr>
<p><a name="references"></a></p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp">llama.cpp GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/api-reference/chat/create">OpenAI API Reference</a></li>
</ul>
<pre><code>
This enhanced Markdown document covers each requested update, including detailed technical sections, diagrams, keywords, and sections for expansion and production readiness.
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Spark-in-Kubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Spark-in-Kubernetes/" class="post-title-link" itemprop="url">Spark in Kubernetes</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 11:55:22" itemprop="dateCreated datePublished" datetime="2024-10-28T11:55:22-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kubernetes/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#architecture-overview">Architecture Overview</a><ul>
<li><a href="#diagram-architecture-overview">Diagram: Architecture Overview</a></li>
</ul>
</li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#1-configuring-google-cloud-storage-gcs-bucket">1. Configuring Google Cloud Storage (GCS) Bucket</a></li>
<li><a href="#2-deploying-postgresql-for-hive-metadata">2. Deploying PostgreSQL for Hive Metadata</a><ul>
<li><a href="#postgresql-yaml">PostgreSQL YAML</a></li>
</ul>
</li>
<li><a href="#3-installing-hive-metastore">3. Installing Hive Metastore</a><ul>
<li><a href="#hive-configuration">Hive Configuration</a></li>
</ul>
</li>
<li><a href="#4-deploying-spark-master-and-workers">4. Deploying Spark Master and Workers</a><ul>
<li><a href="#spark-master-and-worker-statefulset-yaml">Spark Master and Worker StatefulSet YAML</a></li>
</ul>
</li>
<li><a href="#5-setting-up-the-spark-history-server">5. Setting Up the Spark History Server</a><ul>
<li><a href="#spark-history-server-yaml">Spark History Server YAML</a></li>
</ul>
</li>
<li><a href="#6-configuring-ingress">6. Configuring Ingress</a><ul>
<li><a href="#ingress-yaml">Ingress YAML</a></li>
</ul>
</li>
<li><a href="#7-testing-the-deployment-with-spark-job">7. Testing the Deployment with Spark Job</a></li>
<li><a href="#furthermore">Furthermore</a><ul>
<li><a href="#statefulset-vs-deployment">StatefulSet vs Deployment</a></li>
<li><a href="#1-spark-master-and-worker-as-statefulsets">1. <strong>Spark Master and Worker as StatefulSets</strong></a></li>
<li><a href="#2-spark-history-server-as-a-deployment">2. <strong>Spark History Server as a Deployment</strong></a></li>
</ul>
</li>
<li><a href="#summary-table">Summary Table</a></li>
</ul>
<hr>
<p>This guide covers the steps to deploy an Apache Spark cluster with a master, two workers, and a Spark History Server on Kubernetes. It configures a GCS bucket as the default file system and installs Hive with PostgreSQL as its backend. An Ingress is set up for accessing the Spark UI and History Server.</p>
<p><a name="architecture-overview"></a></p>
<h2 id="Architecture-Overview"><a href="#Architecture-Overview" class="headerlink" title="Architecture Overview"></a>Architecture Overview</h2><p>The setup includes the following components:</p>
<ul>
<li><strong>Spark Master and Workers</strong>: Deployed using StatefulSets for stable identity and persistence.</li>
<li><strong>History Server</strong>: Deployed using a Deployment and configured to store Spark event logs in GCS.</li>
<li><strong>Hive and PostgreSQL</strong>: PostgreSQL is used as the backend for Hive metadata, and Hive is deployed to store Spark tables.</li>
<li><strong>Ingress</strong>: Provides external access to Spark Master UI and History Server UI.</li>
</ul>
<h3 id="Diagram-Architecture-Overview"><a href="#Diagram-Architecture-Overview" class="headerlink" title="Diagram: Architecture Overview"></a>Diagram: Architecture Overview</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">+---------------------------+</span><br><span class="line">|                           |</span><br><span class="line">|        Kubernetes         |</span><br><span class="line">|                           |</span><br><span class="line">+---------------------------+</span><br><span class="line">|                           |</span><br><span class="line">|  +---------+   +---------+|</span><br><span class="line">|  |  Spark  |   |  Spark  ||</span><br><span class="line">|  |  Master |   | Workers ||</span><br><span class="line">|  +---------+   +---------+|</span><br><span class="line">|                           |</span><br><span class="line">|        +-----------+      |</span><br><span class="line">|        |  History  |      |</span><br><span class="line">|        |  Server   |      |</span><br><span class="line">|        +-----------+      |</span><br><span class="line">|            |              |</span><br><span class="line">|         Ingress           |</span><br><span class="line">+---------------------------+</span><br><span class="line">           |</span><br><span class="line">    External Access</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="prerequisites"></a></p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><ul>
<li><strong>Kubernetes Cluster</strong> with access to deploy resources.</li>
<li><strong>kubectl</strong> command-line tool configured to access the cluster.</li>
<li><strong>Helm</strong> for deploying Hive and PostgreSQL.</li>
<li><strong>Google Cloud Storage (GCS)</strong> bucket created for Spark event logs.</li>
<li><strong>Google Cloud SDK</strong> installed and configured for authentication to GCS.</li>
</ul>
<hr>
<p><a name="1-configuring-google-cloud-storage-gcs-bucket"></a></p>
<h2 id="1-Configuring-Google-Cloud-Storage-GCS-Bucket"><a href="#1-Configuring-Google-Cloud-Storage-GCS-Bucket" class="headerlink" title="1. Configuring Google Cloud Storage (GCS) Bucket"></a>1. Configuring Google Cloud Storage (GCS) Bucket</h2><ol>
<li><p>Create a GCS bucket if not already created:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gsutil mb gs://your-spark-event-logs</span><br></pre></td></tr></table></figure>
</li>
<li><p>Set up a GCS service account key and save it as a Kubernetes secret. This will allow Spark to access GCS:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret generic gcs-key \</span><br><span class="line">--from-file=key.json=/path/to/gcs-service-account-key.json</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<p><a name="2-deploying-postgresql-for-hive-metadata"></a></p>
<h2 id="2-Deploying-PostgreSQL-for-Hive-Metadata"><a href="#2-Deploying-PostgreSQL-for-Hive-Metadata" class="headerlink" title="2. Deploying PostgreSQL for Hive Metadata"></a>2. Deploying PostgreSQL for Hive Metadata</h2><p>PostgreSQL will act as the relational database for Hive’s metadata.</p>
<h3 id="PostgreSQL-YAML"><a href="#PostgreSQL-YAML" class="headerlink" title="PostgreSQL YAML"></a>PostgreSQL YAML</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">postgresql-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">postgresql</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">postgresql</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">postgresql</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">postgresql</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">postgres:13</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POSTGRES_DB</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;hive_metastore&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POSTGRES_USER</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;hiveuser&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">POSTGRES_PASSWORD</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;hivepassword&quot;</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">&quot;/var/lib/postgresql/data&quot;</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">postgresql-data</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">postgresql-data</span></span><br><span class="line">        <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">          <span class="attr">claimName:</span> <span class="string">postgresql-pvc</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="3-installing-hive-metastore"></a></p>
<h2 id="3-Installing-Hive-Metastore"><a href="#3-Installing-Hive-Metastore" class="headerlink" title="3. Installing Hive Metastore"></a>3. Installing Hive Metastore</h2><p>Hive Metastore will manage metadata for Spark. </p>
<h3 id="Hive-Configuration"><a href="#Hive-Configuration" class="headerlink" title="Hive Configuration"></a>Hive Configuration</h3><ol>
<li><p>Download and install Hive Helm chart:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line">helm install hive bitnami/hive --<span class="built_in">set</span> postgresql.enabled=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Update Hive configuration to use PostgreSQL.</p>
</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Values.yaml for Hive</span></span><br><span class="line"><span class="attr">hive:</span></span><br><span class="line">  <span class="attr">metastore:</span></span><br><span class="line">    <span class="attr">databaseType:</span> <span class="string">postgres</span></span><br><span class="line">    <span class="attr">jdbcUrl:</span> <span class="string">jdbc:postgresql://postgresql-service/hive_metastore</span></span><br><span class="line">    <span class="attr">user:</span> <span class="string">hiveuser</span></span><br><span class="line">    <span class="attr">password:</span> <span class="string">hivepassword</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="4-deploying-spark-master-and-workers"></a></p>
<h2 id="4-Deploying-Spark-Master-and-Workers"><a href="#4-Deploying-Spark-Master-and-Workers" class="headerlink" title="4. Deploying Spark Master and Workers"></a>4. Deploying Spark Master and Workers</h2><h3 id="Spark-Master-and-Worker-StatefulSet-YAML"><a href="#Spark-Master-and-Worker-StatefulSet-YAML" class="headerlink" title="Spark Master and Worker StatefulSet YAML"></a>Spark Master and Worker StatefulSet YAML</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-master</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">spark-master</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">spark</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">spark</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">spark-master</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">spark:latest</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">7077</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPARK_MASTER_HOST</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;spark-master&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-worker</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">spark</span></span><br><span class="line">      <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">spark</span></span><br><span class="line">        <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">spark-worker</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">spark:latest</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8081</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPARK_WORKER_CORES</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;1&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPARK_WORKER_MEMORY</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;1G&quot;</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPARK_MASTER</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;spark://spark-master:7077&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="5-setting-up-the-spark-history-server"></a></p>
<h2 id="5-Setting-Up-the-Spark-History-Server"><a href="#5-Setting-Up-the-Spark-History-Server" class="headerlink" title="5. Setting Up the Spark History Server"></a>5. Setting Up the Spark History Server</h2><p>The History Server will read event logs from the GCS bucket for job history.</p>
<h3 id="Spark-History-Server-YAML"><a href="#Spark-History-Server-YAML" class="headerlink" title="Spark History Server YAML"></a>Spark History Server YAML</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-history-server</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">spark-history</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">spark-history</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">spark-history-server</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">spark:latest</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPARK_HISTORY_OPTS</span></span><br><span class="line">          <span class="attr">value:</span> <span class="string">&quot;-Dspark.history.fs.logDirectory=gs://your-spark-event-logs&quot;</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/opt/spark/work-dir</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">gcs-key</span></span><br><span class="line">          <span class="attr">subPath:</span> <span class="string">key.json</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">gcs-key</span></span><br><span class="line">        <span class="attr">secret:</span></span><br><span class="line">          <span class="attr">secretName:</span> <span class="string">gcs-key</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="6-configuring-ingress"></a></p>
<h2 id="6-Configuring-Ingress"><a href="#6-Configuring-Ingress" class="headerlink" title="6. Configuring Ingress"></a>6. Configuring Ingress</h2><p>Ingress will expose the Spark Master UI and History Server UI.</p>
<h3 id="Ingress-YAML"><a href="#Ingress-YAML" class="headerlink" title="Ingress YAML"></a>Ingress YAML</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">spark.example.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/master</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">spark-master</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">8080</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/history</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">spark-history-server</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">18080</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="7-testing-the-deployment-with-spark-job"></a></p>
<h2 id="7-Testing-the-Deployment-with-Spark-Job"><a href="#7-Testing-the-Deployment-with-Spark-Job" class="headerlink" title="7. Testing the Deployment with Spark Job"></a>7. Testing the Deployment with Spark Job</h2><p>To verify the installation, use <code>spark-submit</code> to run a simple calculation for PI.</p>
<ol>
<li><p>Submit a PI calculation job using <code>spark-submit</code>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="built_in">exec</span> -it spark-master-0 -- spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://spark-master:7077 \</span><br><span class="line">/opt/spark/examples/jars/spark-examples_2.12-3.0.1.jar 1000</span><br></pre></td></tr></table></figure>
</li>
<li><p>Check the Spark Master and History Server UIs</p>
</li>
</ol>
<p> to confirm job execution and view logs.</p>
<h2 id="Furthermore"><a href="#Furthermore" class="headerlink" title="Furthermore"></a>Furthermore</h2><h3 id="StatefulSet-vs-Deployment"><a href="#StatefulSet-vs-Deployment" class="headerlink" title="StatefulSet vs Deployment"></a>StatefulSet vs Deployment</h3><p>In the official Helm chart for Apache Spark, the choice of <strong>StatefulSet</strong> for Spark Master and Worker, and <strong>Deployment</strong> for the Spark History Server, aligns with the specific requirements and behaviors of each component. Here’s a breakdown of the reasons for these design choices:</p>
<h3 id="1-Spark-Master-and-Worker-as-StatefulSets"><a href="#1-Spark-Master-and-Worker-as-StatefulSets" class="headerlink" title="1. Spark Master and Worker as StatefulSets"></a>1. <strong>Spark Master and Worker as StatefulSets</strong></h3><ul>
<li><strong>Persistence and Stability</strong>: The Spark Master and Worker nodes need stable, unique identities to communicate reliably. Using <strong>StatefulSet</strong> ensures that each replica (instance) has a stable network identity (hostname) and, if configured, persistent storage.</li>
<li><strong>Leader Election and Failover</strong>: Spark Master in standalone mode has a primary leader and backup node architecture, where the leader is responsible for the cluster state. StatefulSets allow these nodes to maintain consistent, unique identifiers, which is crucial for leader election and failover without disrupting the Spark cluster.</li>
<li><strong>Worker Registration</strong>: Spark Workers register with the Master, and having a unique, stable network identity ensures workers don’t inadvertently re-register or conflict with each other after restarts or failures. StatefulSets are the preferred way to handle this kind of behavior.</li>
</ul>
<h3 id="2-Spark-History-Server-as-a-Deployment"><a href="#2-Spark-History-Server-as-a-Deployment" class="headerlink" title="2. Spark History Server as a Deployment"></a>2. <strong>Spark History Server as a Deployment</strong></h3><ul>
<li><strong>Stateless Operation</strong>: The Spark History Server is fundamentally a stateless application. It reads from a pre-configured storage (such as HDFS or S3) where application logs are stored but doesn’t require persistent storage for its own operation. Using a <strong>Deployment</strong> is appropriate here, as the history server can be easily replicated or scaled without maintaining unique identities.</li>
<li><strong>Easier Scaling and Update Management</strong>: Deployments provide automatic scaling and rolling updates, which are more suitable for stateless services. If you need to increase the availability of the history server, you can simply increase the replica count in the Deployment, and Kubernetes will handle the scaling automatically.</li>
<li><strong>Failure Recovery</strong>: Since there’s no dependency on unique network identities or persistent state, if the History Server pod fails, it can be easily recreated without any additional orchestration, which is exactly what Deployments are optimized for.</li>
</ul>
<h2 id="Summary-Table"><a href="#Summary-Table" class="headerlink" title="Summary Table"></a>Summary Table</h2><table>
<thead>
<tr>
<th>Component</th>
<th>Kubernetes Kind</th>
<th>Purpose</th>
<th>Reasoning</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Spark Master</strong></td>
<td>StatefulSet</td>
<td>Primary and backup master for Spark cluster</td>
<td>Needs stable identity for cluster coordination and leader election</td>
</tr>
<tr>
<td><strong>Spark Worker</strong></td>
<td>StatefulSet</td>
<td>Worker nodes that register with Spark Master</td>
<td>Stable network identity ensures reliable registration and communication with Master</td>
</tr>
<tr>
<td><strong>Spark History Server</strong></td>
<td>Deployment</td>
<td>Reads logs and provides historical application data</td>
<td>Stateless and doesn’t need unique identities; easier to scale and restart as a Deployment</td>
</tr>
</tbody></table>
<p>This setup optimizes the deployment structure for each Spark component’s unique requirements, leveraging Kubernetes’ StatefulSet and Deployment resources for their intended purposes.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.whereq.com/2024/10/28/Comprehensive-Guide-to-Kubernetes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Dazhi Zhang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WhereQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | WhereQ">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/28/Comprehensive-Guide-to-Kubernetes/" class="post-title-link" itemprop="url">Comprehensive Guide to Kubernetes</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-28 11:51:24" itemprop="dateCreated datePublished" datetime="2024-10-28T11:51:24-04:00">2024-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-11-21 16:23:35" itemprop="dateModified" datetime="2025-11-21T16:23:35-05:00">2025-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a href="#cluster">Cluster</a></li>
<li><a href="#node">Node</a></li>
<li><a href="#pod">Pod</a></li>
<li><a href="#deployment">Deployment</a></li>
<li><a href="#service">Service</a></li>
<li><a href="#ingress">Ingress</a></li>
<li><a href="#configmap">ConfigMap</a></li>
<li><a href="#secret">Secret</a></li>
<li><a href="#persistent-volume-pv-and-persistent-volume-claim-pvc">Persistent Volume (PV) and Persistent Volume Claim (PVC)</a></li>
<li><a href="#namespace">Namespace</a></li>
<li><a href="#daemonset">DaemonSet</a></li>
<li><a href="#job-and-cronjob">Job and CronJob</a></li>
<li><a href="#horizontal-pod-autoscaler-hpa">Horizontal Pod Autoscaler (HPA)</a></li>
<li><a href="#statefulset">StatefulSet</a></li>
<li><a href="#volume-and-storageclass">Volume and StorageClass</a></li>
<li><a href="#networkpolicy">NetworkPolicy</a></li>
<li><a href="#custom-resource-definitions-crds">Custom Resource Definitions (CRDs)</a></li>
<li><a href="#helm-charts">Helm Charts</a></li>
</ul>
<hr>
<p>This guide provides a detailed overview of Kubernetes concepts, examples, use cases, installation YAML examples, and visual representations of the architecture. </p>
<p><a name="cluster"></a></p>
<h2 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h2><p>A <strong>Kubernetes Cluster</strong> is a group of nodes (machines) that host and manage containerized applications. Each cluster has at least one master node, which controls the state of the cluster, and multiple worker nodes.</p>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>A cloud-based cluster with one master node and multiple worker nodes in Google Kubernetes Engine (GKE).</p>
<h3 id="Use-Case"><a href="#Use-Case" class="headerlink" title="Use Case"></a>Use Case</h3><p>An ideal setup for running a production microservices application with high availability.</p>
<h4 id="YAML-Structure-for-Cluster-Creation"><a href="#YAML-Structure-for-Cluster-Creation" class="headerlink" title="YAML Structure for Cluster Creation"></a>YAML Structure for Cluster Creation</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kind.x-k8s.io/v1alpha4</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Cluster</span></span><br><span class="line"><span class="attr">nodes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">control-plane</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">worker</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">role:</span> <span class="string">worker</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="node"></a></p>
<h2 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h2><p>A <strong>Node</strong> is a single machine within a Kubernetes cluster, capable of running one or more pods.</p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p>In a cloud environment, each node could be a virtual machine instance.</p>
<h3 id="Use-Case-1"><a href="#Use-Case-1" class="headerlink" title="Use Case"></a>Use Case</h3><p>Nodes distribute workloads across the infrastructure.</p>
<h4 id="YAML-Snippet"><a href="#YAML-Snippet" class="headerlink" title="YAML Snippet"></a>YAML Snippet</h4><p>The node configuration is usually specified by the cluster management tool (e.g., GKE or EKS) rather than in YAML, as it pertains to the infrastructure layer.</p>
<hr>
<p><a name="pod"></a></p>
<h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p>A <strong>Pod</strong> is the smallest deployable unit in Kubernetes, which can contain one or more containers.</p>
<h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example"></a>Example</h3><p>A pod running a web server container and a logging container.</p>
<h3 id="Use-Case-2"><a href="#Use-Case-2" class="headerlink" title="Use Case"></a>Use Case</h3><p>Running tightly coupled applications together within the same lifecycle.</p>
<h4 id="YAML-Structure-for-Pod"><a href="#YAML-Structure-for-Pod" class="headerlink" title="YAML Structure for Pod"></a>YAML Structure for Pod</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web-server-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web-server</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">logger</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">fluentd</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="deployment"></a></p>
<h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><p>A <strong>Deployment</strong> is a Kubernetes object for managing a group of identical pods. It provides capabilities like rolling updates and rollback.</p>
<h3 id="Example-3"><a href="#Example-3" class="headerlink" title="Example"></a>Example</h3><p>A deployment with three replicas of a web server pod.</p>
<h3 id="Use-Case-3"><a href="#Use-Case-3" class="headerlink" title="Use Case"></a>Use Case</h3><p>Maintaining a stable version of an application by managing pod replicas.</p>
<h4 id="YAML-Structure-for-Deployment"><a href="#YAML-Structure-for-Deployment" class="headerlink" title="YAML Structure for Deployment"></a>YAML Structure for Deployment</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.17.4</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="service"></a></p>
<h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p>A <strong>Service</strong> provides a stable endpoint for accessing a set of pods.</p>
<h3 id="Example-4"><a href="#Example-4" class="headerlink" title="Example"></a>Example</h3><p>A service that exposes an application to the public internet.</p>
<h3 id="Use-Case-4"><a href="#Use-Case-4" class="headerlink" title="Use Case"></a>Use Case</h3><p>Load balancing traffic to an application across multiple pods.</p>
<h4 id="YAML-Structure-for-Service"><a href="#YAML-Structure-for-Service" class="headerlink" title="YAML Structure for Service"></a>YAML Structure for Service</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web-service</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">LoadBalancer</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="ingress"></a></p>
<h2 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h2><p><strong>Ingress</strong> manages external access to services, typically using HTTP.</p>
<h3 id="Example-5"><a href="#Example-5" class="headerlink" title="Example"></a>Example</h3><p>An ingress with rules to route traffic to different services based on URL paths.</p>
<h3 id="Use-Case-5"><a href="#Use-Case-5" class="headerlink" title="Use Case"></a>Use Case</h3><p>Routing <code>/api</code> to backend services and <code>/static</code> to frontend services on the same domain.</p>
<h4 id="YAML-Structure-for-Ingress"><a href="#YAML-Structure-for-Ingress" class="headerlink" title="YAML Structure for Ingress"></a>YAML Structure for Ingress</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">example-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">example.com</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">      <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/api</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">api-service</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/static</span></span><br><span class="line">        <span class="attr">pathType:</span> <span class="string">Prefix</span></span><br><span class="line">        <span class="attr">backend:</span></span><br><span class="line">          <span class="attr">service:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">static-service</span></span><br><span class="line">            <span class="attr">port:</span></span><br><span class="line">              <span class="attr">number:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="configmap"></a></p>
<h2 id="ConfigMap"><a href="#ConfigMap" class="headerlink" title="ConfigMap"></a>ConfigMap</h2><p>A <strong>ConfigMap</strong> stores non-sensitive configuration data.</p>
<h3 id="Example-6"><a href="#Example-6" class="headerlink" title="Example"></a>Example</h3><p>A ConfigMap for environment-specific variables.</p>
<h3 id="Use-Case-6"><a href="#Use-Case-6" class="headerlink" title="Use Case"></a>Use Case</h3><p>Keeping configuration separate from the application code.</p>
<h4 id="YAML-Structure-for-ConfigMap"><a href="#YAML-Structure-for-ConfigMap" class="headerlink" title="YAML Structure for ConfigMap"></a>YAML Structure for ConfigMap</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">config-demo</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">DATABASE_URL:</span> <span class="string">&quot;jdbc:mysql://dbhost:3306/mydatabase&quot;</span></span><br><span class="line">  <span class="attr">DEBUG_LEVEL:</span> <span class="string">&quot;3&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="secret"></a></p>
<h2 id="Secret"><a href="#Secret" class="headerlink" title="Secret"></a>Secret</h2><p>A <strong>Secret</strong> stores sensitive information, like passwords and tokens.</p>
<h3 id="Example-7"><a href="#Example-7" class="headerlink" title="Example"></a>Example</h3><p>A secret containing API keys for external services.</p>
<h3 id="Use-Case-7"><a href="#Use-Case-7" class="headerlink" title="Use Case"></a>Use Case</h3><p>Securing sensitive data without exposing it in the code.</p>
<h4 id="YAML-Structure-for-Secret"><a href="#YAML-Structure-for-Secret" class="headerlink" title="YAML Structure for Secret"></a>YAML Structure for Secret</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">api-key-secret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">api-key:</span> <span class="string">c29tZS1yYW5kb20ta2V5Cg==</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="persistent-volume-pv-and-persistent-volume-claim-pvc"></a></p>
<h2 id="Persistent-Volume-PV-and-Persistent-Volume-Claim-PVC"><a href="#Persistent-Volume-PV-and-Persistent-Volume-Claim-PVC" class="headerlink" title="Persistent Volume (PV) and Persistent Volume Claim (PVC)"></a>Persistent Volume (PV) and Persistent Volume Claim (PVC)</h2><p>A <strong>Persistent Volume</strong> provides storage, while a <strong>Persistent Volume Claim</strong> is a request for that storage.</p>
<h3 id="Example-8"><a href="#Example-8" class="headerlink" title="Example"></a>Example</h3><p>A PV representing cloud disk storage and a PVC used by a database pod.</p>
<h3 id="Use-Case-8"><a href="#Use-Case-8" class="headerlink" title="Use Case"></a>Use Case</h3><p>Ensuring data persistence for applications that require durable storage.</p>
<h4 id="YAML-Structure-for-PV-and-PVC"><a href="#YAML-Structure-for-PV-and-PVC" class="headerlink" title="YAML Structure for PV and PVC"></a>YAML Structure for PV and PVC</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv-storage</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">10Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">hostPath:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">&quot;/mnt/data&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pvc-storage</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">8Gi</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="namespace"></a></p>
<h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><p>A <strong>Namespace</strong> is a way to divide cluster resources among multiple users.</p>
<h3 id="Example-9"><a href="#Example-9" class="headerlink" title="Example"></a>Example</h3><p>Separate namespaces for development, staging, and production environments.</p>
<h3 id="Use-Case-9"><a href="#Use-Case-9" class="headerlink" title="Use Case"></a>Use Case</h3><p>Organizing resources for different environments or teams.</p>
<h4 id="YAML-Structure-for-Namespace"><a href="#YAML-Structure-for-Namespace" class="headerlink" title="YAML Structure for Namespace"></a>YAML Structure for Namespace</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev-environment</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="daemonset"></a></p>
<h2 id="DaemonSet"><a href="#DaemonSet" class="headerlink" title="DaemonSet"></a>DaemonSet</h2><p>A <strong>DaemonSet</strong> ensures that specific pods run on each node.</p>
<h3 id="Example-10"><a href="#Example-10" class="headerlink" title="Example"></a>Example</h3><p>Running a logging agent on every node in the cluster.</p>
<h3 id="Use-Case-10"><a href="#Use-Case-10" class="headerlink" title="Use Case"></a>Use Case</h3><p>Managing node-wide services like logging or monitoring.</p>
<h4 id="YAML-Structure-for-DaemonSet"><a href="#YAML-Structure-for-DaemonSet" class="headerlink" title="YAML Structure for DaemonSet"></a>YAML Structure for DaemonSet</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">logger</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">logger</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">logger</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">fluent/fluentd</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="job-and-cronjob"></a></p>
<h2 id="Job-and-CronJob"><a href="#Job-and-CronJob" class="headerlink" title="Job and CronJob"></a>Job and CronJob</h2><p><strong>Job</strong> runs a one-time task, while <strong>CronJob</strong> schedules a recurring task.</p>
<h3 id="Example-11"><a href="#Example-11" class="headerlink" title="Example"></a>Example</h3><p>A Job to back up a database once and a CronJob to clean up logs daily.</p>
<h3 id="Use-Case-11"><a href="#Use-Case-11" class="headerlink" title="Use Case"></a>Use Case</h3><p>Automating scheduled tasks or batch processing.</p>
<h4 id="YAML-Structure-for-Job-and-CronJob"><a href="#YAML-Structure-for-Job-and-CronJob" class="headerlink" title="YAML Structure for Job and CronJob"></a>YAML Structure for Job and CronJob</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">backup-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">backup</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">backup-tool</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">daily-cleanup</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">&quot;0 0 * * *&quot;</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cleanup</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">cleanup-tool</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="horizontal-pod-autoscaler-hpa"></a></p>
<h2 id="Horizontal-Pod-Autoscaler-HPA"><a href="#Horizontal-Pod-Autoscaler-HPA" class="headerlink" title="Horizontal Pod Autoscaler (HPA)"></a>Horizontal Pod Autoscaler (HPA)</h2><p>The <strong>HPA</strong> scales pod replicas automatically based on resource utilization.</p>
<h3 id="Example-12"><a href="#Example-12" class="headerlink" title="Example"></a>Example</h3><p>Scaling web server pods based on CPU usage.</p>
<h3 id="Use-Case-12"><a href="#Use-Case-12" class="headerlink" title="Use Case"></a>Use Case</h3><p>Scaling applications to handle variable workloads.</p>
<h4 id="YAML-Structure-for-HPA"><a href="#YAML-Structure-for-HPA" class="headerlink" title="YAML Structure for HPA"></a>YAML Structure for HPA</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web-hpa</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">scaleTarget</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Ref:</span></span><br><span class="line">    <span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web-deployment</span></span><br><span class="line">  <span class="attr">minReplicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">maxReplicas:</span> <span class="number">10</span></span><br><span class="line">  <span class="attr">targetCPUUtilizationPercentage:</span> <span class="number">70</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="statefulset"></a></p>
<h2 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet"></a>StatefulSet</h2><p>A <strong>StatefulSet</strong> manages stateful applications with unique and persistent storage.</p>
<h3 id="Example-13"><a href="#Example-13" class="headerlink" title="Example"></a>Example</h3><p>A StatefulSet for a MongoDB replica set.</p>
<h3 id="Use-Case-13"><a href="#Use-Case-13" class="headerlink" title="Use Case"></a>Use Case</h3><p>Managing stateful applications where each instance requires its own storage.</p>
<h4 id="YAML-Structure-for-StatefulSet"><a href="#YAML-Structure-for-StatefulSet" class="headerlink" title="YAML Structure for StatefulSet"></a>YAML Structure for StatefulSet</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">&quot;mongo&quot;</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">mongo</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">mongo</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongo</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">mongo</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">27017</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">mongo</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="volume-and-storageclass"></a></p>
<h2 id="Volume-and-StorageClass"><a href="#Volume-and-StorageClass" class="headerlink" title="Volume and StorageClass"></a>Volume and StorageClass</h2><p><strong>Volumes</strong> provide storage to pods, while <strong>StorageClass</strong> defines types of storage.</p>
<h3 id="Example-14"><a href="#Example-14" class="headerlink" title="Example"></a>Example</h3><p>SSD-based storage for a database application.</p>
<h3 id="Use-Case-14"><a href="#Use-Case-14" class="headerlink" title="Use Case"></a>Use Case</h3><p>Choosing storage for applications based on performance requirements.</p>
<h4 id="YAML-Structure-for-StorageClass-and-Volume"><a href="#YAML-Structure-for-StorageClass-and-Volume" class="headerlink" title="YAML Structure for StorageClass and Volume"></a>YAML Structure for StorageClass and Volume</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fast</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">gp2</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fast-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">fast</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">50Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="networkpolicy"></a></p>
<h2 id="NetworkPolicy"><a href="#NetworkPolicy" class="headerlink" title="NetworkPolicy"></a>NetworkPolicy</h2><p><strong>NetworkPolicy</strong> defines network access rules between pods.</p>
<h3 id="Example-15"><a href="#Example-15" class="headerlink" title="Example"></a>Example</h3><p>Restricting access to specific pods.</p>
<h3 id="Use-Case-15"><a href="#Use-Case-15" class="headerlink" title="Use Case"></a>Use Case</h3><p>Securing inter-service communication.</p>
<h4 id="YAML-Structure-for-NetworkPolicy"><a href="#YAML-Structure-for-NetworkPolicy" class="headerlink" title="YAML Structure for NetworkPolicy"></a>YAML Structure for NetworkPolicy</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">NetworkPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">deny-all</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">podSelector:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">policyTypes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Ingress</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">Egress</span></span><br><span class="line">  <span class="attr">ingress:</span> []</span><br><span class="line">  <span class="attr">egress:</span> []</span><br></pre></td></tr></table></figure>

<hr>
<p><a name="custom-resource-definitions-crds"></a></p>
<h2 id="Custom-Resource-Definitions-CRDs"><a href="#Custom-Resource-Definitions-CRDs" class="headerlink" title="Custom Resource Definitions (CRDs)"></a>Custom Resource Definitions (CRDs)</h2><p><strong>CRDs</strong> extend Kubernetes by allowing users to create custom resources.</p>
<h3 id="Example-16"><a href="#Example-16" class="headerlink" title="Example"></a>Example</h3><p>A custom resource to manage database schema migrations.</p>
<h3 id="Use-Case-16"><a href="#Use-Case-16" class="headerlink" title="Use Case"></a>Use Case</h3><p>Adding domain-specific resources for applications.</p>
<h4 id="YAML-Structure-for-CRD"><a href="#YAML-Structure-for-CRD" class="headerlink" title="YAML Structure for CRD"></a>YAML Structure for CRD</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">migrations.mycompany.com</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">group:</span> <span class="string">mycompany.com</span></span><br><span class="line">  <span class="attr">versions:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">v1</span></span><br><span class="line">    <span class="attr">served:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">scope:</span> <span class="string">Namespaced</span></span><br><span class="line">  <span class="attr">names:</span></span><br><span class="line">    <span class="attr">plural:</span> <span class="string">migrations</span></span><br><span class="line">    <span class="attr">singular:</span> <span class="string">migration</span></span><br><span class="line">    <span class="attr">kind:</span> <span class="string">Migration</span></span><br></pre></td></tr></table></figure>

<hr>
<p><a name="helm-charts"></a></p>
<h2 id="Helm-Charts"><a href="#Helm-Charts" class="headerlink" title="Helm Charts"></a>Helm Charts</h2><p><strong>Helm</strong> is a package manager for Kubernetes, and <strong>Helm Charts</strong> are pre-configured packages.</p>
<h3 id="Example-17"><a href="#Example-17" class="headerlink" title="Example"></a>Example</h3><p>A Helm chart for deploying a WordPress site.</p>
<h3 id="Use-Case-17"><a href="#Use-Case-17" class="headerlink" title="Use Case"></a>Use Case</h3><p>Simplifying application deployment and management.</p>
<h4 id="Example-Helm-Command"><a href="#Example-Helm-Command" class="headerlink" title="Example Helm Command"></a>Example Helm Command</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install my-wordpress bitnami/wordpress</span><br></pre></td></tr></table></figure>

<hr>
<p>These concepts are essential for understanding and operating Kubernetes in production, allowing you to deploy, manage, and scale applications effectively. Each example and YAML configuration highlights the power and flexibility Kubernetes offers in a variety of scenarios.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/8/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/15/">15</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/10/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Dazhi Zhang</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.1/mermaid.min.js","integrity":"sha256-YbM1pG3wWnzhyYN49g5fPnen+2CKEFaZfopkkwSpNtY="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>





  





</body>
</html>
